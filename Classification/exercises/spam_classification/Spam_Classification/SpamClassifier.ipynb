{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpamClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN4edPtzWgkVr+cFIR3E2iE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zeddling/Hands_On_ML/blob/classification/Hands_On_ML/Classification/exercises/spam_classification/Spam_Classification/SpamClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XkKChelrw1V"
      },
      "source": [
        "#Spam Classifier\n",
        "<p>Reference: <a href=\"https://github.com/ageron/handson-ml2/blob/master/03_classification.ipynb\">Classification.ipynb</a></p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymMBCGSRptSQ",
        "outputId": "17cf0143-60a4-4c30-deb3-b6c62c62d00c"
      },
      "source": [
        "# Mount google drive folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0yjOI1-6vbu"
      },
      "source": [
        "# Load dataset\n",
        "import os\n",
        "ham_filenames = [name for name in sorted(os.listdir(\"/content/drive/MyDrive/Datasets/spam_email/easy_ham\")) if len(name) > 20]\n",
        "hard_ham_filenames = [name for name in sorted(os.listdir(\"/content/drive/MyDrive/Datasets/spam_email/hard_ham\")) if len(name) > 20]\n",
        "spam_filenames = [name for name in sorted(os.listdir(\"/content/drive/MyDrive/Datasets/spam_email/spam\")) if len(name) > 20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X2U_FPS7tsR",
        "outputId": "c92afa42-c752-4c79-e2cf-401b566ff6cf"
      },
      "source": [
        "len(ham_filenames)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZTe7E7_7wCH",
        "outputId": "01cdfd48-993c-435a-e0d8-1422ad2801dc"
      },
      "source": [
        "len(spam_filenames)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXP7Jh4qXc9Y",
        "outputId": "8c0a6a84-976d-4089-dd18-74d56e1016d7"
      },
      "source": [
        "len(hard_ham_filenames)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "250"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WziBfphj8E5I"
      },
      "source": [
        "# Use python's email module to pass emails\n",
        "import email\n",
        "import email.policy\n",
        "\n",
        "spam_path=\"/content/drive/MyDrive/Datasets/spam_email/\"\n",
        "def load_emails(filename, directory):\n",
        "  with open(os.path.join(spam_path, directory, filename), \"rb\") as f:\n",
        "    return email.parser.BytesParser(policy=email.policy.default).parse(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ4hGpkLev0v"
      },
      "source": [
        "hard_ham_emails = [load_emails(filename=name, directory=\"hard_ham\") for name in hard_ham_filenames]\n",
        "spam_emails = [load_emails(filename=name, directory=\"spam\") for name in spam_filenames]\n",
        "ham_emails = [load_emails(filename=name, directory=\"easy_ham\") for name in ham_filenames]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmvwikbmZrVu",
        "outputId": "df94c36f-900c-43b9-c405-c986386399f6"
      },
      "source": [
        "print(hard_ham_emails[0].get_content().strip())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<html>\n",
            "<head>\n",
            "        <title>Cable companies cracking down on Wi-Fi</title>\n",
            "</head>\n",
            "<body bgcolor=\"#e5e5e5\">\n",
            "<center>\n",
            "<a name=\"top\"></a>\n",
            "<!-- Logo and ad banner -->\n",
            "<table cellpadding=0 cellspacing=0 border=0 width=612 bgcolor=\"#ffffff\">\n",
            "\t<tr valign=top>\n",
            "    <td width=442 colspan=4 bgcolor=\"#e5e5e5\">\n",
            "        <img src=\"http://home.cnet.com/i/ne/ds/dhed.gif\" alt=\"\" width=\"442\" height=\"63\" border=\"0\"><br>\n",
            "    </td>\n",
            "    <td width=160 rowspan=2>\n",
            "\t\t<table cellpadding=0 cellspacing=0 border=0 width=160>\n",
            "\t\t<tr><td align=center bgcolor=\"#e5e5e5\">\n",
            "\t\t<img src=\"http://home.cnet.com/i/ne/ds/ad.gif\" alt=\"\" width=\"107\" height=\"16\" border=\"0\"><br></td></tr>\n",
            "\t\t</table>\n",
            "<!-- Towerboard -->\n",
            "\t<iframe src=\"http://www.zdnet.com/include/ads/ifc/RGROUP=2560\" scrolling=\"no\" frameborder=\"0\" hspace=\"0\" vspace=\"0\" height=\"600\" width=\"160\" marginheight=\"0\" marginwidth=\"0\">\n",
            "<script language=\"JavaScript\" src=\"http://www.zdnet.com/include/ads/js/RGROUP=2560\">\n",
            "</script>\n",
            "</iframe>\n",
            "<!-- /Towerboard -->\n",
            "\t<p>\n",
            "\t<!-- search form -->\n",
            "\t<TABLE border=0 cellPadding=2 cellSpacing=0 width=150>\n",
            "\t<TR>\n",
            "\t<TD>\n",
            "\t<form method=\"GET\" action=\"http://www.search.com/redirect/\">\n",
            "\t                <img src=\"/b.gif\" width=1 height=4><font face=\"arial, helvetica\" size=\"-1\"><br>&nbsp;<b>Search</b></font><br>\n",
            "\t                &nbsp;<input type=\"text\" name=\"q\" size=\"15\" value=\"\"><br>\n",
            "\t                &nbsp;<select name=\"target\">\n",
            "\t                <option value=\"http://news.search.com/search?tag=ex.ne.newsletter.srch.ne\" selected>News.com\n",
            "\t                <option value=\"http://cnet.search.com/search?tag=ex.ne.newsletter.srch.cnet\">All CNET&nbsp;&nbsp;&nbsp;&nbsp;\n",
            "\t                <option value=\"http://www.search.com/search?tag=ex.ne.newsletter.srch.web\">The Web\n",
            "                </select>&nbsp;<input type=\"submit\" value=\"Go!\" name=\"submit\"></td></form>\n",
            "    </tr></table>\n",
            "    <!-- /search form -->\n",
            "    <p>\n",
            "<!-- Vertical Brick -->\n",
            "<IMG alt=\"Also from CNET\" height=20 src=\"http://home.cnet.com/Ads/Media/Images/RHC_ALSOfromCNETnet.gif\" width=150 NOSEND=\"1\"><BR>\n",
            "<TABLE border=0 cellPadding=2 cellSpacing=0 width=150><TBODY><TR vAlign=top>\n",
            "<TD><FONT face=\"arial, helvetica\" size=-1><B>\n",
            "<a href=\"http://clickthru.online.com/Click?q=4a-HcgUIPpcnTHdcorsxoLkkTKhn-yR\" >Live tech help NOW!</a><p>\n",
            "<a href=\"http://clickthru.online.com/Click?q=5f-WK5BIIKX2F1YRa96fez6pa6cIJPR\" >April's tech award</a><p>\n",
            "<a href=\"http://clickthru.online.com/Click?q=74-VAV8IZZSN6JNEnCRYG8Y0gSPZxnR\" >1 million open jobs</a><p>\n",
            "<a href=\"http://clickthru.online.com/Click?q=89-h28bQ-J1QVNIV5FkUMBXB6W5WWcR\" >News.com: Top CIOs</a> <p>\n",
            "<a href=\"http://clickthru.online.com/Click?q=9e-tWQoQtMQJG9vEv5HSCN0U7nQUDRR\" >ZDNet: PeopleSoft</a>\n",
            "</B></FONT></TD>\n",
            "</TR></TBODY></TABLE></P>\n",
            "<!-- End Vertical Brick-->\n",
            "\t\t<p>\n",
            "\t</td>\n",
            "\t<td width=9 rowspan=2>\n",
            "\t\t<table width=9 cellpadding=0 cellspacing=0 border=0>\n",
            "\t\t\t<tr><td bgcolor=\"#e5e5e5\"><img src=\"http://home.cnet.com/b.gif\" width=\"9\" height=\"50\" border=\"0\"><br></td></tr>\n",
            "\t\t\t<tr><td bgcolor=\"#000000\"><img src=\"http://home.cnet.com/b.gif\" width=\"9\" height=\"1\" border=\"0\"><br></td></tr>\n",
            "\t\t\t<tr><td bgcolor=\"#ffcc00\"><img src=\"http://home.cnet.com/b.gif\" width=\"9\" height=\"10\" border=\"0\"><br></td></tr>\n",
            "\t\t\t<tr><td bgcolor=\"#000000\"><img src=\"http://home.cnet.com/b.gif\" width=\"9\" height=\"1\" border=\"0\"><br></td></tr>\n",
            "\t\t</table>\n",
            "\t</td>\n",
            "\t<td width=1 bgcolor=\"#000000\" rowspan=2><img src=\"http://home.cnet.com/i/ne/ds/bkg.gif\" width=\"1\" height=\"50\" border=\"0\"></td>\n",
            "\t</tr>\n",
            "<!-- Logo and ad banner -->\n",
            "<!-- In the News / Special Reports -->\n",
            "<tr valign=top>\n",
            "\t<td width=1 bgcolor=\"#000000\"><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"1\" border=\"0\"></td>\n",
            "\t<td width=10 bgcolor=\"#ffcc00\"><img src=\"http://home.cnet.com/b.gif\" width=\"10\" height=\"1\" border=\"0\"><br></td>\n",
            "\t<td width=1 bgcolor=\"#000000\"><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"1\" border=\"0\"></td>\n",
            "\t<td width=430 bgcolor=\"#ffffff\">\n",
            "<!-- START COPY FOR THE GUTS -->\n",
            "\t<table cellpadding=0 cellspacing=0 border=0 width=430 bgcolor=\"#eeeeee\">\n",
            "\t<tr valign=top>\n",
            "\t<td width=10><img src=\"http://home.cnet.com/b.gif\" alt=\"\" width=\"10\" height=\"1\" border=\"0\"><br></td>\n",
            "\t<td width=252>\n",
            "\t<table cellpadding=0 cellspacing=0 border=0 width=252>\n",
            "\t<tr>\n",
            "\t<td><img src=\"http://home.cnet.com/i/ne/ds/itn.gif\" alt=\"In the News\" width=\"68\" height=\"16\" border=\"0\"><br></td>\n",
            "<!-- Date -->\n",
            "\t<td align=right><font face=\"Arial, Helvetica\" size=\"-2\">July 9, 2002</font><br></td>\n",
            "\t</tr>\n",
            "\t</table>\n",
            "\t<img src=\"http://home.cnet.com/b.gif\" alt=\"\" width=\"1\" height=\"6\" border=\"0\"><br>\n",
            "\t<font face=\"Arial, Helvetica\" size=\"-1\">\n",
            "\t <a href=\"#h1\" style=\"text-decoration:none;\"><img src=\"http://home.cnet.com/i/ne/ds/arrow.gif\" alt=\"\" width=\"11\" height=\"9\" border=\"0\"><font color=\"#000000\">\n",
            "Cable companies cracking down on Wi-Fi</font></a><br>\n",
            "\t <a href=\"#h2\" style=\"text-decoration:none;\"><img src=\"http://home.cnet.com/i/ne/ds/arrow.gif\" alt=\"\" width=\"11\" height=\"9\" border=\"0\"><font color=\"#000000\">\n",
            "Apple's iPod comes to Linux</font></a><br>\n",
            "\t <a href=\"#h3\" style=\"text-decoration:none;\"><img src=\"http://home.cnet.com/i/ne/ds/arrow.gif\" alt=\"\" width=\"11\" height=\"9\" border=\"0\"><font color=\"#000000\">\n",
            "Talk of Dell printer move heats up</font></a><br>\n",
            "\t <a href=\"#h4\" style=\"text-decoration:none;\"><img src=\"http://home.cnet.com/i/ne/ds/arrow.gif\" alt=\"\" width=\"11\" height=\"9\" border=\"0\"><font color=\"#000000\">\n",
            "Microsoft eyes Visa users with Passport</font></a><br>\n",
            "\t <a href=\"#h5\" style=\"text-decoration:none;\"><img src=\"http://home.cnet.com/i/ne/ds/arrow.gif\" alt=\"\" width=\"11\" height=\"9\" border=\"0\"><font color=\"#000000\">\n",
            "Judge OKs suit against Kazaa parent</font></a><br>\n",
            "\t <a href=\"#h6\" style=\"text-decoration:none;\"><img src=\"http://home.cnet.com/i/ne/ds/arrow.gif\" alt=\"\" width=\"11\" height=\"9\" border=\"0\"><font color=\"#000000\">\n",
            "China wakes to new destiny</font></a><br>\n",
            "\t\t</td>\n",
            "\t\t<td width=8><img src=\"http://home.cnet.com/b.gif\" alt=\"\" width=\"8\" height=\"1\" border=\"0\"><br></td>\n",
            "\t\t<td width=1 bgcolor=\"#999999\"><img src=\"http://home.cnet.com/b.gif\" alt=\"\" width=\"1\" height=\"1\" border=\"0\"><br></td>\n",
            "\t\t<td width=159>\n",
            "<!-- Promo Area -->\n",
            "\t\t<table cellpadding=0 cellspacing=0 border=0 width=159>\n",
            "\t\t<tr valign=bottom>\n",
            "\t\t\t<td width=\"8\"><img src=\"http://home.cnet.com/b.gif\" alt=\"\" width=\"8\" height=\"1\" border=\"0\"><br></td>\n",
            "\t\t\t<td width=\"8\"><img src=\"http://home.cnet.com/i/ne/ds/bug.gif\" alt=\"\" width=\"8\" height=\"24\" border=\"0\"></td>\n",
            "\t\t\t<td width=\"151\"><font face=\"Arial, Helvetica\">&nbsp;<b>Vision Series</b></font></td>\n",
            "\t\t</tr>\n",
            "\t\t<tr>\n",
            "\t\t\t<td><img src=\"http://home.cnet.com/b.gif\" alt=\"\" width=\"1\" height=\"1\" border=\"0\"></td>\n",
            "\t\t\t<td colspan=2 bgcolor=\"#000000\"><img src=\"http://home.cnet.com/b.gif\" height=1 width=1><br></td>\n",
            "\t\t</tr>\n",
            "\t\t</table>\n",
            "\t\t<table cellpadding=8 cellspacing=0 border=0>\n",
            "\t\t<tr><td>\n",
            "\t\t\t\t<font face=\"Arial, Helvetica\" size=\"-1\">\n",
            "\t\t\tRead News.com's exclusive interviews of 10 top CIOs, including IBM's Phil Thompson.<br>\n",
            "\t\t\t\t<b><a href=\"http://clickthru.online.com/Click?q=b4-aJlbQ6Z1xK4xfxgqJzDxDXozLCdR\" >Vision Series home</a></b><br>\n",
            "\t\t</td></tr>\n",
            "\t\t</table>\n",
            "<!-- /Promo Area -->\n",
            "                                <img src=\"http://home.cnet.com/b.gif\" height=6 width=1><br>\n",
            "                        </td>\n",
            "                        </tr>\n",
            "                        </table>\n",
            "        <!-- Thin grey line -->\n",
            "        <table cellpadding=0 cellspacing=0 border=0 width=430>\n",
            "        <tr valign=top>\n",
            "                <td bgcolor=\"#999999\"><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"1\" border=\"0\"></td>\n",
            "        </tr>\n",
            "        </table>\n",
            "<table cellpadding=10 cellspacing=0 border=0>\n",
            "<tr><td><font face=\"Arial, Helvetica\">\n",
            "<a name=\"h1\"></a>\n",
            "<b>Cable companies cracking down on Wi-Fi</b><br>\n",
            "<font size=\"-1\">\n",
            "Broadband providers are cracking down on popular Wi-Fi networks, threatening to cut service to customers who set up the inexpensive wireless systems and allow others to freely tap into their Internet access.\n",
            "Time Warner Cable of New York City has given 10 customers less than a week to stop using their accounts to provide a wireless local area network available to anyone within 300 feet. The letters are just an initial volley; Time Warner expects to send additional letters, while AT&T Broadband also is preparing similar letters for some of its customers.\n",
            "</font><br>\n",
            "<font size=\"-2\">\n",
            "July 9, 2002, 4:00 AM PT\n",
            "</font> | <font size=\"-1\">\n",
            "<a href=\"http://clickthru.online.com/Click?q=c9-3OZLQpgkU3mw4fgjg0SxiPZvH6cR\" >\n",
            "<b>Read Full Story</b></a></font> <img src=\"http://home.cnet.com/i/ne/ds/right_arrow.gif\" alt=\"\" width=\"9\" height=\"9\" border=\"0\">\n",
            "<P>\n",
            "<a name=\"h2\"><b>Apple's iPod comes to Linux</b></a><br>\n",
            "<font size=\"-1\">\n",
            "Windows users have recently been given access to the popular Macintosh music player, iPod, and now Linux users may soon be able to take a bite out of Apple Computer's gadget. Last week, tex9, a small software-development company in San Francisco, began beta testing an iPod plug-in for its xtunes music player software, which is itself a Linux clone of Apple's iTunes. The plug-in will, tex9 promises, allow drag-and-drop access to iPod, which holds up to 10GB of music.\n",
            "</font><br>\n",
            "<font size=\"-2\">\n",
            "July 9, 2002, 12:00 PM PT\n",
            "</font> | <font size=\"-1\">\n",
            "<a href=\"http://clickthru.online.com/Click?q=df-1kJhQLEFHE_SERofbQq-Kh1XhaZR\" >\n",
            "<b>Read Full Story</b></a></font> <img src=\"http://home.cnet.com/i/ne/ds/right_arrow.gif\" alt=\"\" width=\"9\" height=\"9\" border=\"0\">\n",
            "<p>\n",
            "<a name=\"h3\"><b>Talk of Dell printer move heats up</b></a><br>\n",
            "<font size=\"-1\">\n",
            "Dell Computer appears to be moving toward selling its own printers.\n",
            "A pair of analyst reports issued Tuesday added to a torrent of recent speculation that the Round Rock, Texas-based PC maker's next move will be into the printer market. Dell has plunged into a number of new markets over the past few years.\n",
            "</font><br>\n",
            "<font size=\"-2\">\n",
            "July 9, 2002, 12:30 PM PT</font> | <font size=\"-1\">\n",
            "<a href=\"http://clickthru.online.com/Click?q=f4-Y-XEQ0skGx03lD7uUJ5QddfWmTdR\" >\n",
            "<b>Read Full Story</b></a></font> <img src=\"http://home.cnet.com/i/ne/ds/right_arrow.gif\" alt=\"\" width=\"9\" height=\"9\" border=\"0\">\n",
            "<p>\n",
            "\n",
            "<br>\n",
            "<a name=\"h4\"><b>Microsoft eyes Visa users with Passport</b></a><br>\n",
            "<font size=\"-1\">\n",
            "Microsoft hopes to extend its Passport online identification system into authorizing credit card payments.\n",
            "The software giant will strike a partnership Tuesday with security-software maker Arcot Systems, which builds online payment systems for merchants and for banks that issue Visa and MasterCard credit cards. Arcot makes the systems behind Visa's own Verified by Visa program as well as a similar program in development at MasterCard.\n",
            "</font><br>\n",
            "<font size=\"-2\">\n",
            "July 8, 2002, 9:00 PM PT\n",
            "</font> | <font size=\"-1\">\n",
            "<a href=\"http://clickthru.online.com/Click?q=09-joDSIj88wYrwYd1LYSS7ZMgtY8cR\" >\n",
            "<b>Read Full Story</b></a></font> <img src=\"http://home.cnet.com/i/ne/ds/right_arrow.gif\" alt=\"\" width=\"9\" height=\"9\" border=\"0\">\n",
            "<p>\n",
            "<a name=\"h5\"><b>Judge OKs suit against Kazaa parent</b></a><br>\n",
            "<font size=\"-1\">\n",
            "A federal judge said Monday that record labels and film studios could expand an ongoing copyright lawsuit to include Sharman Networks, which distributes the popular Kazaa software.\n",
            "\n",
            "The Recording Industry Association of America (RIAA) and the Motion Picture Association of America (MPAA) sued three prominent file-swapping companies in October in Los Angeles federal court. The suit named Morpheus parent StreamCast Networks, Grokster and Kazaa BV, the Netherlands-based company that originally created the Kazaa software.\n",
            "</font><br>\n",
            "<font size=\"-2\">\n",
            "July 9, 2002, 12:55 PM PT\n",
            "</font> | <font size=\"-1\">\n",
            "<a href=\"http://clickthru.online.com/Click?q=1e-JQuLI4jWHd57RCeqEsB8LE27qdRR\" >\n",
            "<b>Read Full Story</b></a></font> <img src=\"http://home.cnet.com/i/ne/ds/right_arrow.gif\" alt=\"\" width=\"9\" height=\"9\" border=\"0\">\n",
            "<p>\n",
            "<a name=\"h6\"><b>China wakes to new destiny</b></a><br>\n",
            "<font size=\"-1\">\n",
            "Global slump prompts tech titans to tap the sleeping giant's manufacturing prowess and consumer market.\n",
            "</font><br>\n",
            "<font size=\"-2\">\n",
            "July 9, 2002, 4:00 AM PT\n",
            "</font> | <font size=\"-1\">\n",
            "<a href=\"http://clickthru.online.com/Click?q=33-vUjnINjXKjpwghvz6yClxb-7XsFR\" >\n",
            "<b>Read Full Story</b></a></font> <img src=\"http://home.cnet.com/i/ne/ds/right_arrow.gif\" alt=\"\" width=\"9\" height=\"9\" border=\"0\">\n",
            "<p>\n",
            "<table width=\"100%\" cellpadding=0 cellspacing=0 border=0><tr><td width=\"100%\" valign=bottom>\n",
            "<font face=\"arial, helvetica\" size=\"-1\"><font color=\"#666666\"><b>From our partners:</b></font></td></tr><tr><td colspan=2><img src=\"http://a.r.tv.com/cnet.1d/b.gif\" width=1 height=1 alt=\"\"></td></tr>\n",
            "<tr><td colspan=2 bgcolor=\"#666666\"><img src=\"http://a.r.tv.com/cnet.1d/b.gif\" width=1 height=1 alt=\"\"></td></tr></table>\n",
            "<b>Another big charge for AOL?</b></a><br>\n",
            "<font size=\"-2\">\n",
            "Business Week\n",
            "</font><br>\n",
            "<font size=\"-1\">\n",
            "It may again have billions of excess goodwill on its books, and a write-down won't go over well with already unhappy investors.\n",
            "</font><br>\n",
            "<font size=\"-2\">\n",
            "July 9, 2002\n",
            "</font> | <font size=\"-1\">\n",
            "<a href=\"http://clickthru.online.com/Click?q=48-ggFbIdBsyRC-D3fXl_kj2ZBSJu4R\" >\n",
            "<b>Read Full Story</b></a></font> <img src=\"http://home.cnet.com/i/ne/ds/right_arrow.gif\" alt=\"\" width=\"9\" height=\"9\" border=\"0\">\n",
            "<p>\n",
            "<b>Business needs to take the blinders off</b></a><br>\n",
            "<font size=\"-2\">\n",
            "Business Week\n",
            "</font><br>\n",
            "<font size=\"-1\">\n",
            "Today's corporate apologists are too much like the Marxists who reflexively defended Communism's old poster boy -- Stalin.</font><br>\n",
            "<font size=\"-2\">\n",
            "July 9, 2002\n",
            "</font> | <font size=\"-1\">\n",
            "<a href=\"http://clickthru.online.com/Click?q=5d-JN-bIK0sjRJtwwOobvZm5yGKIaeR\" >\n",
            "<b>Read Full Story</b></a></font> <img src=\"http://home.cnet.com/i/ne/ds/right_arrow.gif\" alt=\"\" width=\"9\" height=\"9\" border=\"0\">\n",
            "<p>\n",
            "<table width=\"100%\" cellpadding=0 cellspacing=0 border=0><tr><td width=\"100%\" valign=bottom>\n",
            "<font face=\"arial, helvetica\" size=\"-1\"><font color=\"#666666\"><b>Also from CNET:</b></font></td></tr><tr><td colspan=2><img src=\"http://a.r.tv.com/cnet.1d/b.gif\" width=1 height=1 alt=\"\"></td></tr>\n",
            "<tr><td colspan=2 bgcolor=\"#666666\"><img src=\"http://a.r.tv.com/cnet.1d/b.gif\" width=1 height=1 alt=\"\"></td></tr></table>\n",
            "<font face=\"arial, helvetica\" size=\"-1\">Real-time stock quotes from CNET News.com Investor.<br>30-day <a href=\"http://clickthru.online.com/Click?q=72-R8PHIPUf0jrNqz0rqMtNXjoCKqyR\" >free trial</a>!</font>\n",
            "        </td>\n",
            "</tr>\n",
            "</table>\n",
            "        </td>\n",
            "</tr>\n",
            "</table>\n",
            "<!-- Video Report -->\n",
            "<table cellpadding=0 cellspacing=0 border=0 width=612>\n",
            "<tr valign=top>\n",
            "        <td width=1 bgcolor=\"#000000\"><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"1\" border=\"0\"></td>\n",
            "        <td width=10 bgcolor=\"#ffcc00\"><img src=\"http://home.cnet.com/b.gif\" width=\"10\" height=\"1\" border=\"0\"></td>\n",
            "        <td width=1 bgcolor=\"#000000\"><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"1\" border=\"0\"></td>\n",
            "        <td width=12 bgcolor=\"#ffffff\"><img src=\"http://home.cnet.com/b.gif\" width=\"12\" height=\"1\" border=\"0\"></td>\n",
            "        <td width=575 bgcolor=\"#ffffff\">\n",
            "<!-- Leads Module -->\n",
            "<img src=\"http://www.cnet.com/i/gl/new-cc.gif\" alt=\"Crucial Clicks\" width=\"120\" height=\"19\" border=\"0\"><br>\n",
            "<table width=\"100%\"  cellpadding=\"0\" cellspacing=\"0\" border=\"0\" bgcolor=\"#ffffff\">\n",
            "<tr bgcolor=\"#cccccc\"><td colspan=\"7\"><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"1\" border=\"0\"></td></tr>\n",
            "<tr>\n",
            "<td bgcolor=\"#cccccc\" rowspan=\"3\"><img src=\"http://home.cnet.com/b.gif\" height=1 width=1></td>\n",
            "<td rowspan=\"3\"><img src=\"http://home.cnet.com/b.gif\" height=1 width=5></td>\n",
            "<td colspan=\"3\"><img src=\"http://home.cnet.com/b.gif\" height=5 width=1></td>\n",
            "<td rowspan=\"3\"><img src=\"http://home.cnet.com/b.gif\" height=1 width=5></td>\n",
            "<td bgcolor=\"#cccccc\" rowspan=\"3\"><img src=\"http://home.cnet.com/b.gif\" height=1 width=1></td>\n",
            "</tr>\n",
            "<tr valign=\"top\">\n",
            "<td width=\"100%\">\n",
            "<table width=\"100%\"  cellpadding=\"0\" cellspacing=\"0\" border=\"0\">\n",
            "<tr valign=\"top\">\n",
            "<td width=\"85\"><a href=\"http://clickthru.online.com/Click?q=88-ec5PQQKx6IEe4UY-rU358atSBb9R\" ><img src=\"http://a.r.tv.com/cnet.1d/i/pg/021502_pointcamera.jpg\" width=\"85\" height=\"110\" border=\"0\" alt=\"\" /></a></td>\n",
            "<td width=\"5\"><img src=\"http://home.cnet.com/b.gif\" height=1 width=5></td>\n",
            "<td width=\"100%\"><font face=\"arial, helvetica\" size=\"-1\">\n",
            "<a href=\"http://clickthru.online.com/Click?q=9d-kkCWQv0umM4zedRuKLvd75wKZzuR\" ><b>Digicams for summer shutterbugs</b></a><br />Going on vacation, or just headed to the beach? Indulge your summer snapshot habit with one of our picks.</font></td>\n",
            "</tr>\n",
            "<tr><td colspan=\"3\"><img src=\"http://home.cnet.com/b.gif\" height=3 width=1><br /><font face=\"arial, helvetica\" size=\"-1\">\n",
            "&#149; <a href=\"http://clickthru.online.com/Click?q=b2-M4pwQX0a3ZhfzqvjM2cmpxUCPusR\" >5-megapixel shoot-out</a><br />\n",
            "&#149; <a href=\"http://clickthru.online.com/Click?q=c7-KG43QLPWxessB4vNWtUoF24wxeZR\" >Leica Digilux 1: street shooter\"s digicam</a><br />\n",
            "</font></td></tr>\n",
            "</table>\n",
            "</td>\n",
            "<td><img src=\"http://home.cnet.com/b.gif\" height=1 width=5></td>\n",
            "<td width=\"180\">\n",
            "<table cellpadding=\"0\" cellspacing=\"0\" width=\"180\" border=\"0\" bgcolor=\"#ffffef\">\n",
            "<tr><td colspan=\"5\" bgcolor=\"#666666\"><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"1\" alt=\"\" border=\"0\" /></td></tr>\n",
            "<tr>\n",
            "<td bgcolor=\"#666666\"><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"1\" alt=\"\" border=\"0\" /></td>\n",
            "<td><img src=\"http://home.cnet.com/b.gif\" width=\"10\" height=\"1\" alt=\"\" border=\"0\" /></td>\n",
            "<td><font face=\"ms sans serif, geneva\" size=\"-2\"><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"5\" alt=\"\" border=\"0\" /><br />\n",
            "<font face=\"arial, helvetica\" color=\"#666666\" size=\"-1\"><b>Most popular products</b></font><br /><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"5\" alt=\"\" border=\"0\" /><br />\n",
            "<b>Digital cameras</b><br /><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"7\" alt=\"\" border=\"0\" /><br />\n",
            "1. <a href=\"http://clickthru.online.com/Click?q=dc-40zzQ0Lr5OhlQXYBz6gEwTinhldR\" >Canon PowerShot G2</a><br /><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"3\" alt=\"\" border=\"0\" /><br />\n",
            "2. <a href=\"http://clickthru.online.com/Click?q=f2-OZVTQUwWCeN3O_A0pvVdi5Z7edsR\" >Canon PowerShot S40</a><br /><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"3\" alt=\"\" border=\"0\" /><br />\n",
            "3. <a href=\"http://clickthru.online.com/Click?q=07-HqCzI5rq9TCgh8KiqzUbrvLkiDZR\" >Canon PowerShot S30</a><br /><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"3\" alt=\"\" border=\"0\" /><br />\n",
            "4. <a href=\"http://clickthru.online.com/Click?q=1c-cs_iIFr43mNlgPjn9kgGa2oXqGdR\" >Canon PowerShot A40</a><br /><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"3\" alt=\"\" border=\"0\" /><br />\n",
            "5. <a href=\"http://clickthru.online.com/Click?q=31-V_YRIjMsD0vB7ayyLxjkqVAXXbcR\" >Nikon Coolpix 995</a><br /><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"6\" alt=\"\" border=\"0\" /><br />\n",
            "<img src=\"http://a.r.tv.com/cnet.1d/i/fd/yl_arrow.gif\" width=\"13\" height=\"13\" border=\"0\" alt=\"\" align=\"absmiddle\" /> <b><a href=\"http://clickthru.online.com/Click?q=46-19zwInpDSNGQ8sta1cN0535V0YiR\" >See all most popular cameras</a></b><br />\n",
            "<img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"10\" alt=\"\" border=\"0\" /><br />\n",
            "</font></td>\n",
            "<td><img src=\"http://home.cnet.com/b.gif\" width=\"10\" height=\"1\" alt=\"\" border=\"0\" /></td>\n",
            "<td bgcolor=\"#666666\"><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"1\" alt=\"\" border=\"0\" /></td>\n",
            "</tr>\n",
            "<tr><td colspan=\"5\" bgcolor=\"#666666\"><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"1\" alt=\"\" border=\"0\" /></td></tr>\n",
            "</table>\n",
            "</td>\n",
            "</tr>\n",
            "<tr valign=\"top\"><td colspan=\"3\"><img src=\"http://home.cnet.com/b.gif\" height=5 width=1></td></tr>\n",
            "<tr><td colspan=\"7\" bgcolor=\"#cccccc\"><img src=\"http://home.cnet.com/b.gif\" height=1 width=1></td></tr>\n",
            "</table><br />\n",
            "<!-- /Leads Module -->\n",
            "<p>\n",
            "        <font face=\"Arial, Helvetica\" size=\"-1\">&nbsp;<Br>\n",
            "        <table cellpadding=0 cellspacing=0 border=0 width=560>\n",
            "                <tr>\n",
            "                        <td rowspan=3 width=175><img src=\"http://home.cnet.com/i/ne/ds/sub-vidreport.gif\" alt=\"\" width=\"175\" height=\"25\" border=\"0\"></td>\n",
            "                        <td width=385><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"21\" border=\"0\"><br></td>\n",
            "                </tr>\n",
            "                <tr>\n",
            "                        <td bgcolor=\"#cccccc\"><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"1\" border=\"0\"><br></td>\n",
            "                </tr>\n",
            "                <tr>\n",
            "                        <td><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"3\" border=\"0\"><br></td>\n",
            "                </tr>\n",
            "        </table>\n",
            "        <table cellpadding=0 cellspacing=0 border=0 width=560>\n",
            "                <tr valign=top>\n",
            "                        <td><img src=\"http://news.cnet.com/i/ne/bb/2002/07/0708_netscape7.jpg\" alt=\"\" width=\"96\" height=\"72\" border=\"0\"></td>\n",
            "                        <td><img src=\"http://home.cnet.com/b.gif\" width=\"10\" height=\"1\" border=\"0\"><br></td>\n",
            "                        <td><font face=\"Arial, Helvetica\" size=\"-1\">\n",
            "                        <b><font size=\"+0\"><a href=\"http://clickthru.online.com/Click?q=5b-5LOwIBKDUXrvYmoxCjjvDSwizzlR\" >Netscape 7: How does it stack up?</a></font></b><br>\n",
            "CNET Download.com's Rex Baldazo previews Netscape 7, a new open-source version of the browser that the company hopes will chip away at Microsoft's leading position with Internet Explorer.<br>\n",
            "                        <a href=\"http://clickthru.online.com/Click?q=70-3vnJIdp6VDyyOjYKns2asfI8Uk4R\" ><img src=\"http://news.cnet.com/i/gl/vid-w.gif\" width=24 height=18 border=0 hspace=3 align=top></a> <a href=\"http://clickthru.online.com/Click?q=85-2G2oQ7KQfSBryiQaf70SVbToBBuR\" ><b>Watch Video</b></a><br>\n",
            "</tr>\n",
            "</table>\n",
            "&nbsp;<br>\n",
            "</td>\n",
            "<td width=12 bgcolor=\"#ffffff\"><img src=\"http://home.cnet.com/b.gif\" width=\"12\" height=\"1\" border=\"0\"><br></td>\n",
            "        <td width=1 bgcolor=\"#000000\"><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"1\" border=\"0\"></td>\n",
            "</tr>\n",
            "</table>\n",
            "<!-- /Video Report -->\n",
            "<!-- News by Section -->\n",
            "<table cellpadding=0 cellspacing=0 border=0 width=612>\n",
            "<tr valign=top>\n",
            "        <td width=1 bgcolor=\"#000000\"><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"1\" border=\"0\"></td>\n",
            "        <td width=10 bgcolor=\"#ffcc00\"><img src=\"http://home.cnet.com/b.gif\" width=\"10\" height=\"1\" border=\"0\"></td>\n",
            "        <td width=1 bgcolor=\"#000000\"><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"1\" border=\"0\"></td>\n",
            "        <td width=587 bgcolor=\"#ffffff\">\n",
            "        <font face=\"Arial, Helvetica\" size=\"-1\">&nbsp;<Br>\n",
            "        <table cellpadding=0 cellspacing=0 border=0 width=572>\n",
            "                <tr>\n",
            "                        <td rowspan=3 width=12><img src=\"http://home.cnet.com/b.gif\" width=\"12\" height=\"1\" border=\"0\"><br></td>\n",
            "                        <td rowspan=3 width=175><img src=\"http://home.cnet.com/i/ne/ds/sub-bysection.gif\" alt=\"\" width=\"175\" height=\"25\" border=\"0\"></td>\n",
            "                        <td width=385><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"21\" border=\"0\"><br></td>\n",
            "                </tr>\n",
            "                <tr>\n",
            "                        <td bgcolor=\"#cccccc\"><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"1\" border=\"0\"><br></td>\n",
            "                </tr>\n",
            "                <tr>\n",
            "                        <td><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"3\" border=\"0\"><br></td>\n",
            "                </tr>\n",
            "        </table>\n",
            "        <table width=\"572\" cellpadding=\"0\" cellspacing=\"0\" border=\"0\">\n",
            "        <tr valign=\"top\">\n",
            "                <td width=\"286\"><font face=\"arial, helvetica\" size =\"-1\">\n",
            "                        <ul>\n",
            "                        <b>Enterprise</b><br>\n",
            "                        <li><a href=\"http://clickthru.online.com/Click?q=9a-b6_GQTMBGY_mw61Figi7yr9FKgsR\" >\n",
            "Shares in chip gear fall on new fears</a>\n",
            "                        <li><a href=\"http://clickthru.online.com/Click?q=af--dB8QLpqkx4VuLSydDX7NdmUVSZR\" >\n",
            "Dell douses Lexmark speculation</a>\n",
            "                        <li><a href=\"http://clickthru.online.com/Click?q=c5-8BcDQzOaF-FWAk_zSROUJEymxquR\" >\n",
            "Microsoft tests dressed up Web software</a>\n",
            "                        </ul>\n",
            "                </font>\n",
            "                </td>\n",
            "                <td width=\"286\"><font face=\"arial, helvetica\" size =\"-1\">\n",
            "                        <ul>\n",
            "                        <b>E-Business</b><br>\n",
            "                        <li><a href=\"http://clickthru.online.com/Click?q=da-dT8jQUPq_nEl9djbjsMVKpv3DxsR\" >\n",
            "Stocks edge lower after Bush speech</a>\n",
            "                        <li><a href=\"http://clickthru.online.com/Click?q=ef-04uYQmkHvF0v1HKqBxDVAmoBamZR\" >\n",
            "Bush talks tough on corporate fraud</a>\n",
            "                        <li><a href=\"http://clickthru.online.com/Click?q=04-k9W0IFQXFQfKUsA98BbBL7kOi_dR\" >\n",
            "Vignette's forecast dips on demand woes</a>\n",
            "                        </ul>\n",
            "                </font>\n",
            "                </td>\n",
            "        </tr>\n",
            "        <tr valign=\"top\">\n",
            "                <td width=\"286\"><font face=\"arial, helvetica\" size =\"-1\">\n",
            "                        <ul>\n",
            "                        <b>Communications</b><br>\n",
            "                        <li><a href=\"http://clickthru.online.com/Click?q=19-BLe0I2rXOrYLMLlKMZ2Fz8IR7XcR\" >\n",
            "WorldCom: The clock is ticking</a>\n",
            "                        <li><a href=\"http://clickthru.online.com/Click?q=2e-eMTGIiK8vtN8WxMktQ3DlPfP8NRR\" >\n",
            "Deutsche Telekom up on CEO talks</a>\n",
            "                        <li><a href=\"http://clickthru.online.com/Click?q=43-coL5IBJAEmvf_rv9Z5VKc-3P0BlR\" >\n",
            "NTT DoCoMo tries new 3G twist</a>\n",
            "                        </ul>\n",
            "                </font>\n",
            "                </td>\n",
            "                <td width=\"286\"><font face=\"arial, helvetica\" size =\"-1\">\n",
            "                        <ul>\n",
            "                        <b>Media</b><br>\n",
            "                        <li><a href=\"http://clickthru.online.com/Click?q=58-mr2xIdJHwWFD9MHYjKHbtbXYzH4R\" >\n",
            "Vivendi units harmonize in digital deal</a>\n",
            "                        <li><a href=\"http://clickthru.online.com/Click?q=6d-e8plIDEIKwv_1pH7Bc1bJBykEmeR\" >\n",
            "AOL Time Warner secures new credit</a>\n",
            "                        <li><a href=\"http://clickthru.online.com/Click?q=82-P0EYQXK1SVsULUc6gJLkjCXMZHsR\" >\n",
            "Banks bail out Vivendi with loans</a>\n",
            "                        </ul>\n",
            "                </font>\n",
            "                </td>\n",
            "       </tr>\n",
            "        <tr valign=\"top\">\n",
            "                <td width=\"286\"><font face=\"arial, helvetica\" size =\"-1\">\n",
            "                        <ul>\n",
            "                       <b>Personal Technology</b><br>\n",
            "                        <li><a href=\"http://clickthru.online.com/Click?q=97-dlfYQ1M1UyTjJsQ3V0z6qjySJGZR\" >\n",
            "It ain't heavy; it's my laptop</a>\n",
            "                        <li><a href=\"http://clickthru.online.com/Click?q=ad-_4IAQzEB45rLNHcQhaIHsSzky0uR\" >\n",
            "Matsushita: Chip unit headed toward black</a>\n",
            "                        <li><a href=\"http://clickthru.online.com/Click?q=c2-oXxLQUEk7TCKoi9gVnxXFZcIuIsR\" >\n",
            "French game maker up on Sega rumors</a>\n",
            "                        </ul>\n",
            "                </font>\n",
            "                </td>\n",
            "                <td width=\"286\"><font face=\"arial, helvetica\" size =\"-1\">\n",
            "                        </font>\n",
            "                </td>\n",
            "        </tr>\n",
            "        </table>\n",
            "<!-- END COPY FOR THE GUTS -->\n",
            "        &nbsp;<br>\n",
            "        </td>\n",
            "        <td width=12 bgcolor=\"#ffffff\"><img src=\"http://home.cnet.com/b.gif\" width=\"12\" height=\"1\" border=\"0\"><br></td>\n",
            "        <td width=1 bgcolor=\"#000000\"><img src=\"http://home.cnet.com/b.gif\" width=\"1\" height=\"1\" border=\"0\"></td>\n",
            "</tr>\n",
            "</table>\n",
            "<!-- ### footer ### -->\n",
            "<table width=\"612\" bgcolor=\"#000000\" cellpadding=\"0\" cellspacing=\"0\" border=\"0\">\n",
            "<tr><td width=\"1\"><img src=\"http://www.cnet.com/b.gif\" width=\"1\" height=\"1\"></td>\n",
            "<td width=\"10\" bgcolor=\"#ffcc00\"><img src=\"http://www.cnet.com/b.gif\" width=\"10\" height=\"1\"></td>\n",
            "<td width=\"1\"><img src=\"http://www.cnet.com/b.gif\" width=\"1\" height=\"1\"></td>\n",
            "<td width=\"599\" bgcolor=\"#cccccc\"><img src=\"http://www.cnet.com/b.gif\" width=\"1\" height=\"1\"></td>\n",
            "<td width=\"1\"><img src=\"http://www.cnet.com/b.gif\" width=\"1\" height=\"1\"></td></tr>\n",
            "</table>\n",
            "<table width=\"612\" bgcolor=\"#eeeeee\" cellpadding=\"0\" cellspacing=\"0\" border=\"0\">\n",
            "<tr><td width=\"1\" bgcolor=\"#000000\"><img src=\"http://www.cnet.com/b.gif\" width=\"1\" height=\"1\"></td>\n",
            "<td width=\"10\" bgcolor=\"#ffcc00\"><img src=\"http://www.cnet.com/b.gif\" width=\"10\" height=\"1\"></td>\n",
            "<td width=\"1\" bgcolor=\"#000000\"><img src=\"http://www.cnet.com/b.gif\" width=\"1\" height=\"1\"></td>\n",
            "<td width=\"12\"><img src=\"http://www.cnet.com/b.gif\" width=\"12\" height=\"1\"></td>\n",
            "<td width=\"575\"><img src=\"http://www.cnet.com/b.gif\" width=\"1\" height=\"10\"><br>\n",
            "<a href=\"http://clickthru.online.com/Click?q=d7-wk3ZQLWkVTpPDzlRmBekeVktk2ZR\" ><img src=\"http://a.r.tv.com/cnet.1d/i/nl/ft.gif\" width=\"375\" height=\"18\" border=\"0\" alt=\"Sign up for more free newsletters from CNET!\"></a><p>\n",
            "<!-- subscription management -->\n",
            "\n",
            "<font face=\"ms sans serif, geneva\" size=\"-2\">\n",
            "The e-mail address for your subscription is&nbsp;qqqqqqqqqq-cnet-newsletters@example.com<br>\n",
            "<A NOTRACK HREF='http://clickthru.online.com/Click?q=ec-MHlXray63gwtHPxvVqBAYENOGKW9jRRR'>Unsubscribe</A>&nbsp;|&nbsp;<a href='http://nl.com.com/servlet/url_login?email=qqqqqqqqqq-cnet-newsletters@example.com&brand=cnet'>Manage My Subscriptions</a>&nbsp;|&nbsp;<a href=\"http://clickthru.online.com/Click?q=01-9oXDI2jHgOhG8rMvurMPGPxZ6RcR\" >FAQ</A>&nbsp;|&nbsp;<a href=\"http://clickthru.online.com/Click?q=16-T_cjI4cFV5ruiQADblRuaBDxRURR\" >Advertise</A><p>Please send any questions, comments, or concerns to&nbsp;<a href=\"mailto:dispatchfeedback@news.com\">dispatchfeedback@news.com</A>.<br></font>\n",
            "<!-- /subscription management-->\n",
            "</font><img src=\"http://www.zdnet.com/b.gif\" width=\"1\" height=\"8\"></td>\n",
            "<td width=\"12\"><img src=\"http://www.cnet.com/b.gif\" width=\"12\" height=\"1\"></td>\n",
            "<td width=\"1\" bgcolor=\"#000000\"><img src=\"http://www.cnet.com/b.gif\" width=\"1\" height=\"1\"></td></tr>\n",
            "</table>\n",
            "<table width=\"612\" bgcolor=\"#000000\" cellpadding=\"0\" cellspacing=\"0\" border=\"0\">\n",
            "<tr><td width=\"1\"><img src=\"http://www.cnet.com/b.gif\" width=\"1\" height=\"1\"></td>\n",
            "<td width=\"10\" bgcolor=\"#ffcc00\"><img src=\"http://www.cnet.com/b.gif\" width=\"10\" height=\"1\"></td>\n",
            "<td width=\"601\"><img src=\"http://www.cnet.com/b.gif\" width=\"1\" height=\"1\"></td></tr>\n",
            "</table>\n",
            "<table width=\"612\" bgcolor=\"#ffcc00\" cellpadding=\"0\" cellspacing=\"0\" border=\"0\">\n",
            "<tr><td width=\"1\" bgcolor=\"#000000\"><img src=\"http://www.cnet.com/b.gif\" width=\"1\" height=\"1\"></td>\n",
            "<td width=\"10\"><img src=\"http://www.cnet.com/b.gif\" width=\"10\" height=\"1\"></td>\n",
            "<td width=\"37\"><a href=\"http://clickthru.online.com/Click?q=2b-2FVYINzsBKYmzY1wzk0xBfd-8WFR\" ><img src=\"http://www.cnet.com/i/dp/smrb.gif\" width=\"37\" height=\"37\" border=\"0\"></a></td>\n",
            "<td width=\"563\" nowrap><font face=\"arial, helvetica\" size=\"-1\">\n",
            "<a href=\"http://clickthru.online.com/Click?q=41-qqJ1IEKImGNYE8fU5CfCkxHB0FrR\" ><font color=\"#000000\">Price comparisons</font></a> |\n",
            "<a href=\"http://clickthru.online.com/Click?q=56-NwKYInns9YfTpcErctPQDwwaMCiR\" ><font color=\"#000000\">Product reviews</font></a> |\n",
            "<a href=\"http://clickthru.online.com/Click?q=6b-8g5ZIHEcwxylgIK80ywQ-4d0P6lR\" ><font color=\"#000000\">Tech news</font></a> |\n",
            "<a href=\"http://clickthru.online.com/Click?q=80-KTKvQQ0KilA5FaIoaDkjVsTLZ89R\" ><font color=\"#000000\">Downloads</font></a> |\n",
            "<a href=\"http://clickthru.online.com/Click?q=95-XdwrQvdJolMF9lor1yZeU_u_KnuR\" ><font color=\"#000000\">All CNET services</font></a>\n",
            "</font></td>\n",
            "<td width=\"1\" bgcolor=\"#000000\"><img src=\"http://www.cnet.com/b.gif\" width=\"1\" height=\"1\"></td></tr>\n",
            "</table>\n",
            "<table width=\"612\" cellpadding=\"0\" cellspacing=\"0\" border=\"0\">\n",
            "<tr><td bgcolor=\"#000000\"><img src=\"http://www.cnet.com/b.gif\" width=\"1\" height=\"1\"></td></tr>\n",
            "<tr><td height=\"25\"><font face=\"ms sans serif, geneva\" size=\"-2\"><table width=100% border=0 cellspacing=2 cellpadding=1> <tr valign=bottom> <td width=75% height=31> <p></font> <br><b><font face=Arial, Helvetica, sans-serif size=2>    Copyright 2002 CNET Networks, Inc. All rights reserved.    </font></b> </p></td><td height=31 valign=top> <div align=right> <img src=\"http://gserv-cnet.zdnet.com/clear/outbound.gif?APPID=2&EMID=25136487&NL=e433&ISSUE=2002-07-09\" height=1 width=1>    </div></td></tr><tr>  <td colspan=2><font face=Arial, Helvetica, sans-serif size=2>    </font></td></tr></table></td></tr>\n",
            "</table>\n",
            "<!-- ### /footer ### -->\n",
            "</body>\n",
            "</html>\n",
            "<IMG HEIGHT=1 WIDTH=1 SRC=\"http://clickthru.online.com/Click?q=aa-gBae-hU-_tfD2LsnEUuZc5Hbw9RR\">\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8irNtLcige5",
        "outputId": "d60b0752-d826-4386-95ae-04e921bce7d2"
      },
      "source": [
        "print(ham_emails[0].get_content().strip())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Date:        Wed, 21 Aug 2002 10:54:46 -0500\n",
            "    From:        Chris Garrigues <cwg-dated-1030377287.06fa6d@DeepEddy.Com>\n",
            "    Message-ID:  <1029945287.4797.TMDA@deepeddy.vircio.com>\n",
            "\n",
            "\n",
            "  | I can't reproduce this error.\n",
            "\n",
            "For me it is very repeatable... (like every time, without fail).\n",
            "\n",
            "This is the debug log of the pick happening ...\n",
            "\n",
            "18:19:03 Pick_It {exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace} {4852-4852 -sequence mercury}\n",
            "18:19:03 exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace 4852-4852 -sequence mercury\n",
            "18:19:04 Ftoc_PickMsgs {{1 hit}}\n",
            "18:19:04 Marking 1 hits\n",
            "18:19:04 tkerror: syntax error in expression \"int ...\n",
            "\n",
            "Note, if I run the pick command by hand ...\n",
            "\n",
            "delta$ pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace  4852-4852 -sequence mercury\n",
            "1 hit\n",
            "\n",
            "That's where the \"1 hit\" comes from (obviously).  The version of nmh I'm\n",
            "using is ...\n",
            "\n",
            "delta$ pick -version\n",
            "pick -- nmh-1.0.4 [compiled on fuchsia.cs.mu.OZ.AU at Sun Mar 17 14:55:56 ICT 2002]\n",
            "\n",
            "And the relevant part of my .mh_profile ...\n",
            "\n",
            "delta$ mhparam pick\n",
            "-seq sel -list\n",
            "\n",
            "\n",
            "Since the pick command works, the sequence (actually, both of them, the\n",
            "one that's explicit on the command line, from the search popup, and the\n",
            "one that comes from .mh_profile) do get created.\n",
            "\n",
            "kre\n",
            "\n",
            "ps: this is still using the version of the code form a day ago, I haven't\n",
            "been able to reach the cvs repository today (local routing issue I think).\n",
            "\n",
            "\n",
            "\n",
            "_______________________________________________\n",
            "Exmh-workers mailing list\n",
            "Exmh-workers@redhat.com\n",
            "https://listman.redhat.com/mailman/listinfo/exmh-workers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRWAIOVOizQ4",
        "outputId": "36fd6fbd-6263-4f51-9974-507cfd93d38f"
      },
      "source": [
        "print(ham_emails[6].get_content().strip())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Scotsman - 22 August 2002\n",
            "\n",
            " Playboy wants to go out with a bang \n",
            " \n",
            " \n",
            " AN AGEING Berlin playboy has come up with an unusual offer to lure women into\n",
            " his bed - by promising the last woman he sleeps with an inheritance of 250,000\n",
            " (£160,000). \n",
            " \n",
            " Rolf Eden, 72, a Berlin disco owner famous for his countless sex partners,\n",
            " said he could imagine no better way to die than in the arms of an attractive\n",
            " young woman - preferably under 30. \n",
            " \n",
            " \"I put it all in my last will and testament - the last woman who sleeps with\n",
            " me gets all the money,\" Mr Eden told Bild newspaper. \n",
            " \n",
            " \"I want to pass away in the most beautiful moment of my life. First a lot of\n",
            " fun with a beautiful woman, then wild sex, a final orgasm - and it will all\n",
            " end with a heart attack and then Im gone.\" \n",
            " \n",
            " Mr Eden, who is selling his nightclub this year, said applications should be\n",
            " sent in quickly because of his age. \"It could end very soon,\" he said.\n",
            "\n",
            "\n",
            "------------------------ Yahoo! Groups Sponsor ---------------------~-->\n",
            "4 DVDs Free +s&p Join Now\n",
            "http://us.click.yahoo.com/pt6YBB/NXiEAA/mG3HAA/7gSolB/TM\n",
            "---------------------------------------------------------------------~->\n",
            "\n",
            "To unsubscribe from this group, send an email to:\n",
            "forteana-unsubscribe@egroups.com\n",
            "\n",
            " \n",
            "\n",
            "Your use of Yahoo! Groups is subject to http://docs.yahoo.com/info/terms/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLa9mw6-Z5Ev",
        "outputId": "389e9277-a325-45d1-a144-2f6809bbe6b8"
      },
      "source": [
        "# Combine hard ham and easy ham\n",
        "# Shuffle list\n",
        "import random\n",
        "\n",
        "ham_emails.extend(hard_ham_emails)\n",
        "random.shuffle(ham_emails)\n",
        "len(ham_emails)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2750"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiVSV63Glh2W"
      },
      "source": [
        "# Get email structure\n",
        "def get_email_structure(email):\n",
        "  if isinstance(email, str):\n",
        "    return email\n",
        "  payload = email.get_payload()\n",
        "  if isinstance(payload, list):\n",
        "    return \"multipart({})\".format(\", \".join([\n",
        "        get_email_structure(sub_email)\n",
        "        for sub_email in payload\n",
        "    ]))\n",
        "  else:\n",
        "    return email.get_content_type()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ciHcjdfnC1o"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "def structures_counter(emails):\n",
        "  structures = Counter()\n",
        "  for email in emails:\n",
        "    structure = get_email_structure(email)\n",
        "    structures[structure] += 1\n",
        "  return structures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LgHXeZXnuOx",
        "outputId": "5c26be15-05aa-4859-b489-069be5694082"
      },
      "source": [
        "structures_counter(ham_emails).most_common()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('text/plain', 2494),\n",
              " ('text/html', 120),\n",
              " ('multipart(text/plain, application/pgp-signature)', 66),\n",
              " ('multipart(text/plain, text/html)', 46),\n",
              " ('multipart(text/plain, text/plain)', 4),\n",
              " ('multipart(text/plain)', 3),\n",
              " ('multipart(text/html)', 2),\n",
              " ('multipart(text/plain, application/x-pkcs7-signature)', 2),\n",
              " ('multipart(text/plain, application/octet-stream)', 2),\n",
              " ('multipart(text/plain, image/bmp)', 1),\n",
              " ('multipart(text/plain, application/x-java-applet)', 1),\n",
              " ('multipart(multipart(text/plain, text/html))', 1),\n",
              " ('multipart(text/plain, multipart(text/plain))', 1),\n",
              " ('multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(text/plain, application/x-pkcs7-signature)))',\n",
              "  1),\n",
              " ('multipart(text/plain, application/ms-tnef, text/plain)', 1),\n",
              " ('multipart(text/plain, multipart(text/plain, text/plain), text/rfc822-headers)',\n",
              "  1),\n",
              " ('multipart(text/plain, image/png, image/png)', 1),\n",
              " ('multipart(text/plain, video/mng)', 1),\n",
              " ('multipart(text/plain, text/enriched)', 1),\n",
              " ('multipart(multipart(text/plain, text/plain, text/plain), application/pgp-signature)',\n",
              "  1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sphHL4Xbn4N6",
        "outputId": "2e0b8bfd-9933-46fb-826f-b6ad78c7c804"
      },
      "source": [
        "structures_counter(spam_emails).most_common()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('text/plain', 218),\n",
              " ('text/html', 183),\n",
              " ('multipart(text/plain, text/html)', 45),\n",
              " ('multipart(text/html)', 20),\n",
              " ('multipart(text/plain)', 19),\n",
              " ('multipart(multipart(text/html))', 5),\n",
              " ('multipart(text/plain, image/jpeg)', 3),\n",
              " ('multipart(text/html, application/octet-stream)', 2),\n",
              " ('multipart(text/plain, application/octet-stream)', 1),\n",
              " ('multipart(text/html, text/plain)', 1),\n",
              " ('multipart(multipart(text/html), application/octet-stream, image/jpeg)', 1),\n",
              " ('multipart(multipart(text/plain, text/html), image/gif)', 1),\n",
              " ('multipart/alternative', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OjesitvoK51"
      },
      "source": [
        "###Notes\n",
        "Ham emails are mostly plain text while spam is mostly HTML<br>\n",
        "None of the spam emails are signed with PGP whereas ham emails aren't"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YCUKWdaoCAP",
        "outputId": "6b9e5c46-c8da-43c1-9797-769af1e97520"
      },
      "source": [
        "# Check email headers\n",
        "for header, value in spam_emails[0].items():\n",
        "  print(header,\":\",value)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Return-Path : <12a1mailbot1@web.de>\n",
            "Delivered-To : zzzz@localhost.spamassassin.taint.org\n",
            "Received : from localhost (localhost [127.0.0.1])\tby phobos.labs.spamassassin.taint.org (Postfix) with ESMTP id 136B943C32\tfor <zzzz@localhost>; Thu, 22 Aug 2002 08:17:21 -0400 (EDT)\n",
            "Received : from mail.webnote.net [193.120.211.219]\tby localhost with POP3 (fetchmail-5.9.0)\tfor zzzz@localhost (single-drop); Thu, 22 Aug 2002 13:17:21 +0100 (IST)\n",
            "Received : from dd_it7 ([210.97.77.167])\tby webnote.net (8.9.3/8.9.3) with ESMTP id NAA04623\tfor <zzzz@spamassassin.taint.org>; Thu, 22 Aug 2002 13:09:41 +0100\n",
            "From : 12a1mailbot1@web.de\n",
            "Received : from r-smtp.korea.com - 203.122.2.197 by dd_it7  with Microsoft SMTPSVC(5.5.1775.675.6);\t Sat, 24 Aug 2002 09:42:10 +0900\n",
            "To : dcek1a1@netsgo.com\n",
            "Subject : Life Insurance - Why Pay More?\n",
            "Date : Wed, 21 Aug 2002 20:31:57 -1600\n",
            "MIME-Version : 1.0\n",
            "Message-ID : <0103c1042001882DD_IT7@dd_it7>\n",
            "Content-Type : text/html; charset=\"iso-8859-1\"\n",
            "Content-Transfer-Encoding : quoted-printable\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "G_7KE3DvpPyC",
        "outputId": "ddc79a94-437b-4d87-fed5-bb5875bf188c"
      },
      "source": [
        "spam_emails[0][\"Subject\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Life Insurance - Why Pay More?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC-yKPs6paL6"
      },
      "source": [
        "# Split dataset into train and test\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = np.array(ham_emails + spam_emails, dtype=object)\n",
        "y = np.array([0] * len(ham_emails) + [1] * len(spam_emails))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5lRycrFqmPu"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otkQKxfiquvL"
      },
      "source": [
        "1. Convert HTML to plain text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bY-33Q_mqJvY"
      },
      "source": [
        "# Drop head tag\n",
        "# Convert <a> to HYPERLINK\n",
        "# Get rid of all HTML tags\n",
        "# Replace multiple newines with single newlines\n",
        "# Unescape html entities\n",
        "import re\n",
        "from html import unescape\n",
        "\n",
        "def html_to_plain_text(html):\n",
        "  text = re.sub('<head.*?>.*?</head>', '', html, flags=re.M | re.S | re.I)\n",
        "  text = re.sub('<a\\s.*?>', ' HYPERLINK ', text, flags=re.M | re.S | re.I)\n",
        "  text = re.sub('<.*?>', '', text, flags=re.M | re.S)\n",
        "  text = re.sub(r'(\\s*\\n)+', '\\n', text, flags=re.M | re.S)\n",
        "  return unescape(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ibt1f7gt4pa",
        "outputId": "93936e54-f8d9-4edd-8f3a-b1158597440b"
      },
      "source": [
        "# Test to plain text\n",
        "html_spam_emails = [email for email in X_train[y_train==1] if get_email_structure(email) == \"text/html\"]\n",
        "sample_html_spam = html_spam_emails[0]\n",
        "print(sample_html_spam.get_content().strip()[:1000], \"...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<HTML><HEAD><TITLE></TITLE><META http-equiv=\"Content-Type\" content=\"text/html; charset=windows-1252\"><STYLE>A:link {TEX-DECORATION: none}A:active {TEXT-DECORATION: none}A:visited {TEXT-DECORATION: none}A:hover {COLOR: #0033ff; TEXT-DECORATION: underline}</STYLE><META content=\"MSHTML 6.00.2713.1100\" name=\"GENERATOR\"></HEAD>\n",
            "<BODY text=\"#000000\" vLink=\"#0033ff\" link=\"#0033ff\" bgColor=\"#CCCC99\"><TABLE borderColor=\"#660000\" cellSpacing=\"0\" cellPadding=\"0\" border=\"0\" width=\"100%\"><TR><TD bgColor=\"#CCCC99\" valign=\"top\" colspan=\"2\" height=\"27\">\n",
            "<font size=\"6\" face=\"Arial, Helvetica, sans-serif\" color=\"#660000\">\n",
            "<b>OTC</b></font></TD></TR><TR><TD height=\"2\" bgcolor=\"#6a694f\">\n",
            "<font size=\"5\" face=\"Times New Roman, Times, serif\" color=\"#FFFFFF\">\n",
            "<b>&nbsp;Newsletter</b></font></TD><TD height=\"2\" bgcolor=\"#6a694f\"><div align=\"right\"><font color=\"#FFFFFF\">\n",
            "<b>Discover Tomorrow's Winners&nbsp;</b></font></div></TD></TR><TR><TD height=\"25\" colspan=\"2\" bgcolor=\"#CCCC99\"><table width=\"100%\" border=\"0\"  ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ikt5jG1Gu8D_",
        "outputId": "303aa763-dca9-4f5d-ce1c-fada6c36acfe"
      },
      "source": [
        "print(html_to_plain_text(sample_html_spam.get_content())[:1000], \"...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "OTC\n",
            " Newsletter\n",
            "Discover Tomorrow's Winners \n",
            "For Immediate Release\n",
            "Cal-Bay (Stock Symbol: CBYI)\n",
            "Watch for analyst \"Strong Buy Recommendations\" and several advisory newsletters picking CBYI.  CBYI has filed to be traded on the OTCBB, share prices historically INCREASE when companies get listed on this larger trading exchange. CBYI is trading around 25 cents and should skyrocket to $2.66 - $3.25 a share in the near future.\n",
            "Put CBYI on your watch list, acquire a position TODAY.\n",
            "REASONS TO INVEST IN CBYI\n",
            "A profitable company and is on track to beat ALL earnings estimates!\n",
            "One of the FASTEST growing distributors in environmental & safety equipment instruments.\n",
            "Excellent management team, several EXCLUSIVE contracts.  IMPRESSIVE client list including the U.S. Air Force, Anheuser-Busch, Chevron Refining and Mitsubishi Heavy Industries, GE-Energy & Environmental Research.\n",
            "RAPIDLY GROWING INDUSTRY\n",
            "Industry revenues exceed $900 million, estimates indicate that there could be as much as $25 billi ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kkiwHeYvtJM"
      },
      "source": [
        "# Convert every email to plain text\n",
        "def email_to_text(email):\n",
        "  html = None\n",
        "  for part in email.walk():\n",
        "    ctype = part.get_content_type()\n",
        "    if not ctype in (\"text/plain\", \"text/html\"):\n",
        "      continue\n",
        "    try:\n",
        "      content = part.get_content()\n",
        "    except: # in the event of encoding issues\n",
        "      content = str(part.get_payload())\n",
        "    if ctype == \"text/plain\":\n",
        "      return content\n",
        "    else:\n",
        "      html = content\n",
        "  if html:\n",
        "    return html_to_plain_text(html)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXWOJdQIw1JH",
        "outputId": "e37d77da-7435-43e5-e826-cd9324bc2620"
      },
      "source": [
        "print(email_to_text(sample_html_spam))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "OTC\n",
            " Newsletter\n",
            "Discover Tomorrow's Winners \n",
            "For Immediate Release\n",
            "Cal-Bay (Stock Symbol: CBYI)\n",
            "Watch for analyst \"Strong Buy Recommendations\" and several advisory newsletters picking CBYI.  CBYI has filed to be traded on the OTCBB, share prices historically INCREASE when companies get listed on this larger trading exchange. CBYI is trading around 25 cents and should skyrocket to $2.66 - $3.25 a share in the near future.\n",
            "Put CBYI on your watch list, acquire a position TODAY.\n",
            "REASONS TO INVEST IN CBYI\n",
            "A profitable company and is on track to beat ALL earnings estimates!\n",
            "One of the FASTEST growing distributors in environmental & safety equipment instruments.\n",
            "Excellent management team, several EXCLUSIVE contracts.  IMPRESSIVE client list including the U.S. Air Force, Anheuser-Busch, Chevron Refining and Mitsubishi Heavy Industries, GE-Energy & Environmental Research.\n",
            "RAPIDLY GROWING INDUSTRY\n",
            "Industry revenues exceed $900 million, estimates indicate that there could be as much as $25 billion from \"smell technology\" by the end of 2003.\n",
            "!!!!!CONGRATULATIONS!!!!!Our last recommendation to buy ORBT at $1.29 rallied and is holding steady at $3.50! Congratulations to all our subscribers that took advantage of this recommendation.\n",
            "ALL removes HONORED. Please allow 7 days to be removed and send ALL addresses to:\n",
            " HYPERLINK GoneForGood@btamail.net.cn\n",
            " \n",
            "Certain statements contained in this news release may be forward-looking statements within the meaning of The Private Securities Litigation Reform Act of 1995. These statements may be identified by such terms as \"expect\", \"believe\", \"may\", \"will\", and \"intend\" or similar terms. We are NOT a registered investment advisor or a broker dealer. This is NOT an offer to buy or sell securities. No recommendation that the securities of the companies profiled should be purchased, sold or held by individuals or entities that learn of the profiled companies. We were paid $27,000 in cash by a third party to publish this report. Investing in companies profiled is high-risk and use of this information is for reading purposes only. If anyone decides to act as an investor, then it will be that investor's sole risk. Investors are advised NOT to invest without the proper advisement from an attorney or a registered financial broker. Do not rely solely on the information presented, do additional independent research to form your own opinion and decision regarding investing in the profiled companies. Be advised that the purchase of such high-risk securities may result in the loss of your entire investment.  Not intended for recipients or residents of CA,CO,CT,DE,ID, IL,IA,LA,MO,NV,NC,OK,OH,PA,RI,TN,VA,WA,WV,WI. Void where prohibited.  The owners of this publication may already own free trading shares in CBYI and may immediately sell all or a portion of these shares into the open market at or about the time this report is published.  Factual statements are made as of the date stated and are subject to change without notice.\n",
            "Copyright c 2001\n",
            "≡\n",
            "OTC\n",
            "≡\n",
            "****\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyr4ATqBx6dG"
      },
      "source": [
        "Stemming - Reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words(lemma)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiRawq9F0zQI",
        "outputId": "1776ed92-b5de-43d3-ff45-cd65de551817"
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYOmzFI6yrSF",
        "outputId": "93cebed8-6616-4eab-e23f-197cb710f795"
      },
      "source": [
        "try:\n",
        "  import nltk\n",
        "\n",
        "  stemmer = nltk.PorterStemmer()\n",
        "  for word in (\"Computations\", \"Computation\", \"Computing\", \"Computed\", \"Compute\", \"Compulsive\"):\n",
        "    print(word, \"=>\", stemmer.stem(word))\n",
        "except ImportError:\n",
        "  print(\"Error: stemming requires the NLTK module.\")\n",
        "  stemmer = None"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computations => comput\n",
            "Computation => comput\n",
            "Computing => comput\n",
            "Computed => comput\n",
            "Compute => comput\n",
            "Compulsive => compuls\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7SWtXwa1zfW",
        "outputId": "5b3c0ef9-daef-4d72-b31f-f704434df59a"
      },
      "source": [
        "!pip install urlextract"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting urlextract\n",
            "  Downloading https://files.pythonhosted.org/packages/c3/24/0f5c690a4ef9b5d30845517ef14c35ce6a3d96e5b0ae0db6895bb194ab10/urlextract-1.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from urlextract) (2.10)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from urlextract) (1.4.4)\n",
            "Collecting uritools\n",
            "  Downloading https://files.pythonhosted.org/packages/5f/fe/44e4381e7fcf89cc32af9f2d83a778e63dbc1e3f80e9625ad00ec0214a0b/uritools-3.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from urlextract) (3.0.12)\n",
            "Installing collected packages: uritools, urlextract\n",
            "Successfully installed uritools-3.0.2 urlextract-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1RuoMb92CQL"
      },
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    !pip install -q -U urlextract\n",
        "except ImportError:\n",
        "    pass # not running on Colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnq1_qjr3-ty",
        "outputId": "e671c790-8750-4ba3-8151-f380e990dda0"
      },
      "source": [
        "try:\n",
        "    import urlextract # may require an Internet connection to download root domain names\n",
        "    \n",
        "    url_extractor = urlextract.URLExtract()\n",
        "    print(url_extractor.find_urls(\"Will it detect github.com and https://youtu.be/7Pq-S557XQU?t=3m32s\"))\n",
        "except ImportError:\n",
        "    print(\"Error: replacing URLs requires the urlextract module.\")\n",
        "    url_extractor = None"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['github.com', 'https://youtu.be/7Pq-S557XQU?t=3m32s']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyveSW2X4LSS"
      },
      "source": [
        "# Transformer to convert email to text\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class EmailToWordCounterTransformer(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, strip_headers=True, lower_case=True, remove_punctuation=True,\n",
        "               replace_urls=True, replace_numbers=True, stemming=True):\n",
        "    self.strip_headers = strip_headers\n",
        "    self.lower_case = lower_case\n",
        "    self.remove_punctuation = remove_punctuation\n",
        "    self.replace_urls = replace_urls\n",
        "    self.replace_numbers = replace_numbers\n",
        "    self.stemming = stemming\n",
        "  \n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y=None):\n",
        "    X_transformed = []\n",
        "    for email in X:\n",
        "      text = email_to_text(email) or \"\"\n",
        "      if self.lower_case:\n",
        "        text = text.lower()\n",
        "      if self.replace_urls and url_extractor is not None:\n",
        "        urls = list(set(url_extractor.find_urls(text)))\n",
        "        urls.sort(key=lambda url: len(url), reverse=True)\n",
        "        for url in urls:\n",
        "          text = text.replace(url, \"URL \")\n",
        "      if self.replace_numbers:\n",
        "        text = re.sub(r'\\d+(?:\\.\\d*)?(?:[eE][+-]?\\d+)?', 'NUMBER', text)\n",
        "      if self.remove_punctuation:\n",
        "        text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
        "      word_counts = Counter(text.split())\n",
        "      if self.stemming and stemmer is not None:\n",
        "        stemmed_word_counts = Counter()\n",
        "        for word, count in word_counts.items():\n",
        "          stemmed_words = stemmer.stem(word)\n",
        "          stemmed_word_counts[stemmed_words] += count\n",
        "        word_counts = stemmed_word_counts\n",
        "      X_transformed.append(word_counts)\n",
        "    return np.array(X_transformed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7q2S9Mvq8dEz",
        "outputId": "a420a205-885b-4521-b748-f5158a2a4e2b"
      },
      "source": [
        "X_few = X_train[:3]\n",
        "X_few_wordcounts = EmailToWordCounterTransformer().fit_transform(X_few)\n",
        "X_few_wordcounts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([Counter({'number': 19, 'i': 7, 'that': 7, 'a': 6, 'openssh': 6, 't': 6, 'packag': 5, 'of': 5, 'it': 5, 'with': 4, 'matthia': 3, 'do': 3, 'red': 3, 'hat': 3, 'and': 3, 's': 3, 'rpm': 3, 'the': 3, 'to': 3, 'ssh': 3, 'list': 3, 'wrote': 2, 'at': 2, 'saou': 2, 'all': 2, 'don': 2, 'version': 2, 'you': 2, 'have': 2, 'is': 2, 'offici': 2, 'problem': 2, 'from': 2, 'rh': 2, 'upgrad': 2, 'doesn': 2, 'downgrad': 2, 'as': 2, 'like': 2, 'well': 2, 'but': 2, 'connect': 2, 'work': 2, 'onc': 1, 'upon': 1, 'time': 1, 'peter': 1, 'on': 1, 'wed': 1, 'feb': 1, 'numberpm': 1, 'strang': 1, 'my': 1, 'explicitli': 1, 'requir': 1, 'openssl': 1, 'what': 1, 'an': 1, 'suppos': 1, 'isn': 1, 'use': 1, 'will': 1, 'solv': 1, 'your': 1, 'numberpnumb': 1, 'think': 1, 'directli': 1, 'site': 1, 'ship': 1, 'explain': 1, 'probabl': 1, 'should': 1, 'versoin': 1, 'provid': 1, 'except': 1, 'can': 1, 'physic': 1, 'access': 1, 'box': 1, 'over': 1, 'sound': 1, 'bright': 1, 'idea': 1, 've': 1, 'seen': 1, 'few': 1, 'realli': 1, 'wonder': 1, 'ever': 1, 'tri': 1, 'complet': 1, 'uninstal': 1, 'relat': 1, 'while': 1, 'be': 1, 'through': 1, 'cours': 1, 'if': 1, 'cut': 1, 'moment': 1, 're': 1, 'stuck': 1, 'simpl': 1, 'also': 1, 'charm': 1, 'world': 1, 'trade': 1, 'center': 1, 'edificio': 1, 'nort': 1, 'planta': 1, 'system': 1, 'network': 1, 'engin': 1, 'barcelona': 1, 'spain': 1, 'electron': 1, 'group': 1, 'interact': 1, 'phone': 1, '_______________________________________________': 1, 'mail': 1, 'freshrpm': 1, 'net': 1, 'url': 1}),\n",
              "       Counter({'the': 12, 'file': 6, 'is': 5, 'as': 4, 'of': 4, 'cach': 3, 'system': 3, 'with': 3, 'or': 3, 'in': 3, 'a': 3, 'can': 2, 'be': 2, 'on': 2, 'napster': 2, 'freenet': 2, 'xdegre': 2, 'more': 2, 'sophist': 2, 'than': 2, 'download': 2, 'stripe': 2, 'use': 2, 'digit': 2, 'signatur': 2, 'to': 2, 'same': 2, 'thi': 2, 'digest': 2, 'mr': 1, 'fork': 1, 'write': 1, 'multipl': 1, 'randomli': 1, 'scatter': 1, 'around': 1, 'internet': 1, 'fact': 1, 'it': 1, 'those': 1, 'user': 1, 'high': 1, 'bandwidth': 1, 'connect': 1, 'portion': 1, 'from': 1, 'sever': 1, 'locat': 1, 'simultan': 1, 'softwar': 1, 'then': 1, 'reassembl': 1, 'these': 1, 'into': 1, 'whole': 1, 'and': 1, 'verifi': 1, 'that': 1, 'origin': 1, 'key': 1, 'compon': 1, 'which': 1, 'store': 1, 'an': 1, 'http': 1, 'header': 1, 'for': 1, 'part': 1, 'seem': 1, 'behavior': 1, 'implement': 1, 'mani': 1, 'other': 1, 'pnumberp': 1, 'cdn': 1, 'such': 1, 'kazaa': 1, 'edonkey': 1, 'overnet': 1, 'bittorr': 1, 'gnutella': 1, 'huge': 1, 'extens': 1, 'onionnetwork': 1, 'webraid': 1, 'though': 1, 'qualiti': 1, 'by': 1, 'each': 1, 'vari': 1, 'wildli': 1, 'gordon': 1}),\n",
              "       Counter({'i': 6, 'c': 4, 'r': 2, 'f': 2, 'to': 2, 'unsubscrib': 2, 'freebsd': 2, 'the': 2, 'v': 1, 'u': 1, 'j': 1, 'url': 1, 'nnumber': 1, 'number': 1, 'b': 1, 'd': 1, 'g': 1, 'send': 1, 'mail': 1, 'majordomo': 1, 'org': 1, 'with': 1, 'port': 1, 'in': 1, 'bodi': 1, 'of': 1, 'messag': 1})],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ0FBx099Oss"
      },
      "source": [
        "# Task: convert word counts into vectors\n",
        "# fit() builds vocabulary (an ordered list of the most common words)\n",
        "# transform() converts word counts to vectors; outputs a sparse matrix\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "class WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, vocabulary_size=1000):\n",
        "    self.vocabulary_size = vocabulary_size\n",
        "  \n",
        "  def fit(self, X, y=None):\n",
        "    total_count = Counter()\n",
        "    for word_count in X:\n",
        "      for word, count in word_count.items():\n",
        "        total_count[word] += min(count, 10)\n",
        "    most_common = total_count.most_common()[:self.vocabulary_size]\n",
        "    self.vocabulary_ = {word: index + 1 for index, (word, count) in enumerate(most_common)}\n",
        "    return self\n",
        "  \n",
        "  def transform(self, X, y=None):\n",
        "    rows=[]\n",
        "    cols=[]\n",
        "    data=[]\n",
        "    for row, word_count in enumerate(X):\n",
        "      for word, count in word_count.items():\n",
        "        rows.append(row)\n",
        "        cols.append(self.vocabulary_.get(word, 0))\n",
        "        data.append(count)\n",
        "    return csr_matrix((data, (rows, cols)), shape=(len(X), self.vocabulary_size+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhTsat3Z_97V",
        "outputId": "e80d38b5-b311-4d71-f84f-7d67fadef604"
      },
      "source": [
        "# Test transformer\n",
        "vocab_transformer = WordCounterToVectorTransformer(vocabulary_size=10)\n",
        "X_few_vectors = vocab_transformer.fit_transform(X_few_wordcounts)\n",
        "X_few_vectors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<3x11 sparse matrix of type '<class 'numpy.longlong'>'\n",
              "\twith 26 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqB80WgxAYP4",
        "outputId": "c9522b14-ba19-49ca-ffb6-8c1ba6634dc9"
      },
      "source": [
        "X_few_vectors.toarray()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[167,   3,   7,  19,   5,   6,   7,   4,   2,   3,   6],\n",
              "       [118,  12,   0,   0,   4,   3,   1,   3,   5,   2,   0],\n",
              "       [ 28,   2,   6,   1,   1,   0,   0,   1,   0,   2,   0]],\n",
              "      dtype=int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrGHQkWNBMCy"
      },
      "source": [
        "Understanding sparse matrix<br>\n",
        "1. The first column represents number of words not in the vocabulary.\n",
        "2. Subsequent columns represents the count of the words in the vocabulary respectively present in the row"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhhUiTQOB_I_",
        "outputId": "17b9d26c-2618-4d64-df71-030705ec7637"
      },
      "source": [
        "vocab_transformer.vocabulary_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': 5,\n",
              " 'i': 2,\n",
              " 'is': 8,\n",
              " 'number': 3,\n",
              " 'of': 4,\n",
              " 'openssh': 10,\n",
              " 'that': 6,\n",
              " 'the': 1,\n",
              " 'to': 9,\n",
              " 'with': 7}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfND2KGNCLq0"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "preprocess_pipeline = Pipeline([\n",
        "                              (\"email_to_wordcount\", EmailToWordCounterTransformer()),\n",
        "                              (\"wordcount_to_vector\", WordCounterToVectorTransformer()),\n",
        "])\n",
        "\n",
        "X_train_transformed = preprocess_pipeline.fit_transform(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiAjyQFKT2h3"
      },
      "source": [
        "# Train Models\n",
        "### 1. Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOEs7Lp5T2H3",
        "outputId": "bbb9f139-ce4e-40ca-d626-c6066dd02b5d"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "log_clf = LogisticRegression(solver=\"lbfgs\", max_iter=1000, random_state=42)\n",
        "score = cross_val_score(log_clf, X_train_transformed, y_train, cv=3, verbose=3)\n",
        "score.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  ................................................................\n",
            "[CV] .................................... , score=0.979, total=   0.6s\n",
            "[CV]  ................................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .................................... , score=0.971, total=   0.8s\n",
            "[CV]  ................................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .................................... , score=0.971, total=   0.8s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    2.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9738451102036612"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNouZPuKUsfu",
        "outputId": "b58006f1-bb81-46cd-da1b-ad430adebdf6"
      },
      "source": [
        "# Precision/Recall\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "X_test_transformed = preprocess_pipeline.transform(X_test)\n",
        "\n",
        "log_clf = LogisticRegression(solver=\"lbfgs\", max_iter=1000, random_state=42)\n",
        "log_clf.fit(X_train_transformed, y_train)\n",
        "\n",
        "y_pred_log = log_clf.predict(X_test_transformed)\n",
        "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred_log)))\n",
        "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred_log)))\n",
        "print(\"f1 score: {:.2f}%\".format(100 * f1_score(y_test, y_pred_log)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 97.09%\n",
            "Recall: 96.15%\n",
            "f1 score: 96.62%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXUNzURXj7RK",
        "outputId": "c7d63946-261b-46d9-e6bc-58ab38683b07"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "log_param_grid = [{\n",
        "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
        "    'C': np.logspace(-4, 4, 20),\n",
        "    'fit_intercept': [True, False],\n",
        "}]\n",
        "\n",
        "\n",
        "grid_search_log = GridSearchCV(log_clf, log_param_grid, cv=5, verbose=3)\n",
        "grid_search_log.fit(X_train_transformed, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
            "[CV] C=0.0001, fit_intercept=True, penalty=l1 ........................\n",
            "[CV]  C=0.0001, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0001, fit_intercept=True, penalty=l1 ........................\n",
            "[CV]  C=0.0001, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0001, fit_intercept=True, penalty=l1 ........................\n",
            "[CV]  C=0.0001, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0001, fit_intercept=True, penalty=l1 ........................\n",
            "[CV]  C=0.0001, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0001, fit_intercept=True, penalty=l1 ........................\n",
            "[CV]  C=0.0001, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0001, fit_intercept=True, penalty=l2 ........................\n",
            "[CV]  C=0.0001, fit_intercept=True, penalty=l2, score=0.856, total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, penalty=l2 ........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, penalty=l2, score=0.854, total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, penalty=l2 ........................\n",
            "[CV]  C=0.0001, fit_intercept=True, penalty=l2, score=0.852, total=   0.2s\n",
            "[CV] C=0.0001, fit_intercept=True, penalty=l2 ........................\n",
            "[CV]  C=0.0001, fit_intercept=True, penalty=l2, score=0.860, total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=True, penalty=l2 ........................\n",
            "[CV]  C=0.0001, fit_intercept=True, penalty=l2, score=0.862, total=   0.2s\n",
            "[CV] C=0.0001, fit_intercept=True, penalty=elasticnet ................\n",
            "[CV]  C=0.0001, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0001, fit_intercept=True, penalty=elasticnet ................\n",
            "[CV]  C=0.0001, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0001, fit_intercept=True, penalty=elasticnet ................\n",
            "[CV]  C=0.0001, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0001, fit_intercept=True, penalty=elasticnet ................\n",
            "[CV]  C=0.0001, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0001, fit_intercept=True, penalty=elasticnet ................\n",
            "[CV]  C=0.0001, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0001, fit_intercept=True, penalty=none ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.0001, fit_intercept=True, penalty=none ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, penalty=none, score=0.965, total=   0.2s\n",
            "[CV] C=0.0001, fit_intercept=True, penalty=none ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, penalty=none, score=0.973, total=   0.2s\n",
            "[CV] C=0.0001, fit_intercept=True, penalty=none ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, penalty=none, score=0.981, total=   0.3s\n",
            "[CV] C=0.0001, fit_intercept=True, penalty=none ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=True, penalty=none, score=0.969, total=   0.3s\n",
            "[CV] C=0.0001, fit_intercept=False, penalty=l1 .......................\n",
            "[CV]  C=0.0001, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0001, fit_intercept=False, penalty=l1 .......................\n",
            "[CV]  C=0.0001, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0001, fit_intercept=False, penalty=l1 .......................\n",
            "[CV]  C=0.0001, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0001, fit_intercept=False, penalty=l1 .......................\n",
            "[CV]  C=0.0001, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0001, fit_intercept=False, penalty=l1 .......................\n",
            "[CV]  C=0.0001, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0001, fit_intercept=False, penalty=l2 .......................\n",
            "[CV]  C=0.0001, fit_intercept=False, penalty=l2, score=0.913, total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, penalty=l2 .......................\n",
            "[CV]  C=0.0001, fit_intercept=False, penalty=l2, score=0.896, total=   0.0s\n",
            "[CV] C=0.0001, fit_intercept=False, penalty=l2 .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, penalty=l2, score=0.896, total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, penalty=l2 .......................\n",
            "[CV]  C=0.0001, fit_intercept=False, penalty=l2, score=0.902, total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, penalty=l2 .......................\n",
            "[CV]  C=0.0001, fit_intercept=False, penalty=l2, score=0.910, total=   0.1s\n",
            "[CV] C=0.0001, fit_intercept=False, penalty=elasticnet ...............\n",
            "[CV]  C=0.0001, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0001, fit_intercept=False, penalty=elasticnet ...............\n",
            "[CV]  C=0.0001, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0001, fit_intercept=False, penalty=elasticnet ...............\n",
            "[CV]  C=0.0001, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0001, fit_intercept=False, penalty=elasticnet ...............\n",
            "[CV]  C=0.0001, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0001, fit_intercept=False, penalty=elasticnet ...............\n",
            "[CV]  C=0.0001, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0001, fit_intercept=False, penalty=none .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.0001, fit_intercept=False, penalty=none .....................\n",
            "[CV]  C=0.0001, fit_intercept=False, penalty=none, score=0.962, total=   0.2s\n",
            "[CV] C=0.0001, fit_intercept=False, penalty=none .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, penalty=none, score=0.979, total=   0.3s\n",
            "[CV] C=0.0001, fit_intercept=False, penalty=none .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.0001, fit_intercept=False, penalty=none .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0001, fit_intercept=False, penalty=none, score=0.971, total=   0.3s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=True, penalty=l1 ........\n",
            "[CV]  C=0.00026366508987303583, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=True, penalty=l1 ........\n",
            "[CV]  C=0.00026366508987303583, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=True, penalty=l1 ........\n",
            "[CV]  C=0.00026366508987303583, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=True, penalty=l1 ........\n",
            "[CV]  C=0.00026366508987303583, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=True, penalty=l1 ........\n",
            "[CV]  C=0.00026366508987303583, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=True, penalty=l2 ........\n",
            "[CV]  C=0.00026366508987303583, fit_intercept=True, penalty=l2, score=0.881, total=   0.2s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=True, penalty=l2 ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.00026366508987303583, fit_intercept=True, penalty=l2, score=0.871, total=   0.1s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=True, penalty=l2 ........\n",
            "[CV]  C=0.00026366508987303583, fit_intercept=True, penalty=l2, score=0.865, total=   0.2s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=True, penalty=l2 ........\n",
            "[CV]  C=0.00026366508987303583, fit_intercept=True, penalty=l2, score=0.881, total=   0.2s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=True, penalty=l2 ........\n",
            "[CV]  C=0.00026366508987303583, fit_intercept=True, penalty=l2, score=0.890, total=   0.3s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=True, penalty=elasticnet \n",
            "[CV]  C=0.00026366508987303583, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=True, penalty=elasticnet \n",
            "[CV]  C=0.00026366508987303583, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=True, penalty=elasticnet \n",
            "[CV]  C=0.00026366508987303583, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=True, penalty=elasticnet \n",
            "[CV]  C=0.00026366508987303583, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=True, penalty=elasticnet \n",
            "[CV]  C=0.00026366508987303583, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=True, penalty=none ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.00026366508987303583, fit_intercept=True, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=True, penalty=none ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.00026366508987303583, fit_intercept=True, penalty=none, score=0.965, total=   0.2s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=True, penalty=none ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.00026366508987303583, fit_intercept=True, penalty=none, score=0.973, total=   0.2s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=True, penalty=none ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.00026366508987303583, fit_intercept=True, penalty=none, score=0.981, total=   0.3s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=True, penalty=none ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.00026366508987303583, fit_intercept=True, penalty=none, score=0.969, total=   0.3s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=False, penalty=l1 .......\n",
            "[CV]  C=0.00026366508987303583, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=False, penalty=l1 .......\n",
            "[CV]  C=0.00026366508987303583, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=False, penalty=l1 .......\n",
            "[CV]  C=0.00026366508987303583, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=False, penalty=l1 .......\n",
            "[CV]  C=0.00026366508987303583, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=False, penalty=l1 .......\n",
            "[CV]  C=0.00026366508987303583, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=False, penalty=l2 .......\n",
            "[CV]  C=0.00026366508987303583, fit_intercept=False, penalty=l2, score=0.927, total=   0.1s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=False, penalty=l2 .......\n",
            "[CV]  C=0.00026366508987303583, fit_intercept=False, penalty=l2, score=0.923, total=   0.1s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=False, penalty=l2 .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.00026366508987303583, fit_intercept=False, penalty=l2, score=0.919, total=   0.1s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=False, penalty=l2 .......\n",
            "[CV]  C=0.00026366508987303583, fit_intercept=False, penalty=l2, score=0.919, total=   0.1s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=False, penalty=l2 .......\n",
            "[CV]  C=0.00026366508987303583, fit_intercept=False, penalty=l2, score=0.927, total=   0.1s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=False, penalty=elasticnet \n",
            "[CV]  C=0.00026366508987303583, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=False, penalty=elasticnet \n",
            "[CV]  C=0.00026366508987303583, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=False, penalty=elasticnet \n",
            "[CV]  C=0.00026366508987303583, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=False, penalty=elasticnet \n",
            "[CV]  C=0.00026366508987303583, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=False, penalty=elasticnet \n",
            "[CV]  C=0.00026366508987303583, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=False, penalty=none .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.00026366508987303583, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=False, penalty=none .....\n",
            "[CV]  C=0.00026366508987303583, fit_intercept=False, penalty=none, score=0.962, total=   0.2s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=False, penalty=none .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.00026366508987303583, fit_intercept=False, penalty=none, score=0.979, total=   0.3s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=False, penalty=none .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.00026366508987303583, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.00026366508987303583, fit_intercept=False, penalty=none .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.00026366508987303583, fit_intercept=False, penalty=none, score=0.971, total=   0.3s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=True, penalty=l1 .........\n",
            "[CV]  C=0.0006951927961775605, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=True, penalty=l1 .........\n",
            "[CV]  C=0.0006951927961775605, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=True, penalty=l1 .........\n",
            "[CV]  C=0.0006951927961775605, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=True, penalty=l1 .........\n",
            "[CV]  C=0.0006951927961775605, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=True, penalty=l1 .........\n",
            "[CV]  C=0.0006951927961775605, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=True, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0006951927961775605, fit_intercept=True, penalty=l2, score=0.906, total=   0.2s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=True, penalty=l2 .........\n",
            "[CV]  C=0.0006951927961775605, fit_intercept=True, penalty=l2, score=0.892, total=   0.2s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=True, penalty=l2 .........\n",
            "[CV]  C=0.0006951927961775605, fit_intercept=True, penalty=l2, score=0.892, total=   0.2s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=True, penalty=l2 .........\n",
            "[CV]  C=0.0006951927961775605, fit_intercept=True, penalty=l2, score=0.900, total=   0.2s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=True, penalty=l2 .........\n",
            "[CV]  C=0.0006951927961775605, fit_intercept=True, penalty=l2, score=0.902, total=   0.3s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=True, penalty=elasticnet .\n",
            "[CV]  C=0.0006951927961775605, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=True, penalty=elasticnet .\n",
            "[CV]  C=0.0006951927961775605, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=True, penalty=elasticnet .\n",
            "[CV]  C=0.0006951927961775605, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=True, penalty=elasticnet .\n",
            "[CV]  C=0.0006951927961775605, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=True, penalty=elasticnet .\n",
            "[CV]  C=0.0006951927961775605, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=True, penalty=none .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0006951927961775605, fit_intercept=True, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=True, penalty=none .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0006951927961775605, fit_intercept=True, penalty=none, score=0.965, total=   0.2s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=True, penalty=none .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0006951927961775605, fit_intercept=True, penalty=none, score=0.973, total=   0.2s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=True, penalty=none .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0006951927961775605, fit_intercept=True, penalty=none, score=0.981, total=   0.3s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=True, penalty=none .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0006951927961775605, fit_intercept=True, penalty=none, score=0.969, total=   0.3s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=False, penalty=l1 ........\n",
            "[CV]  C=0.0006951927961775605, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=False, penalty=l1 ........\n",
            "[CV]  C=0.0006951927961775605, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=False, penalty=l1 ........\n",
            "[CV]  C=0.0006951927961775605, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=False, penalty=l1 ........\n",
            "[CV]  C=0.0006951927961775605, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=False, penalty=l1 ........\n",
            "[CV]  C=0.0006951927961775605, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=False, penalty=l2 ........\n",
            "[CV]  C=0.0006951927961775605, fit_intercept=False, penalty=l2, score=0.950, total=   0.2s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=False, penalty=l2 ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0006951927961775605, fit_intercept=False, penalty=l2, score=0.938, total=   0.1s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=False, penalty=l2 ........\n",
            "[CV]  C=0.0006951927961775605, fit_intercept=False, penalty=l2, score=0.933, total=   0.1s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=False, penalty=l2 ........\n",
            "[CV]  C=0.0006951927961775605, fit_intercept=False, penalty=l2, score=0.940, total=   0.2s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=False, penalty=l2 ........\n",
            "[CV]  C=0.0006951927961775605, fit_intercept=False, penalty=l2, score=0.942, total=   0.2s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=False, penalty=elasticnet \n",
            "[CV]  C=0.0006951927961775605, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=False, penalty=elasticnet \n",
            "[CV]  C=0.0006951927961775605, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=False, penalty=elasticnet \n",
            "[CV]  C=0.0006951927961775605, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=False, penalty=elasticnet \n",
            "[CV]  C=0.0006951927961775605, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=False, penalty=elasticnet \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0006951927961775605, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=False, penalty=none ......\n",
            "[CV]  C=0.0006951927961775605, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=False, penalty=none ......\n",
            "[CV]  C=0.0006951927961775605, fit_intercept=False, penalty=none, score=0.962, total=   0.2s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=False, penalty=none ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0006951927961775605, fit_intercept=False, penalty=none, score=0.979, total=   0.3s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=False, penalty=none ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0006951927961775605, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.0006951927961775605, fit_intercept=False, penalty=none ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0006951927961775605, fit_intercept=False, penalty=none, score=0.971, total=   0.3s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=True, penalty=l1 .........\n",
            "[CV]  C=0.0018329807108324356, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=True, penalty=l1 .........\n",
            "[CV]  C=0.0018329807108324356, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=True, penalty=l1 .........\n",
            "[CV]  C=0.0018329807108324356, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=True, penalty=l1 .........\n",
            "[CV]  C=0.0018329807108324356, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=True, penalty=l1 .........\n",
            "[CV]  C=0.0018329807108324356, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=True, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0018329807108324356, fit_intercept=True, penalty=l2, score=0.935, total=   0.3s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=True, penalty=l2 .........\n",
            "[CV]  C=0.0018329807108324356, fit_intercept=True, penalty=l2, score=0.935, total=   0.2s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=True, penalty=l2 .........\n",
            "[CV]  C=0.0018329807108324356, fit_intercept=True, penalty=l2, score=0.919, total=   0.3s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=True, penalty=l2 .........\n",
            "[CV]  C=0.0018329807108324356, fit_intercept=True, penalty=l2, score=0.933, total=   0.3s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=True, penalty=l2 .........\n",
            "[CV]  C=0.0018329807108324356, fit_intercept=True, penalty=l2, score=0.923, total=   0.3s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=True, penalty=elasticnet .\n",
            "[CV]  C=0.0018329807108324356, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=True, penalty=elasticnet .\n",
            "[CV]  C=0.0018329807108324356, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=True, penalty=elasticnet .\n",
            "[CV]  C=0.0018329807108324356, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=True, penalty=elasticnet .\n",
            "[CV]  C=0.0018329807108324356, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=True, penalty=elasticnet .\n",
            "[CV]  C=0.0018329807108324356, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=True, penalty=none .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0018329807108324356, fit_intercept=True, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=True, penalty=none .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0018329807108324356, fit_intercept=True, penalty=none, score=0.965, total=   0.3s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=True, penalty=none .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0018329807108324356, fit_intercept=True, penalty=none, score=0.973, total=   0.2s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=True, penalty=none .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0018329807108324356, fit_intercept=True, penalty=none, score=0.981, total=   0.3s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=True, penalty=none .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0018329807108324356, fit_intercept=True, penalty=none, score=0.969, total=   0.3s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=False, penalty=l1 ........\n",
            "[CV]  C=0.0018329807108324356, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=False, penalty=l1 ........\n",
            "[CV]  C=0.0018329807108324356, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=False, penalty=l1 ........\n",
            "[CV]  C=0.0018329807108324356, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=False, penalty=l1 ........\n",
            "[CV]  C=0.0018329807108324356, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=False, penalty=l1 ........\n",
            "[CV]  C=0.0018329807108324356, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=False, penalty=l2 ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0018329807108324356, fit_intercept=False, penalty=l2, score=0.956, total=   0.2s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=False, penalty=l2 ........\n",
            "[CV]  C=0.0018329807108324356, fit_intercept=False, penalty=l2, score=0.958, total=   0.1s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=False, penalty=l2 ........\n",
            "[CV]  C=0.0018329807108324356, fit_intercept=False, penalty=l2, score=0.950, total=   0.2s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=False, penalty=l2 ........\n",
            "[CV]  C=0.0018329807108324356, fit_intercept=False, penalty=l2, score=0.958, total=   0.2s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=False, penalty=l2 ........\n",
            "[CV]  C=0.0018329807108324356, fit_intercept=False, penalty=l2, score=0.958, total=   0.2s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=False, penalty=elasticnet \n",
            "[CV]  C=0.0018329807108324356, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=False, penalty=elasticnet \n",
            "[CV]  C=0.0018329807108324356, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=False, penalty=elasticnet \n",
            "[CV]  C=0.0018329807108324356, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=False, penalty=elasticnet \n",
            "[CV]  C=0.0018329807108324356, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=False, penalty=elasticnet \n",
            "[CV]  C=0.0018329807108324356, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=False, penalty=none ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0018329807108324356, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=False, penalty=none ......\n",
            "[CV]  C=0.0018329807108324356, fit_intercept=False, penalty=none, score=0.962, total=   0.2s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=False, penalty=none ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0018329807108324356, fit_intercept=False, penalty=none, score=0.979, total=   0.3s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=False, penalty=none ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0018329807108324356, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.0018329807108324356, fit_intercept=False, penalty=none ......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.0018329807108324356, fit_intercept=False, penalty=none, score=0.971, total=   0.3s\n",
            "[CV] C=0.004832930238571752, fit_intercept=True, penalty=l1 ..........\n",
            "[CV]  C=0.004832930238571752, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.004832930238571752, fit_intercept=True, penalty=l1 ..........\n",
            "[CV]  C=0.004832930238571752, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.004832930238571752, fit_intercept=True, penalty=l1 ..........\n",
            "[CV]  C=0.004832930238571752, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.004832930238571752, fit_intercept=True, penalty=l1 ..........\n",
            "[CV]  C=0.004832930238571752, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.004832930238571752, fit_intercept=True, penalty=l1 ..........\n",
            "[CV]  C=0.004832930238571752, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.004832930238571752, fit_intercept=True, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.004832930238571752, fit_intercept=True, penalty=l2, score=0.942, total=   0.5s\n",
            "[CV] C=0.004832930238571752, fit_intercept=True, penalty=l2 ..........\n",
            "[CV]  C=0.004832930238571752, fit_intercept=True, penalty=l2, score=0.948, total=   0.3s\n",
            "[CV] C=0.004832930238571752, fit_intercept=True, penalty=l2 ..........\n",
            "[CV]  C=0.004832930238571752, fit_intercept=True, penalty=l2, score=0.948, total=   0.3s\n",
            "[CV] C=0.004832930238571752, fit_intercept=True, penalty=l2 ..........\n",
            "[CV]  C=0.004832930238571752, fit_intercept=True, penalty=l2, score=0.954, total=   0.4s\n",
            "[CV] C=0.004832930238571752, fit_intercept=True, penalty=l2 ..........\n",
            "[CV]  C=0.004832930238571752, fit_intercept=True, penalty=l2, score=0.938, total=   0.5s\n",
            "[CV] C=0.004832930238571752, fit_intercept=True, penalty=elasticnet ..\n",
            "[CV]  C=0.004832930238571752, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.004832930238571752, fit_intercept=True, penalty=elasticnet ..\n",
            "[CV]  C=0.004832930238571752, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.004832930238571752, fit_intercept=True, penalty=elasticnet ..\n",
            "[CV]  C=0.004832930238571752, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.004832930238571752, fit_intercept=True, penalty=elasticnet ..\n",
            "[CV]  C=0.004832930238571752, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.004832930238571752, fit_intercept=True, penalty=elasticnet ..\n",
            "[CV]  C=0.004832930238571752, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.004832930238571752, fit_intercept=True, penalty=none ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.004832930238571752, fit_intercept=True, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.004832930238571752, fit_intercept=True, penalty=none ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.004832930238571752, fit_intercept=True, penalty=none, score=0.965, total=   0.2s\n",
            "[CV] C=0.004832930238571752, fit_intercept=True, penalty=none ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.004832930238571752, fit_intercept=True, penalty=none, score=0.973, total=   0.2s\n",
            "[CV] C=0.004832930238571752, fit_intercept=True, penalty=none ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.004832930238571752, fit_intercept=True, penalty=none, score=0.981, total=   0.3s\n",
            "[CV] C=0.004832930238571752, fit_intercept=True, penalty=none ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.004832930238571752, fit_intercept=True, penalty=none, score=0.969, total=   0.3s\n",
            "[CV] C=0.004832930238571752, fit_intercept=False, penalty=l1 .........\n",
            "[CV]  C=0.004832930238571752, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.004832930238571752, fit_intercept=False, penalty=l1 .........\n",
            "[CV]  C=0.004832930238571752, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.004832930238571752, fit_intercept=False, penalty=l1 .........\n",
            "[CV]  C=0.004832930238571752, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.004832930238571752, fit_intercept=False, penalty=l1 .........\n",
            "[CV]  C=0.004832930238571752, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.004832930238571752, fit_intercept=False, penalty=l1 .........\n",
            "[CV]  C=0.004832930238571752, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.004832930238571752, fit_intercept=False, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.004832930238571752, fit_intercept=False, penalty=l2, score=0.963, total=   0.3s\n",
            "[CV] C=0.004832930238571752, fit_intercept=False, penalty=l2 .........\n",
            "[CV]  C=0.004832930238571752, fit_intercept=False, penalty=l2, score=0.967, total=   0.2s\n",
            "[CV] C=0.004832930238571752, fit_intercept=False, penalty=l2 .........\n",
            "[CV]  C=0.004832930238571752, fit_intercept=False, penalty=l2, score=0.958, total=   0.3s\n",
            "[CV] C=0.004832930238571752, fit_intercept=False, penalty=l2 .........\n",
            "[CV]  C=0.004832930238571752, fit_intercept=False, penalty=l2, score=0.963, total=   0.3s\n",
            "[CV] C=0.004832930238571752, fit_intercept=False, penalty=l2 .........\n",
            "[CV]  C=0.004832930238571752, fit_intercept=False, penalty=l2, score=0.960, total=   0.3s\n",
            "[CV] C=0.004832930238571752, fit_intercept=False, penalty=elasticnet .\n",
            "[CV]  C=0.004832930238571752, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.004832930238571752, fit_intercept=False, penalty=elasticnet .\n",
            "[CV]  C=0.004832930238571752, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.004832930238571752, fit_intercept=False, penalty=elasticnet .\n",
            "[CV]  C=0.004832930238571752, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.004832930238571752, fit_intercept=False, penalty=elasticnet .\n",
            "[CV]  C=0.004832930238571752, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.004832930238571752, fit_intercept=False, penalty=elasticnet .\n",
            "[CV]  C=0.004832930238571752, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.004832930238571752, fit_intercept=False, penalty=none .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.004832930238571752, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.004832930238571752, fit_intercept=False, penalty=none .......\n",
            "[CV]  C=0.004832930238571752, fit_intercept=False, penalty=none, score=0.962, total=   0.2s\n",
            "[CV] C=0.004832930238571752, fit_intercept=False, penalty=none .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.004832930238571752, fit_intercept=False, penalty=none, score=0.979, total=   0.3s\n",
            "[CV] C=0.004832930238571752, fit_intercept=False, penalty=none .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.004832930238571752, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.004832930238571752, fit_intercept=False, penalty=none .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.004832930238571752, fit_intercept=False, penalty=none, score=0.971, total=   0.3s\n",
            "[CV] C=0.012742749857031334, fit_intercept=True, penalty=l1 ..........\n",
            "[CV]  C=0.012742749857031334, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.012742749857031334, fit_intercept=True, penalty=l1 ..........\n",
            "[CV]  C=0.012742749857031334, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.012742749857031334, fit_intercept=True, penalty=l1 ..........\n",
            "[CV]  C=0.012742749857031334, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.012742749857031334, fit_intercept=True, penalty=l1 ..........\n",
            "[CV]  C=0.012742749857031334, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.012742749857031334, fit_intercept=True, penalty=l1 ..........\n",
            "[CV]  C=0.012742749857031334, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.012742749857031334, fit_intercept=True, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.012742749857031334, fit_intercept=True, penalty=l2, score=0.965, total=   0.4s\n",
            "[CV] C=0.012742749857031334, fit_intercept=True, penalty=l2 ..........\n",
            "[CV]  C=0.012742749857031334, fit_intercept=True, penalty=l2, score=0.954, total=   0.4s\n",
            "[CV] C=0.012742749857031334, fit_intercept=True, penalty=l2 ..........\n",
            "[CV]  C=0.012742749857031334, fit_intercept=True, penalty=l2, score=0.962, total=   0.5s\n",
            "[CV] C=0.012742749857031334, fit_intercept=True, penalty=l2 ..........\n",
            "[CV]  C=0.012742749857031334, fit_intercept=True, penalty=l2, score=0.965, total=   0.5s\n",
            "[CV] C=0.012742749857031334, fit_intercept=True, penalty=l2 ..........\n",
            "[CV]  C=0.012742749857031334, fit_intercept=True, penalty=l2, score=0.958, total=   0.5s\n",
            "[CV] C=0.012742749857031334, fit_intercept=True, penalty=elasticnet ..\n",
            "[CV]  C=0.012742749857031334, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.012742749857031334, fit_intercept=True, penalty=elasticnet ..\n",
            "[CV]  C=0.012742749857031334, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.012742749857031334, fit_intercept=True, penalty=elasticnet ..\n",
            "[CV]  C=0.012742749857031334, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.012742749857031334, fit_intercept=True, penalty=elasticnet ..\n",
            "[CV]  C=0.012742749857031334, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.012742749857031334, fit_intercept=True, penalty=elasticnet ..\n",
            "[CV]  C=0.012742749857031334, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.012742749857031334, fit_intercept=True, penalty=none ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.012742749857031334, fit_intercept=True, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.012742749857031334, fit_intercept=True, penalty=none ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.012742749857031334, fit_intercept=True, penalty=none, score=0.965, total=   0.3s\n",
            "[CV] C=0.012742749857031334, fit_intercept=True, penalty=none ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.012742749857031334, fit_intercept=True, penalty=none, score=0.973, total=   0.2s\n",
            "[CV] C=0.012742749857031334, fit_intercept=True, penalty=none ........\n",
            "[CV]  C=0.012742749857031334, fit_intercept=True, penalty=none, score=0.981, total=   0.3s\n",
            "[CV] C=0.012742749857031334, fit_intercept=True, penalty=none ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.012742749857031334, fit_intercept=True, penalty=none, score=0.969, total=   0.3s\n",
            "[CV] C=0.012742749857031334, fit_intercept=False, penalty=l1 .........\n",
            "[CV]  C=0.012742749857031334, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.012742749857031334, fit_intercept=False, penalty=l1 .........\n",
            "[CV]  C=0.012742749857031334, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.012742749857031334, fit_intercept=False, penalty=l1 .........\n",
            "[CV]  C=0.012742749857031334, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.012742749857031334, fit_intercept=False, penalty=l1 .........\n",
            "[CV]  C=0.012742749857031334, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.012742749857031334, fit_intercept=False, penalty=l1 .........\n",
            "[CV]  C=0.012742749857031334, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.012742749857031334, fit_intercept=False, penalty=l2 .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.012742749857031334, fit_intercept=False, penalty=l2, score=0.969, total=   0.4s\n",
            "[CV] C=0.012742749857031334, fit_intercept=False, penalty=l2 .........\n",
            "[CV]  C=0.012742749857031334, fit_intercept=False, penalty=l2, score=0.973, total=   0.3s\n",
            "[CV] C=0.012742749857031334, fit_intercept=False, penalty=l2 .........\n",
            "[CV]  C=0.012742749857031334, fit_intercept=False, penalty=l2, score=0.965, total=   0.4s\n",
            "[CV] C=0.012742749857031334, fit_intercept=False, penalty=l2 .........\n",
            "[CV]  C=0.012742749857031334, fit_intercept=False, penalty=l2, score=0.969, total=   0.4s\n",
            "[CV] C=0.012742749857031334, fit_intercept=False, penalty=l2 .........\n",
            "[CV]  C=0.012742749857031334, fit_intercept=False, penalty=l2, score=0.960, total=   0.4s\n",
            "[CV] C=0.012742749857031334, fit_intercept=False, penalty=elasticnet .\n",
            "[CV]  C=0.012742749857031334, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.012742749857031334, fit_intercept=False, penalty=elasticnet .\n",
            "[CV]  C=0.012742749857031334, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.012742749857031334, fit_intercept=False, penalty=elasticnet .\n",
            "[CV]  C=0.012742749857031334, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.012742749857031334, fit_intercept=False, penalty=elasticnet .\n",
            "[CV]  C=0.012742749857031334, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.012742749857031334, fit_intercept=False, penalty=elasticnet .\n",
            "[CV]  C=0.012742749857031334, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.012742749857031334, fit_intercept=False, penalty=none .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.012742749857031334, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.012742749857031334, fit_intercept=False, penalty=none .......\n",
            "[CV]  C=0.012742749857031334, fit_intercept=False, penalty=none, score=0.962, total=   0.2s\n",
            "[CV] C=0.012742749857031334, fit_intercept=False, penalty=none .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.012742749857031334, fit_intercept=False, penalty=none, score=0.979, total=   0.3s\n",
            "[CV] C=0.012742749857031334, fit_intercept=False, penalty=none .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.012742749857031334, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.012742749857031334, fit_intercept=False, penalty=none .......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.012742749857031334, fit_intercept=False, penalty=none, score=0.971, total=   0.3s\n",
            "[CV] C=0.03359818286283781, fit_intercept=True, penalty=l1 ...........\n",
            "[CV]  C=0.03359818286283781, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.03359818286283781, fit_intercept=True, penalty=l1 ...........\n",
            "[CV]  C=0.03359818286283781, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.03359818286283781, fit_intercept=True, penalty=l1 ...........\n",
            "[CV]  C=0.03359818286283781, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.03359818286283781, fit_intercept=True, penalty=l1 ...........\n",
            "[CV]  C=0.03359818286283781, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.03359818286283781, fit_intercept=True, penalty=l1 ...........\n",
            "[CV]  C=0.03359818286283781, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.03359818286283781, fit_intercept=True, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.03359818286283781, fit_intercept=True, penalty=l2, score=0.971, total=   0.6s\n",
            "[CV] C=0.03359818286283781, fit_intercept=True, penalty=l2 ...........\n",
            "[CV]  C=0.03359818286283781, fit_intercept=True, penalty=l2, score=0.960, total=   0.5s\n",
            "[CV] C=0.03359818286283781, fit_intercept=True, penalty=l2 ...........\n",
            "[CV]  C=0.03359818286283781, fit_intercept=True, penalty=l2, score=0.967, total=   0.5s\n",
            "[CV] C=0.03359818286283781, fit_intercept=True, penalty=l2 ...........\n",
            "[CV]  C=0.03359818286283781, fit_intercept=True, penalty=l2, score=0.973, total=   0.6s\n",
            "[CV] C=0.03359818286283781, fit_intercept=True, penalty=l2 ...........\n",
            "[CV]  C=0.03359818286283781, fit_intercept=True, penalty=l2, score=0.962, total=   0.6s\n",
            "[CV] C=0.03359818286283781, fit_intercept=True, penalty=elasticnet ...\n",
            "[CV]  C=0.03359818286283781, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.03359818286283781, fit_intercept=True, penalty=elasticnet ...\n",
            "[CV]  C=0.03359818286283781, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.03359818286283781, fit_intercept=True, penalty=elasticnet ...\n",
            "[CV]  C=0.03359818286283781, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.03359818286283781, fit_intercept=True, penalty=elasticnet ...\n",
            "[CV]  C=0.03359818286283781, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.03359818286283781, fit_intercept=True, penalty=elasticnet ...\n",
            "[CV]  C=0.03359818286283781, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.03359818286283781, fit_intercept=True, penalty=none .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.03359818286283781, fit_intercept=True, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.03359818286283781, fit_intercept=True, penalty=none .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.03359818286283781, fit_intercept=True, penalty=none, score=0.965, total=   0.2s\n",
            "[CV] C=0.03359818286283781, fit_intercept=True, penalty=none .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.03359818286283781, fit_intercept=True, penalty=none, score=0.973, total=   0.2s\n",
            "[CV] C=0.03359818286283781, fit_intercept=True, penalty=none .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.03359818286283781, fit_intercept=True, penalty=none, score=0.981, total=   0.3s\n",
            "[CV] C=0.03359818286283781, fit_intercept=True, penalty=none .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.03359818286283781, fit_intercept=True, penalty=none, score=0.969, total=   0.3s\n",
            "[CV] C=0.03359818286283781, fit_intercept=False, penalty=l1 ..........\n",
            "[CV]  C=0.03359818286283781, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.03359818286283781, fit_intercept=False, penalty=l1 ..........\n",
            "[CV]  C=0.03359818286283781, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.03359818286283781, fit_intercept=False, penalty=l1 ..........\n",
            "[CV]  C=0.03359818286283781, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.03359818286283781, fit_intercept=False, penalty=l1 ..........\n",
            "[CV]  C=0.03359818286283781, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.03359818286283781, fit_intercept=False, penalty=l1 ..........\n",
            "[CV]  C=0.03359818286283781, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.03359818286283781, fit_intercept=False, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.03359818286283781, fit_intercept=False, penalty=l2, score=0.979, total=   0.5s\n",
            "[CV] C=0.03359818286283781, fit_intercept=False, penalty=l2 ..........\n",
            "[CV]  C=0.03359818286283781, fit_intercept=False, penalty=l2, score=0.971, total=   0.4s\n",
            "[CV] C=0.03359818286283781, fit_intercept=False, penalty=l2 ..........\n",
            "[CV]  C=0.03359818286283781, fit_intercept=False, penalty=l2, score=0.967, total=   0.4s\n",
            "[CV] C=0.03359818286283781, fit_intercept=False, penalty=l2 ..........\n",
            "[CV]  C=0.03359818286283781, fit_intercept=False, penalty=l2, score=0.977, total=   0.5s\n",
            "[CV] C=0.03359818286283781, fit_intercept=False, penalty=l2 ..........\n",
            "[CV]  C=0.03359818286283781, fit_intercept=False, penalty=l2, score=0.962, total=   0.5s\n",
            "[CV] C=0.03359818286283781, fit_intercept=False, penalty=elasticnet ..\n",
            "[CV]  C=0.03359818286283781, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.03359818286283781, fit_intercept=False, penalty=elasticnet ..\n",
            "[CV]  C=0.03359818286283781, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.03359818286283781, fit_intercept=False, penalty=elasticnet ..\n",
            "[CV]  C=0.03359818286283781, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.03359818286283781, fit_intercept=False, penalty=elasticnet ..\n",
            "[CV]  C=0.03359818286283781, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.03359818286283781, fit_intercept=False, penalty=elasticnet ..\n",
            "[CV]  C=0.03359818286283781, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.03359818286283781, fit_intercept=False, penalty=none ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.03359818286283781, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.03359818286283781, fit_intercept=False, penalty=none ........\n",
            "[CV]  C=0.03359818286283781, fit_intercept=False, penalty=none, score=0.962, total=   0.2s\n",
            "[CV] C=0.03359818286283781, fit_intercept=False, penalty=none ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.03359818286283781, fit_intercept=False, penalty=none, score=0.979, total=   0.3s\n",
            "[CV] C=0.03359818286283781, fit_intercept=False, penalty=none ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.03359818286283781, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.03359818286283781, fit_intercept=False, penalty=none ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.03359818286283781, fit_intercept=False, penalty=none, score=0.971, total=   0.3s\n",
            "[CV] C=0.08858667904100823, fit_intercept=True, penalty=l1 ...........\n",
            "[CV]  C=0.08858667904100823, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.08858667904100823, fit_intercept=True, penalty=l1 ...........\n",
            "[CV]  C=0.08858667904100823, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.08858667904100823, fit_intercept=True, penalty=l1 ...........\n",
            "[CV]  C=0.08858667904100823, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.08858667904100823, fit_intercept=True, penalty=l1 ...........\n",
            "[CV]  C=0.08858667904100823, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.08858667904100823, fit_intercept=True, penalty=l1 ...........\n",
            "[CV]  C=0.08858667904100823, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.08858667904100823, fit_intercept=True, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.08858667904100823, fit_intercept=True, penalty=l2, score=0.981, total=   0.7s\n",
            "[CV] C=0.08858667904100823, fit_intercept=True, penalty=l2 ...........\n",
            "[CV]  C=0.08858667904100823, fit_intercept=True, penalty=l2, score=0.965, total=   0.5s\n",
            "[CV] C=0.08858667904100823, fit_intercept=True, penalty=l2 ...........\n",
            "[CV]  C=0.08858667904100823, fit_intercept=True, penalty=l2, score=0.973, total=   0.7s\n",
            "[CV] C=0.08858667904100823, fit_intercept=True, penalty=l2 ...........\n",
            "[CV]  C=0.08858667904100823, fit_intercept=True, penalty=l2, score=0.975, total=   0.7s\n",
            "[CV] C=0.08858667904100823, fit_intercept=True, penalty=l2 ...........\n",
            "[CV]  C=0.08858667904100823, fit_intercept=True, penalty=l2, score=0.965, total=   0.7s\n",
            "[CV] C=0.08858667904100823, fit_intercept=True, penalty=elasticnet ...\n",
            "[CV]  C=0.08858667904100823, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.08858667904100823, fit_intercept=True, penalty=elasticnet ...\n",
            "[CV]  C=0.08858667904100823, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.08858667904100823, fit_intercept=True, penalty=elasticnet ...\n",
            "[CV]  C=0.08858667904100823, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.08858667904100823, fit_intercept=True, penalty=elasticnet ...\n",
            "[CV]  C=0.08858667904100823, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.08858667904100823, fit_intercept=True, penalty=elasticnet ...\n",
            "[CV]  C=0.08858667904100823, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.08858667904100823, fit_intercept=True, penalty=none .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.08858667904100823, fit_intercept=True, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.08858667904100823, fit_intercept=True, penalty=none .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.08858667904100823, fit_intercept=True, penalty=none, score=0.965, total=   0.2s\n",
            "[CV] C=0.08858667904100823, fit_intercept=True, penalty=none .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.08858667904100823, fit_intercept=True, penalty=none, score=0.973, total=   0.2s\n",
            "[CV] C=0.08858667904100823, fit_intercept=True, penalty=none .........\n",
            "[CV]  C=0.08858667904100823, fit_intercept=True, penalty=none, score=0.981, total=   0.4s\n",
            "[CV] C=0.08858667904100823, fit_intercept=True, penalty=none .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.08858667904100823, fit_intercept=True, penalty=none, score=0.969, total=   0.3s\n",
            "[CV] C=0.08858667904100823, fit_intercept=False, penalty=l1 ..........\n",
            "[CV]  C=0.08858667904100823, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.08858667904100823, fit_intercept=False, penalty=l1 ..........\n",
            "[CV]  C=0.08858667904100823, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.08858667904100823, fit_intercept=False, penalty=l1 ..........\n",
            "[CV]  C=0.08858667904100823, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.08858667904100823, fit_intercept=False, penalty=l1 ..........\n",
            "[CV]  C=0.08858667904100823, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.08858667904100823, fit_intercept=False, penalty=l1 ..........\n",
            "[CV]  C=0.08858667904100823, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.08858667904100823, fit_intercept=False, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.08858667904100823, fit_intercept=False, penalty=l2, score=0.985, total=   0.5s\n",
            "[CV] C=0.08858667904100823, fit_intercept=False, penalty=l2 ..........\n",
            "[CV]  C=0.08858667904100823, fit_intercept=False, penalty=l2, score=0.967, total=   0.4s\n",
            "[CV] C=0.08858667904100823, fit_intercept=False, penalty=l2 ..........\n",
            "[CV]  C=0.08858667904100823, fit_intercept=False, penalty=l2, score=0.981, total=   0.5s\n",
            "[CV] C=0.08858667904100823, fit_intercept=False, penalty=l2 ..........\n",
            "[CV]  C=0.08858667904100823, fit_intercept=False, penalty=l2, score=0.983, total=   0.6s\n",
            "[CV] C=0.08858667904100823, fit_intercept=False, penalty=l2 ..........\n",
            "[CV]  C=0.08858667904100823, fit_intercept=False, penalty=l2, score=0.965, total=   0.6s\n",
            "[CV] C=0.08858667904100823, fit_intercept=False, penalty=elasticnet ..\n",
            "[CV]  C=0.08858667904100823, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.08858667904100823, fit_intercept=False, penalty=elasticnet ..\n",
            "[CV]  C=0.08858667904100823, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.08858667904100823, fit_intercept=False, penalty=elasticnet ..\n",
            "[CV]  C=0.08858667904100823, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.08858667904100823, fit_intercept=False, penalty=elasticnet ..\n",
            "[CV]  C=0.08858667904100823, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.08858667904100823, fit_intercept=False, penalty=elasticnet ..\n",
            "[CV]  C=0.08858667904100823, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.08858667904100823, fit_intercept=False, penalty=none ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.08858667904100823, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.08858667904100823, fit_intercept=False, penalty=none ........\n",
            "[CV]  C=0.08858667904100823, fit_intercept=False, penalty=none, score=0.962, total=   0.2s\n",
            "[CV] C=0.08858667904100823, fit_intercept=False, penalty=none ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.08858667904100823, fit_intercept=False, penalty=none, score=0.979, total=   0.3s\n",
            "[CV] C=0.08858667904100823, fit_intercept=False, penalty=none ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.08858667904100823, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.08858667904100823, fit_intercept=False, penalty=none ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.08858667904100823, fit_intercept=False, penalty=none, score=0.971, total=   0.3s\n",
            "[CV] C=0.23357214690901212, fit_intercept=True, penalty=l1 ...........\n",
            "[CV]  C=0.23357214690901212, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.23357214690901212, fit_intercept=True, penalty=l1 ...........\n",
            "[CV]  C=0.23357214690901212, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.23357214690901212, fit_intercept=True, penalty=l1 ...........\n",
            "[CV]  C=0.23357214690901212, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.23357214690901212, fit_intercept=True, penalty=l1 ...........\n",
            "[CV]  C=0.23357214690901212, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.23357214690901212, fit_intercept=True, penalty=l1 ...........\n",
            "[CV]  C=0.23357214690901212, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.23357214690901212, fit_intercept=True, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.23357214690901212, fit_intercept=True, penalty=l2, score=0.987, total=   0.7s\n",
            "[CV] C=0.23357214690901212, fit_intercept=True, penalty=l2 ...........\n",
            "[CV]  C=0.23357214690901212, fit_intercept=True, penalty=l2, score=0.967, total=   0.5s\n",
            "[CV] C=0.23357214690901212, fit_intercept=True, penalty=l2 ...........\n",
            "[CV]  C=0.23357214690901212, fit_intercept=True, penalty=l2, score=0.973, total=   0.7s\n",
            "[CV] C=0.23357214690901212, fit_intercept=True, penalty=l2 ...........\n",
            "[CV]  C=0.23357214690901212, fit_intercept=True, penalty=l2, score=0.985, total=   0.8s\n",
            "[CV] C=0.23357214690901212, fit_intercept=True, penalty=l2 ...........\n",
            "[CV]  C=0.23357214690901212, fit_intercept=True, penalty=l2, score=0.967, total=   0.8s\n",
            "[CV] C=0.23357214690901212, fit_intercept=True, penalty=elasticnet ...\n",
            "[CV]  C=0.23357214690901212, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.23357214690901212, fit_intercept=True, penalty=elasticnet ...\n",
            "[CV]  C=0.23357214690901212, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.23357214690901212, fit_intercept=True, penalty=elasticnet ...\n",
            "[CV]  C=0.23357214690901212, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.23357214690901212, fit_intercept=True, penalty=elasticnet ...\n",
            "[CV]  C=0.23357214690901212, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.23357214690901212, fit_intercept=True, penalty=elasticnet ...\n",
            "[CV]  C=0.23357214690901212, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.23357214690901212, fit_intercept=True, penalty=none .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.23357214690901212, fit_intercept=True, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.23357214690901212, fit_intercept=True, penalty=none .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.23357214690901212, fit_intercept=True, penalty=none, score=0.965, total=   0.2s\n",
            "[CV] C=0.23357214690901212, fit_intercept=True, penalty=none .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.23357214690901212, fit_intercept=True, penalty=none, score=0.973, total=   0.2s\n",
            "[CV] C=0.23357214690901212, fit_intercept=True, penalty=none .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.23357214690901212, fit_intercept=True, penalty=none, score=0.981, total=   0.3s\n",
            "[CV] C=0.23357214690901212, fit_intercept=True, penalty=none .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.23357214690901212, fit_intercept=True, penalty=none, score=0.969, total=   0.3s\n",
            "[CV] C=0.23357214690901212, fit_intercept=False, penalty=l1 ..........\n",
            "[CV]  C=0.23357214690901212, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.23357214690901212, fit_intercept=False, penalty=l1 ..........\n",
            "[CV]  C=0.23357214690901212, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.23357214690901212, fit_intercept=False, penalty=l1 ..........\n",
            "[CV]  C=0.23357214690901212, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.23357214690901212, fit_intercept=False, penalty=l1 ..........\n",
            "[CV]  C=0.23357214690901212, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.23357214690901212, fit_intercept=False, penalty=l1 ..........\n",
            "[CV]  C=0.23357214690901212, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.23357214690901212, fit_intercept=False, penalty=l2 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.23357214690901212, fit_intercept=False, penalty=l2, score=0.988, total=   0.7s\n",
            "[CV] C=0.23357214690901212, fit_intercept=False, penalty=l2 ..........\n",
            "[CV]  C=0.23357214690901212, fit_intercept=False, penalty=l2, score=0.971, total=   0.5s\n",
            "[CV] C=0.23357214690901212, fit_intercept=False, penalty=l2 ..........\n",
            "[CV]  C=0.23357214690901212, fit_intercept=False, penalty=l2, score=0.975, total=   0.7s\n",
            "[CV] C=0.23357214690901212, fit_intercept=False, penalty=l2 ..........\n",
            "[CV]  C=0.23357214690901212, fit_intercept=False, penalty=l2, score=0.985, total=   0.8s\n",
            "[CV] C=0.23357214690901212, fit_intercept=False, penalty=l2 ..........\n",
            "[CV]  C=0.23357214690901212, fit_intercept=False, penalty=l2, score=0.969, total=   0.7s\n",
            "[CV] C=0.23357214690901212, fit_intercept=False, penalty=elasticnet ..\n",
            "[CV]  C=0.23357214690901212, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.23357214690901212, fit_intercept=False, penalty=elasticnet ..\n",
            "[CV]  C=0.23357214690901212, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.23357214690901212, fit_intercept=False, penalty=elasticnet ..\n",
            "[CV]  C=0.23357214690901212, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.23357214690901212, fit_intercept=False, penalty=elasticnet ..\n",
            "[CV]  C=0.23357214690901212, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.23357214690901212, fit_intercept=False, penalty=elasticnet ..\n",
            "[CV]  C=0.23357214690901212, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.23357214690901212, fit_intercept=False, penalty=none ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.23357214690901212, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.23357214690901212, fit_intercept=False, penalty=none ........\n",
            "[CV]  C=0.23357214690901212, fit_intercept=False, penalty=none, score=0.962, total=   0.2s\n",
            "[CV] C=0.23357214690901212, fit_intercept=False, penalty=none ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.23357214690901212, fit_intercept=False, penalty=none, score=0.979, total=   0.3s\n",
            "[CV] C=0.23357214690901212, fit_intercept=False, penalty=none ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.23357214690901212, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.23357214690901212, fit_intercept=False, penalty=none ........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.23357214690901212, fit_intercept=False, penalty=none, score=0.971, total=   0.3s\n",
            "[CV] C=0.615848211066026, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=0.615848211066026, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.615848211066026, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=0.615848211066026, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.615848211066026, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=0.615848211066026, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.615848211066026, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=0.615848211066026, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.615848211066026, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=0.615848211066026, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.615848211066026, fit_intercept=True, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.615848211066026, fit_intercept=True, penalty=l2, score=0.988, total=   0.8s\n",
            "[CV] C=0.615848211066026, fit_intercept=True, penalty=l2 .............\n",
            "[CV]  C=0.615848211066026, fit_intercept=True, penalty=l2, score=0.969, total=   0.7s\n",
            "[CV] C=0.615848211066026, fit_intercept=True, penalty=l2 .............\n",
            "[CV]  C=0.615848211066026, fit_intercept=True, penalty=l2, score=0.973, total=   0.8s\n",
            "[CV] C=0.615848211066026, fit_intercept=True, penalty=l2 .............\n",
            "[CV]  C=0.615848211066026, fit_intercept=True, penalty=l2, score=0.985, total=   0.9s\n",
            "[CV] C=0.615848211066026, fit_intercept=True, penalty=l2 .............\n",
            "[CV]  C=0.615848211066026, fit_intercept=True, penalty=l2, score=0.967, total=   0.8s\n",
            "[CV] C=0.615848211066026, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=0.615848211066026, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.615848211066026, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=0.615848211066026, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.615848211066026, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=0.615848211066026, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.615848211066026, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=0.615848211066026, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.615848211066026, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=0.615848211066026, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.615848211066026, fit_intercept=True, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.615848211066026, fit_intercept=True, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.615848211066026, fit_intercept=True, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.615848211066026, fit_intercept=True, penalty=none, score=0.965, total=   0.2s\n",
            "[CV] C=0.615848211066026, fit_intercept=True, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.615848211066026, fit_intercept=True, penalty=none, score=0.973, total=   0.2s\n",
            "[CV] C=0.615848211066026, fit_intercept=True, penalty=none ...........\n",
            "[CV]  C=0.615848211066026, fit_intercept=True, penalty=none, score=0.981, total=   0.4s\n",
            "[CV] C=0.615848211066026, fit_intercept=True, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.615848211066026, fit_intercept=True, penalty=none, score=0.969, total=   0.3s\n",
            "[CV] C=0.615848211066026, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=0.615848211066026, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.615848211066026, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=0.615848211066026, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.615848211066026, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=0.615848211066026, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.615848211066026, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=0.615848211066026, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.615848211066026, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=0.615848211066026, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=0.615848211066026, fit_intercept=False, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.615848211066026, fit_intercept=False, penalty=l2, score=0.988, total=   0.8s\n",
            "[CV] C=0.615848211066026, fit_intercept=False, penalty=l2 ............\n",
            "[CV]  C=0.615848211066026, fit_intercept=False, penalty=l2, score=0.973, total=   0.8s\n",
            "[CV] C=0.615848211066026, fit_intercept=False, penalty=l2 ............\n",
            "[CV]  C=0.615848211066026, fit_intercept=False, penalty=l2, score=0.975, total=   0.8s\n",
            "[CV] C=0.615848211066026, fit_intercept=False, penalty=l2 ............\n",
            "[CV]  C=0.615848211066026, fit_intercept=False, penalty=l2, score=0.985, total=   0.9s\n",
            "[CV] C=0.615848211066026, fit_intercept=False, penalty=l2 ............\n",
            "[CV]  C=0.615848211066026, fit_intercept=False, penalty=l2, score=0.969, total=   0.9s\n",
            "[CV] C=0.615848211066026, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=0.615848211066026, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.615848211066026, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=0.615848211066026, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.615848211066026, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=0.615848211066026, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.615848211066026, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=0.615848211066026, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.615848211066026, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=0.615848211066026, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=0.615848211066026, fit_intercept=False, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.615848211066026, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.615848211066026, fit_intercept=False, penalty=none ..........\n",
            "[CV]  C=0.615848211066026, fit_intercept=False, penalty=none, score=0.962, total=   0.2s\n",
            "[CV] C=0.615848211066026, fit_intercept=False, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.615848211066026, fit_intercept=False, penalty=none, score=0.979, total=   0.3s\n",
            "[CV] C=0.615848211066026, fit_intercept=False, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.615848211066026, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=0.615848211066026, fit_intercept=False, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=0.615848211066026, fit_intercept=False, penalty=none, score=0.971, total=   0.3s\n",
            "[CV] C=1.623776739188721, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=1.623776739188721, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=1.623776739188721, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=1.623776739188721, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=1.623776739188721, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=1.623776739188721, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=1.623776739188721, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=1.623776739188721, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=1.623776739188721, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=1.623776739188721, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=1.623776739188721, fit_intercept=True, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1.623776739188721, fit_intercept=True, penalty=l2, score=0.987, total=   1.0s\n",
            "[CV] C=1.623776739188721, fit_intercept=True, penalty=l2 .............\n",
            "[CV]  C=1.623776739188721, fit_intercept=True, penalty=l2, score=0.971, total=   0.8s\n",
            "[CV] C=1.623776739188721, fit_intercept=True, penalty=l2 .............\n",
            "[CV]  C=1.623776739188721, fit_intercept=True, penalty=l2, score=0.973, total=   1.0s\n",
            "[CV] C=1.623776739188721, fit_intercept=True, penalty=l2 .............\n",
            "[CV]  C=1.623776739188721, fit_intercept=True, penalty=l2, score=0.981, total=   1.0s\n",
            "[CV] C=1.623776739188721, fit_intercept=True, penalty=l2 .............\n",
            "[CV]  C=1.623776739188721, fit_intercept=True, penalty=l2, score=0.969, total=   0.9s\n",
            "[CV] C=1.623776739188721, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=1.623776739188721, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=1.623776739188721, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=1.623776739188721, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=1.623776739188721, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=1.623776739188721, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=1.623776739188721, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=1.623776739188721, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=1.623776739188721, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=1.623776739188721, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=1.623776739188721, fit_intercept=True, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1.623776739188721, fit_intercept=True, penalty=none, score=0.977, total=   0.4s\n",
            "[CV] C=1.623776739188721, fit_intercept=True, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1.623776739188721, fit_intercept=True, penalty=none, score=0.965, total=   0.3s\n",
            "[CV] C=1.623776739188721, fit_intercept=True, penalty=none ...........\n",
            "[CV]  C=1.623776739188721, fit_intercept=True, penalty=none, score=0.973, total=   0.2s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[CV] C=1.623776739188721, fit_intercept=True, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1.623776739188721, fit_intercept=True, penalty=none, score=0.981, total=   0.4s\n",
            "[CV] C=1.623776739188721, fit_intercept=True, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1.623776739188721, fit_intercept=True, penalty=none, score=0.969, total=   0.3s\n",
            "[CV] C=1.623776739188721, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=1.623776739188721, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=1.623776739188721, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=1.623776739188721, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=1.623776739188721, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=1.623776739188721, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=1.623776739188721, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=1.623776739188721, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=1.623776739188721, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=1.623776739188721, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=1.623776739188721, fit_intercept=False, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1.623776739188721, fit_intercept=False, penalty=l2, score=0.983, total=   0.9s\n",
            "[CV] C=1.623776739188721, fit_intercept=False, penalty=l2 ............\n",
            "[CV]  C=1.623776739188721, fit_intercept=False, penalty=l2, score=0.971, total=   0.8s\n",
            "[CV] C=1.623776739188721, fit_intercept=False, penalty=l2 ............\n",
            "[CV]  C=1.623776739188721, fit_intercept=False, penalty=l2, score=0.973, total=   0.9s\n",
            "[CV] C=1.623776739188721, fit_intercept=False, penalty=l2 ............\n",
            "[CV]  C=1.623776739188721, fit_intercept=False, penalty=l2, score=0.979, total=   1.0s\n",
            "[CV] C=1.623776739188721, fit_intercept=False, penalty=l2 ............\n",
            "[CV]  C=1.623776739188721, fit_intercept=False, penalty=l2, score=0.971, total=   0.9s\n",
            "[CV] C=1.623776739188721, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=1.623776739188721, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=1.623776739188721, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=1.623776739188721, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=1.623776739188721, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=1.623776739188721, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=1.623776739188721, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=1.623776739188721, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=1.623776739188721, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=1.623776739188721, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=1.623776739188721, fit_intercept=False, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1.623776739188721, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=1.623776739188721, fit_intercept=False, penalty=none ..........\n",
            "[CV]  C=1.623776739188721, fit_intercept=False, penalty=none, score=0.962, total=   0.2s\n",
            "[CV] C=1.623776739188721, fit_intercept=False, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1.623776739188721, fit_intercept=False, penalty=none, score=0.979, total=   0.3s\n",
            "[CV] C=1.623776739188721, fit_intercept=False, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1.623776739188721, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=1.623776739188721, fit_intercept=False, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1.623776739188721, fit_intercept=False, penalty=none, score=0.971, total=   0.3s\n",
            "[CV] C=4.281332398719396, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=4.281332398719396, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=4.281332398719396, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=4.281332398719396, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=4.281332398719396, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=4.281332398719396, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=4.281332398719396, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=4.281332398719396, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=4.281332398719396, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=4.281332398719396, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=4.281332398719396, fit_intercept=True, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=4.281332398719396, fit_intercept=True, penalty=l2, score=0.983, total=   1.2s\n",
            "[CV] C=4.281332398719396, fit_intercept=True, penalty=l2 .............\n",
            "[CV]  C=4.281332398719396, fit_intercept=True, penalty=l2, score=0.967, total=   0.9s\n",
            "[CV] C=4.281332398719396, fit_intercept=True, penalty=l2 .............\n",
            "[CV]  C=4.281332398719396, fit_intercept=True, penalty=l2, score=0.967, total=   1.1s\n",
            "[CV] C=4.281332398719396, fit_intercept=True, penalty=l2 .............\n",
            "[CV]  C=4.281332398719396, fit_intercept=True, penalty=l2, score=0.979, total=   1.4s\n",
            "[CV] C=4.281332398719396, fit_intercept=True, penalty=l2 .............\n",
            "[CV]  C=4.281332398719396, fit_intercept=True, penalty=l2, score=0.973, total=   1.2s\n",
            "[CV] C=4.281332398719396, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=4.281332398719396, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=4.281332398719396, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=4.281332398719396, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=4.281332398719396, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=4.281332398719396, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=4.281332398719396, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=4.281332398719396, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=4.281332398719396, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=4.281332398719396, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=4.281332398719396, fit_intercept=True, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=4.281332398719396, fit_intercept=True, penalty=none, score=0.977, total=   0.4s\n",
            "[CV] C=4.281332398719396, fit_intercept=True, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=4.281332398719396, fit_intercept=True, penalty=none, score=0.965, total=   0.2s\n",
            "[CV] C=4.281332398719396, fit_intercept=True, penalty=none ...........\n",
            "[CV]  C=4.281332398719396, fit_intercept=True, penalty=none, score=0.973, total=   0.2s\n",
            "[CV] C=4.281332398719396, fit_intercept=True, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=4.281332398719396, fit_intercept=True, penalty=none, score=0.981, total=   0.3s\n",
            "[CV] C=4.281332398719396, fit_intercept=True, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=4.281332398719396, fit_intercept=True, penalty=none, score=0.969, total=   0.3s\n",
            "[CV] C=4.281332398719396, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=4.281332398719396, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=4.281332398719396, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=4.281332398719396, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=4.281332398719396, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=4.281332398719396, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=4.281332398719396, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=4.281332398719396, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=4.281332398719396, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=4.281332398719396, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=4.281332398719396, fit_intercept=False, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=4.281332398719396, fit_intercept=False, penalty=l2, score=0.983, total=   1.1s\n",
            "[CV] C=4.281332398719396, fit_intercept=False, penalty=l2 ............\n",
            "[CV]  C=4.281332398719396, fit_intercept=False, penalty=l2, score=0.971, total=   0.9s\n",
            "[CV] C=4.281332398719396, fit_intercept=False, penalty=l2 ............\n",
            "[CV]  C=4.281332398719396, fit_intercept=False, penalty=l2, score=0.969, total=   1.0s\n",
            "[CV] C=4.281332398719396, fit_intercept=False, penalty=l2 ............\n",
            "[CV]  C=4.281332398719396, fit_intercept=False, penalty=l2, score=0.979, total=   1.2s\n",
            "[CV] C=4.281332398719396, fit_intercept=False, penalty=l2 ............\n",
            "[CV]  C=4.281332398719396, fit_intercept=False, penalty=l2, score=0.973, total=   1.1s\n",
            "[CV] C=4.281332398719396, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=4.281332398719396, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=4.281332398719396, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=4.281332398719396, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=4.281332398719396, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=4.281332398719396, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=4.281332398719396, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=4.281332398719396, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=4.281332398719396, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=4.281332398719396, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=4.281332398719396, fit_intercept=False, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=4.281332398719396, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=4.281332398719396, fit_intercept=False, penalty=none ..........\n",
            "[CV]  C=4.281332398719396, fit_intercept=False, penalty=none, score=0.962, total=   0.2s\n",
            "[CV] C=4.281332398719396, fit_intercept=False, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=4.281332398719396, fit_intercept=False, penalty=none, score=0.979, total=   0.3s\n",
            "[CV] C=4.281332398719396, fit_intercept=False, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=4.281332398719396, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=4.281332398719396, fit_intercept=False, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=4.281332398719396, fit_intercept=False, penalty=none, score=0.971, total=   0.3s\n",
            "[CV] C=11.288378916846883, fit_intercept=True, penalty=l1 ............\n",
            "[CV]  C=11.288378916846883, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=11.288378916846883, fit_intercept=True, penalty=l1 ............\n",
            "[CV]  C=11.288378916846883, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=11.288378916846883, fit_intercept=True, penalty=l1 ............\n",
            "[CV]  C=11.288378916846883, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=11.288378916846883, fit_intercept=True, penalty=l1 ............\n",
            "[CV]  C=11.288378916846883, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=11.288378916846883, fit_intercept=True, penalty=l1 ............\n",
            "[CV]  C=11.288378916846883, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=11.288378916846883, fit_intercept=True, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=11.288378916846883, fit_intercept=True, penalty=l2, score=0.985, total=   1.2s\n",
            "[CV] C=11.288378916846883, fit_intercept=True, penalty=l2 ............\n",
            "[CV]  C=11.288378916846883, fit_intercept=True, penalty=l2, score=0.975, total=   1.0s\n",
            "[CV] C=11.288378916846883, fit_intercept=True, penalty=l2 ............\n",
            "[CV]  C=11.288378916846883, fit_intercept=True, penalty=l2, score=0.965, total=   1.4s\n",
            "[CV] C=11.288378916846883, fit_intercept=True, penalty=l2 ............\n",
            "[CV]  C=11.288378916846883, fit_intercept=True, penalty=l2, score=0.979, total=   1.5s\n",
            "[CV] C=11.288378916846883, fit_intercept=True, penalty=l2 ............\n",
            "[CV]  C=11.288378916846883, fit_intercept=True, penalty=l2, score=0.975, total=   1.4s\n",
            "[CV] C=11.288378916846883, fit_intercept=True, penalty=elasticnet ....\n",
            "[CV]  C=11.288378916846883, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=11.288378916846883, fit_intercept=True, penalty=elasticnet ....\n",
            "[CV]  C=11.288378916846883, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=11.288378916846883, fit_intercept=True, penalty=elasticnet ....\n",
            "[CV]  C=11.288378916846883, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=11.288378916846883, fit_intercept=True, penalty=elasticnet ....\n",
            "[CV]  C=11.288378916846883, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=11.288378916846883, fit_intercept=True, penalty=elasticnet ....\n",
            "[CV]  C=11.288378916846883, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=11.288378916846883, fit_intercept=True, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=11.288378916846883, fit_intercept=True, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=11.288378916846883, fit_intercept=True, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=11.288378916846883, fit_intercept=True, penalty=none, score=0.965, total=   0.3s\n",
            "[CV] C=11.288378916846883, fit_intercept=True, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=11.288378916846883, fit_intercept=True, penalty=none, score=0.973, total=   0.2s\n",
            "[CV] C=11.288378916846883, fit_intercept=True, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=11.288378916846883, fit_intercept=True, penalty=none, score=0.981, total=   0.3s\n",
            "[CV] C=11.288378916846883, fit_intercept=True, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=11.288378916846883, fit_intercept=True, penalty=none, score=0.969, total=   0.3s\n",
            "[CV] C=11.288378916846883, fit_intercept=False, penalty=l1 ...........\n",
            "[CV]  C=11.288378916846883, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=11.288378916846883, fit_intercept=False, penalty=l1 ...........\n",
            "[CV]  C=11.288378916846883, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=11.288378916846883, fit_intercept=False, penalty=l1 ...........\n",
            "[CV]  C=11.288378916846883, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=11.288378916846883, fit_intercept=False, penalty=l1 ...........\n",
            "[CV]  C=11.288378916846883, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=11.288378916846883, fit_intercept=False, penalty=l1 ...........\n",
            "[CV]  C=11.288378916846883, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=11.288378916846883, fit_intercept=False, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=11.288378916846883, fit_intercept=False, penalty=l2, score=0.983, total=   1.1s\n",
            "[CV] C=11.288378916846883, fit_intercept=False, penalty=l2 ...........\n",
            "[CV]  C=11.288378916846883, fit_intercept=False, penalty=l2, score=0.973, total=   1.1s\n",
            "[CV] C=11.288378916846883, fit_intercept=False, penalty=l2 ...........\n",
            "[CV]  C=11.288378916846883, fit_intercept=False, penalty=l2, score=0.967, total=   1.2s\n",
            "[CV] C=11.288378916846883, fit_intercept=False, penalty=l2 ...........\n",
            "[CV]  C=11.288378916846883, fit_intercept=False, penalty=l2, score=0.977, total=   1.4s\n",
            "[CV] C=11.288378916846883, fit_intercept=False, penalty=l2 ...........\n",
            "[CV]  C=11.288378916846883, fit_intercept=False, penalty=l2, score=0.977, total=   1.2s\n",
            "[CV] C=11.288378916846883, fit_intercept=False, penalty=elasticnet ...\n",
            "[CV]  C=11.288378916846883, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=11.288378916846883, fit_intercept=False, penalty=elasticnet ...\n",
            "[CV]  C=11.288378916846883, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=11.288378916846883, fit_intercept=False, penalty=elasticnet ...\n",
            "[CV]  C=11.288378916846883, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=11.288378916846883, fit_intercept=False, penalty=elasticnet ...\n",
            "[CV]  C=11.288378916846883, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=11.288378916846883, fit_intercept=False, penalty=elasticnet ...\n",
            "[CV]  C=11.288378916846883, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=11.288378916846883, fit_intercept=False, penalty=none .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=11.288378916846883, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=11.288378916846883, fit_intercept=False, penalty=none .........\n",
            "[CV]  C=11.288378916846883, fit_intercept=False, penalty=none, score=0.962, total=   0.2s\n",
            "[CV] C=11.288378916846883, fit_intercept=False, penalty=none .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=11.288378916846883, fit_intercept=False, penalty=none, score=0.979, total=   0.3s\n",
            "[CV] C=11.288378916846883, fit_intercept=False, penalty=none .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=11.288378916846883, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=11.288378916846883, fit_intercept=False, penalty=none .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=11.288378916846883, fit_intercept=False, penalty=none, score=0.971, total=   0.3s\n",
            "[CV] C=29.763514416313132, fit_intercept=True, penalty=l1 ............\n",
            "[CV]  C=29.763514416313132, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=29.763514416313132, fit_intercept=True, penalty=l1 ............\n",
            "[CV]  C=29.763514416313132, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=29.763514416313132, fit_intercept=True, penalty=l1 ............\n",
            "[CV]  C=29.763514416313132, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=29.763514416313132, fit_intercept=True, penalty=l1 ............\n",
            "[CV]  C=29.763514416313132, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=29.763514416313132, fit_intercept=True, penalty=l1 ............\n",
            "[CV]  C=29.763514416313132, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=29.763514416313132, fit_intercept=True, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=29.763514416313132, fit_intercept=True, penalty=l2, score=0.983, total=   1.3s\n",
            "[CV] C=29.763514416313132, fit_intercept=True, penalty=l2 ............\n",
            "[CV]  C=29.763514416313132, fit_intercept=True, penalty=l2, score=0.971, total=   1.1s\n",
            "[CV] C=29.763514416313132, fit_intercept=True, penalty=l2 ............\n",
            "[CV]  C=29.763514416313132, fit_intercept=True, penalty=l2, score=0.963, total=   1.5s\n",
            "[CV] C=29.763514416313132, fit_intercept=True, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=29.763514416313132, fit_intercept=True, penalty=l2, score=0.977, total=   1.6s\n",
            "[CV] C=29.763514416313132, fit_intercept=True, penalty=l2 ............\n",
            "[CV]  C=29.763514416313132, fit_intercept=True, penalty=l2, score=0.973, total=   1.4s\n",
            "[CV] C=29.763514416313132, fit_intercept=True, penalty=elasticnet ....\n",
            "[CV]  C=29.763514416313132, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=29.763514416313132, fit_intercept=True, penalty=elasticnet ....\n",
            "[CV]  C=29.763514416313132, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=29.763514416313132, fit_intercept=True, penalty=elasticnet ....\n",
            "[CV]  C=29.763514416313132, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=29.763514416313132, fit_intercept=True, penalty=elasticnet ....\n",
            "[CV]  C=29.763514416313132, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=29.763514416313132, fit_intercept=True, penalty=elasticnet ....\n",
            "[CV]  C=29.763514416313132, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=29.763514416313132, fit_intercept=True, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=29.763514416313132, fit_intercept=True, penalty=none, score=0.977, total=   0.4s\n",
            "[CV] C=29.763514416313132, fit_intercept=True, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=29.763514416313132, fit_intercept=True, penalty=none, score=0.965, total=   0.3s\n",
            "[CV] C=29.763514416313132, fit_intercept=True, penalty=none ..........\n",
            "[CV]  C=29.763514416313132, fit_intercept=True, penalty=none, score=0.973, total=   0.2s\n",
            "[CV] C=29.763514416313132, fit_intercept=True, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=29.763514416313132, fit_intercept=True, penalty=none, score=0.981, total=   0.3s\n",
            "[CV] C=29.763514416313132, fit_intercept=True, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=29.763514416313132, fit_intercept=True, penalty=none, score=0.969, total=   0.3s\n",
            "[CV] C=29.763514416313132, fit_intercept=False, penalty=l1 ...........\n",
            "[CV]  C=29.763514416313132, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=29.763514416313132, fit_intercept=False, penalty=l1 ...........\n",
            "[CV]  C=29.763514416313132, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=29.763514416313132, fit_intercept=False, penalty=l1 ...........\n",
            "[CV]  C=29.763514416313132, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=29.763514416313132, fit_intercept=False, penalty=l1 ...........\n",
            "[CV]  C=29.763514416313132, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=29.763514416313132, fit_intercept=False, penalty=l1 ...........\n",
            "[CV]  C=29.763514416313132, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=29.763514416313132, fit_intercept=False, penalty=l2 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=29.763514416313132, fit_intercept=False, penalty=l2, score=0.981, total=   1.3s\n",
            "[CV] C=29.763514416313132, fit_intercept=False, penalty=l2 ...........\n",
            "[CV]  C=29.763514416313132, fit_intercept=False, penalty=l2, score=0.971, total=   1.1s\n",
            "[CV] C=29.763514416313132, fit_intercept=False, penalty=l2 ...........\n",
            "[CV]  C=29.763514416313132, fit_intercept=False, penalty=l2, score=0.965, total=   1.5s\n",
            "[CV] C=29.763514416313132, fit_intercept=False, penalty=l2 ...........\n",
            "[CV]  C=29.763514416313132, fit_intercept=False, penalty=l2, score=0.977, total=   1.5s\n",
            "[CV] C=29.763514416313132, fit_intercept=False, penalty=l2 ...........\n",
            "[CV]  C=29.763514416313132, fit_intercept=False, penalty=l2, score=0.975, total=   1.3s\n",
            "[CV] C=29.763514416313132, fit_intercept=False, penalty=elasticnet ...\n",
            "[CV]  C=29.763514416313132, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=29.763514416313132, fit_intercept=False, penalty=elasticnet ...\n",
            "[CV]  C=29.763514416313132, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=29.763514416313132, fit_intercept=False, penalty=elasticnet ...\n",
            "[CV]  C=29.763514416313132, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=29.763514416313132, fit_intercept=False, penalty=elasticnet ...\n",
            "[CV]  C=29.763514416313132, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=29.763514416313132, fit_intercept=False, penalty=elasticnet ...\n",
            "[CV]  C=29.763514416313132, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=29.763514416313132, fit_intercept=False, penalty=none .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=29.763514416313132, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=29.763514416313132, fit_intercept=False, penalty=none .........\n",
            "[CV]  C=29.763514416313132, fit_intercept=False, penalty=none, score=0.962, total=   0.2s\n",
            "[CV] C=29.763514416313132, fit_intercept=False, penalty=none .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=29.763514416313132, fit_intercept=False, penalty=none, score=0.979, total=   0.3s\n",
            "[CV] C=29.763514416313132, fit_intercept=False, penalty=none .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=29.763514416313132, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=29.763514416313132, fit_intercept=False, penalty=none .........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=29.763514416313132, fit_intercept=False, penalty=none, score=0.971, total=   0.3s\n",
            "[CV] C=78.47599703514607, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=78.47599703514607, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=78.47599703514607, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=78.47599703514607, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=78.47599703514607, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=78.47599703514607, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=78.47599703514607, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=78.47599703514607, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=78.47599703514607, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=78.47599703514607, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=78.47599703514607, fit_intercept=True, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=78.47599703514607, fit_intercept=True, penalty=l2, score=0.981, total=   1.4s\n",
            "[CV] C=78.47599703514607, fit_intercept=True, penalty=l2 .............\n",
            "[CV]  C=78.47599703514607, fit_intercept=True, penalty=l2, score=0.969, total=   1.2s\n",
            "[CV] C=78.47599703514607, fit_intercept=True, penalty=l2 .............\n",
            "[CV]  C=78.47599703514607, fit_intercept=True, penalty=l2, score=0.967, total=   1.6s\n",
            "[CV] C=78.47599703514607, fit_intercept=True, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=78.47599703514607, fit_intercept=True, penalty=l2, score=0.981, total=   1.6s\n",
            "[CV] C=78.47599703514607, fit_intercept=True, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=78.47599703514607, fit_intercept=True, penalty=l2, score=0.973, total=   1.7s\n",
            "[CV] C=78.47599703514607, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=78.47599703514607, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=78.47599703514607, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=78.47599703514607, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=78.47599703514607, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=78.47599703514607, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=78.47599703514607, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=78.47599703514607, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=78.47599703514607, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=78.47599703514607, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=78.47599703514607, fit_intercept=True, penalty=none ...........\n",
            "[CV]  C=78.47599703514607, fit_intercept=True, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=78.47599703514607, fit_intercept=True, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=78.47599703514607, fit_intercept=True, penalty=none, score=0.965, total=   0.2s\n",
            "[CV] C=78.47599703514607, fit_intercept=True, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=78.47599703514607, fit_intercept=True, penalty=none, score=0.973, total=   0.2s\n",
            "[CV] C=78.47599703514607, fit_intercept=True, penalty=none ...........\n",
            "[CV]  C=78.47599703514607, fit_intercept=True, penalty=none, score=0.981, total=   0.3s\n",
            "[CV] C=78.47599703514607, fit_intercept=True, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=78.47599703514607, fit_intercept=True, penalty=none, score=0.969, total=   0.3s\n",
            "[CV] C=78.47599703514607, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=78.47599703514607, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=78.47599703514607, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=78.47599703514607, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=78.47599703514607, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=78.47599703514607, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=78.47599703514607, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=78.47599703514607, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=78.47599703514607, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=78.47599703514607, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=78.47599703514607, fit_intercept=False, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=78.47599703514607, fit_intercept=False, penalty=l2, score=0.981, total=   1.4s\n",
            "[CV] C=78.47599703514607, fit_intercept=False, penalty=l2 ............\n",
            "[CV]  C=78.47599703514607, fit_intercept=False, penalty=l2, score=0.971, total=   1.3s\n",
            "[CV] C=78.47599703514607, fit_intercept=False, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=78.47599703514607, fit_intercept=False, penalty=l2, score=0.965, total=   1.6s\n",
            "[CV] C=78.47599703514607, fit_intercept=False, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=78.47599703514607, fit_intercept=False, penalty=l2, score=0.977, total=   1.7s\n",
            "[CV] C=78.47599703514607, fit_intercept=False, penalty=l2 ............\n",
            "[CV]  C=78.47599703514607, fit_intercept=False, penalty=l2, score=0.977, total=   1.5s\n",
            "[CV] C=78.47599703514607, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=78.47599703514607, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=78.47599703514607, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=78.47599703514607, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=78.47599703514607, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=78.47599703514607, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=78.47599703514607, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=78.47599703514607, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=78.47599703514607, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=78.47599703514607, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=78.47599703514607, fit_intercept=False, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=78.47599703514607, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=78.47599703514607, fit_intercept=False, penalty=none ..........\n",
            "[CV]  C=78.47599703514607, fit_intercept=False, penalty=none, score=0.962, total=   0.2s\n",
            "[CV] C=78.47599703514607, fit_intercept=False, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=78.47599703514607, fit_intercept=False, penalty=none, score=0.979, total=   0.3s\n",
            "[CV] C=78.47599703514607, fit_intercept=False, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=78.47599703514607, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=78.47599703514607, fit_intercept=False, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=78.47599703514607, fit_intercept=False, penalty=none, score=0.971, total=   0.3s\n",
            "[CV] C=206.913808111479, fit_intercept=True, penalty=l1 ..............\n",
            "[CV]  C=206.913808111479, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=206.913808111479, fit_intercept=True, penalty=l1 ..............\n",
            "[CV]  C=206.913808111479, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=206.913808111479, fit_intercept=True, penalty=l1 ..............\n",
            "[CV]  C=206.913808111479, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=206.913808111479, fit_intercept=True, penalty=l1 ..............\n",
            "[CV]  C=206.913808111479, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=206.913808111479, fit_intercept=True, penalty=l1 ..............\n",
            "[CV]  C=206.913808111479, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=206.913808111479, fit_intercept=True, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=206.913808111479, fit_intercept=True, penalty=l2, score=0.981, total=   1.4s\n",
            "[CV] C=206.913808111479, fit_intercept=True, penalty=l2 ..............\n",
            "[CV]  C=206.913808111479, fit_intercept=True, penalty=l2, score=0.969, total=   1.4s\n",
            "[CV] C=206.913808111479, fit_intercept=True, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=206.913808111479, fit_intercept=True, penalty=l2, score=0.965, total=   1.6s\n",
            "[CV] C=206.913808111479, fit_intercept=True, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=206.913808111479, fit_intercept=True, penalty=l2, score=0.979, total=   1.7s\n",
            "[CV] C=206.913808111479, fit_intercept=True, penalty=l2 ..............\n",
            "[CV]  C=206.913808111479, fit_intercept=True, penalty=l2, score=0.967, total=   1.7s\n",
            "[CV] C=206.913808111479, fit_intercept=True, penalty=elasticnet ......\n",
            "[CV]  C=206.913808111479, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=206.913808111479, fit_intercept=True, penalty=elasticnet ......\n",
            "[CV]  C=206.913808111479, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=206.913808111479, fit_intercept=True, penalty=elasticnet ......\n",
            "[CV]  C=206.913808111479, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=206.913808111479, fit_intercept=True, penalty=elasticnet ......\n",
            "[CV]  C=206.913808111479, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=206.913808111479, fit_intercept=True, penalty=elasticnet ......\n",
            "[CV]  C=206.913808111479, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=206.913808111479, fit_intercept=True, penalty=none ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=206.913808111479, fit_intercept=True, penalty=none, score=0.977, total=   0.4s\n",
            "[CV] C=206.913808111479, fit_intercept=True, penalty=none ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=206.913808111479, fit_intercept=True, penalty=none, score=0.965, total=   0.3s\n",
            "[CV] C=206.913808111479, fit_intercept=True, penalty=none ............\n",
            "[CV]  C=206.913808111479, fit_intercept=True, penalty=none, score=0.973, total=   0.2s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[CV] C=206.913808111479, fit_intercept=True, penalty=none ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=206.913808111479, fit_intercept=True, penalty=none, score=0.981, total=   0.3s\n",
            "[CV] C=206.913808111479, fit_intercept=True, penalty=none ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=206.913808111479, fit_intercept=True, penalty=none, score=0.969, total=   0.3s\n",
            "[CV] C=206.913808111479, fit_intercept=False, penalty=l1 .............\n",
            "[CV]  C=206.913808111479, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=206.913808111479, fit_intercept=False, penalty=l1 .............\n",
            "[CV]  C=206.913808111479, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=206.913808111479, fit_intercept=False, penalty=l1 .............\n",
            "[CV]  C=206.913808111479, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=206.913808111479, fit_intercept=False, penalty=l1 .............\n",
            "[CV]  C=206.913808111479, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=206.913808111479, fit_intercept=False, penalty=l1 .............\n",
            "[CV]  C=206.913808111479, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=206.913808111479, fit_intercept=False, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=206.913808111479, fit_intercept=False, penalty=l2, score=0.981, total=   1.3s\n",
            "[CV] C=206.913808111479, fit_intercept=False, penalty=l2 .............\n",
            "[CV]  C=206.913808111479, fit_intercept=False, penalty=l2, score=0.965, total=   1.5s\n",
            "[CV] C=206.913808111479, fit_intercept=False, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=206.913808111479, fit_intercept=False, penalty=l2, score=0.965, total=   1.7s\n",
            "[CV] C=206.913808111479, fit_intercept=False, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=206.913808111479, fit_intercept=False, penalty=l2, score=0.981, total=   1.5s\n",
            "[CV] C=206.913808111479, fit_intercept=False, penalty=l2 .............\n",
            "[CV]  C=206.913808111479, fit_intercept=False, penalty=l2, score=0.979, total=   1.5s\n",
            "[CV] C=206.913808111479, fit_intercept=False, penalty=elasticnet .....\n",
            "[CV]  C=206.913808111479, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=206.913808111479, fit_intercept=False, penalty=elasticnet .....\n",
            "[CV]  C=206.913808111479, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=206.913808111479, fit_intercept=False, penalty=elasticnet .....\n",
            "[CV]  C=206.913808111479, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=206.913808111479, fit_intercept=False, penalty=elasticnet .....\n",
            "[CV]  C=206.913808111479, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=206.913808111479, fit_intercept=False, penalty=elasticnet .....\n",
            "[CV]  C=206.913808111479, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=206.913808111479, fit_intercept=False, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=206.913808111479, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=206.913808111479, fit_intercept=False, penalty=none ...........\n",
            "[CV]  C=206.913808111479, fit_intercept=False, penalty=none, score=0.962, total=   0.2s\n",
            "[CV] C=206.913808111479, fit_intercept=False, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=206.913808111479, fit_intercept=False, penalty=none, score=0.979, total=   0.3s\n",
            "[CV] C=206.913808111479, fit_intercept=False, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=206.913808111479, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=206.913808111479, fit_intercept=False, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=206.913808111479, fit_intercept=False, penalty=none, score=0.971, total=   0.3s\n",
            "[CV] C=545.5594781168514, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=545.5594781168514, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=545.5594781168514, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=545.5594781168514, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=545.5594781168514, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=545.5594781168514, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=545.5594781168514, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=545.5594781168514, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=545.5594781168514, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=545.5594781168514, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=545.5594781168514, fit_intercept=True, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=545.5594781168514, fit_intercept=True, penalty=l2, score=0.979, total=   1.5s\n",
            "[CV] C=545.5594781168514, fit_intercept=True, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=545.5594781168514, fit_intercept=True, penalty=l2, score=0.969, total=   1.5s\n",
            "[CV] C=545.5594781168514, fit_intercept=True, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=545.5594781168514, fit_intercept=True, penalty=l2, score=0.965, total=   1.6s\n",
            "[CV] C=545.5594781168514, fit_intercept=True, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=545.5594781168514, fit_intercept=True, penalty=l2, score=0.973, total=   1.7s\n",
            "[CV] C=545.5594781168514, fit_intercept=True, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=545.5594781168514, fit_intercept=True, penalty=l2, score=0.965, total=   1.7s\n",
            "[CV] C=545.5594781168514, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=545.5594781168514, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=545.5594781168514, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=545.5594781168514, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=545.5594781168514, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=545.5594781168514, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=545.5594781168514, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=545.5594781168514, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=545.5594781168514, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=545.5594781168514, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=545.5594781168514, fit_intercept=True, penalty=none ...........\n",
            "[CV]  C=545.5594781168514, fit_intercept=True, penalty=none, score=0.977, total=   0.4s\n",
            "[CV] C=545.5594781168514, fit_intercept=True, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=545.5594781168514, fit_intercept=True, penalty=none, score=0.965, total=   0.2s\n",
            "[CV] C=545.5594781168514, fit_intercept=True, penalty=none ...........\n",
            "[CV]  C=545.5594781168514, fit_intercept=True, penalty=none, score=0.973, total=   0.2s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] C=545.5594781168514, fit_intercept=True, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=545.5594781168514, fit_intercept=True, penalty=none, score=0.981, total=   0.3s\n",
            "[CV] C=545.5594781168514, fit_intercept=True, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=545.5594781168514, fit_intercept=True, penalty=none, score=0.969, total=   0.3s\n",
            "[CV] C=545.5594781168514, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=545.5594781168514, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=545.5594781168514, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=545.5594781168514, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=545.5594781168514, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=545.5594781168514, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=545.5594781168514, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=545.5594781168514, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=545.5594781168514, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=545.5594781168514, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=545.5594781168514, fit_intercept=False, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=545.5594781168514, fit_intercept=False, penalty=l2, score=0.977, total=   1.4s\n",
            "[CV] C=545.5594781168514, fit_intercept=False, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=545.5594781168514, fit_intercept=False, penalty=l2, score=0.965, total=   1.6s\n",
            "[CV] C=545.5594781168514, fit_intercept=False, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=545.5594781168514, fit_intercept=False, penalty=l2, score=0.965, total=   1.6s\n",
            "[CV] C=545.5594781168514, fit_intercept=False, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=545.5594781168514, fit_intercept=False, penalty=l2, score=0.981, total=   1.6s\n",
            "[CV] C=545.5594781168514, fit_intercept=False, penalty=l2 ............\n",
            "[CV]  C=545.5594781168514, fit_intercept=False, penalty=l2, score=0.979, total=   1.4s\n",
            "[CV] C=545.5594781168514, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=545.5594781168514, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=545.5594781168514, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=545.5594781168514, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=545.5594781168514, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=545.5594781168514, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=545.5594781168514, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=545.5594781168514, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=545.5594781168514, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=545.5594781168514, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=545.5594781168514, fit_intercept=False, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=545.5594781168514, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=545.5594781168514, fit_intercept=False, penalty=none ..........\n",
            "[CV]  C=545.5594781168514, fit_intercept=False, penalty=none, score=0.962, total=   0.2s\n",
            "[CV] C=545.5594781168514, fit_intercept=False, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=545.5594781168514, fit_intercept=False, penalty=none, score=0.979, total=   0.3s\n",
            "[CV] C=545.5594781168514, fit_intercept=False, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=545.5594781168514, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=545.5594781168514, fit_intercept=False, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=545.5594781168514, fit_intercept=False, penalty=none, score=0.971, total=   0.3s\n",
            "[CV] C=1438.44988828766, fit_intercept=True, penalty=l1 ..............\n",
            "[CV]  C=1438.44988828766, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=1438.44988828766, fit_intercept=True, penalty=l1 ..............\n",
            "[CV]  C=1438.44988828766, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=1438.44988828766, fit_intercept=True, penalty=l1 ..............\n",
            "[CV]  C=1438.44988828766, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=1438.44988828766, fit_intercept=True, penalty=l1 ..............\n",
            "[CV]  C=1438.44988828766, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=1438.44988828766, fit_intercept=True, penalty=l1 ..............\n",
            "[CV]  C=1438.44988828766, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=1438.44988828766, fit_intercept=True, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1438.44988828766, fit_intercept=True, penalty=l2, score=0.975, total=   1.5s\n",
            "[CV] C=1438.44988828766, fit_intercept=True, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1438.44988828766, fit_intercept=True, penalty=l2, score=0.965, total=   1.6s\n",
            "[CV] C=1438.44988828766, fit_intercept=True, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1438.44988828766, fit_intercept=True, penalty=l2, score=0.963, total=   1.7s\n",
            "[CV] C=1438.44988828766, fit_intercept=True, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1438.44988828766, fit_intercept=True, penalty=l2, score=0.973, total=   1.8s\n",
            "[CV] C=1438.44988828766, fit_intercept=True, penalty=l2 ..............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1438.44988828766, fit_intercept=True, penalty=l2, score=0.963, total=   1.7s\n",
            "[CV] C=1438.44988828766, fit_intercept=True, penalty=elasticnet ......\n",
            "[CV]  C=1438.44988828766, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=1438.44988828766, fit_intercept=True, penalty=elasticnet ......\n",
            "[CV]  C=1438.44988828766, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=1438.44988828766, fit_intercept=True, penalty=elasticnet ......\n",
            "[CV]  C=1438.44988828766, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=1438.44988828766, fit_intercept=True, penalty=elasticnet ......\n",
            "[CV]  C=1438.44988828766, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=1438.44988828766, fit_intercept=True, penalty=elasticnet ......\n",
            "[CV]  C=1438.44988828766, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=1438.44988828766, fit_intercept=True, penalty=none ............\n",
            "[CV]  C=1438.44988828766, fit_intercept=True, penalty=none, score=0.977, total=   0.4s\n",
            "[CV] C=1438.44988828766, fit_intercept=True, penalty=none ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1438.44988828766, fit_intercept=True, penalty=none, score=0.965, total=   0.2s\n",
            "[CV] C=1438.44988828766, fit_intercept=True, penalty=none ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1438.44988828766, fit_intercept=True, penalty=none, score=0.973, total=   0.2s\n",
            "[CV] C=1438.44988828766, fit_intercept=True, penalty=none ............\n",
            "[CV]  C=1438.44988828766, fit_intercept=True, penalty=none, score=0.981, total=   0.4s\n",
            "[CV] C=1438.44988828766, fit_intercept=True, penalty=none ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1438.44988828766, fit_intercept=True, penalty=none, score=0.969, total=   0.3s\n",
            "[CV] C=1438.44988828766, fit_intercept=False, penalty=l1 .............\n",
            "[CV]  C=1438.44988828766, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=1438.44988828766, fit_intercept=False, penalty=l1 .............\n",
            "[CV]  C=1438.44988828766, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=1438.44988828766, fit_intercept=False, penalty=l1 .............\n",
            "[CV]  C=1438.44988828766, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=1438.44988828766, fit_intercept=False, penalty=l1 .............\n",
            "[CV]  C=1438.44988828766, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=1438.44988828766, fit_intercept=False, penalty=l1 .............\n",
            "[CV]  C=1438.44988828766, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=1438.44988828766, fit_intercept=False, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1438.44988828766, fit_intercept=False, penalty=l2, score=0.977, total=   1.6s\n",
            "[CV] C=1438.44988828766, fit_intercept=False, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1438.44988828766, fit_intercept=False, penalty=l2, score=0.963, total=   1.5s\n",
            "[CV] C=1438.44988828766, fit_intercept=False, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1438.44988828766, fit_intercept=False, penalty=l2, score=0.963, total=   1.7s\n",
            "[CV] C=1438.44988828766, fit_intercept=False, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1438.44988828766, fit_intercept=False, penalty=l2, score=0.977, total=   1.6s\n",
            "[CV] C=1438.44988828766, fit_intercept=False, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1438.44988828766, fit_intercept=False, penalty=l2, score=0.973, total=   1.7s\n",
            "[CV] C=1438.44988828766, fit_intercept=False, penalty=elasticnet .....\n",
            "[CV]  C=1438.44988828766, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=1438.44988828766, fit_intercept=False, penalty=elasticnet .....\n",
            "[CV]  C=1438.44988828766, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=1438.44988828766, fit_intercept=False, penalty=elasticnet .....\n",
            "[CV]  C=1438.44988828766, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=1438.44988828766, fit_intercept=False, penalty=elasticnet .....\n",
            "[CV]  C=1438.44988828766, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=1438.44988828766, fit_intercept=False, penalty=elasticnet .....\n",
            "[CV]  C=1438.44988828766, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=1438.44988828766, fit_intercept=False, penalty=none ...........\n",
            "[CV]  C=1438.44988828766, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=1438.44988828766, fit_intercept=False, penalty=none ...........\n",
            "[CV]  C=1438.44988828766, fit_intercept=False, penalty=none, score=0.962, total=   0.2s\n",
            "[CV] C=1438.44988828766, fit_intercept=False, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1438.44988828766, fit_intercept=False, penalty=none, score=0.979, total=   0.3s\n",
            "[CV] C=1438.44988828766, fit_intercept=False, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1438.44988828766, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=1438.44988828766, fit_intercept=False, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=1438.44988828766, fit_intercept=False, penalty=none, score=0.971, total=   0.3s\n",
            "[CV] C=3792.690190732246, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=3792.690190732246, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=3792.690190732246, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=3792.690190732246, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=3792.690190732246, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=3792.690190732246, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=3792.690190732246, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=3792.690190732246, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=3792.690190732246, fit_intercept=True, penalty=l1 .............\n",
            "[CV]  C=3792.690190732246, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=3792.690190732246, fit_intercept=True, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=3792.690190732246, fit_intercept=True, penalty=l2, score=0.975, total=   1.7s\n",
            "[CV] C=3792.690190732246, fit_intercept=True, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=3792.690190732246, fit_intercept=True, penalty=l2, score=0.963, total=   1.6s\n",
            "[CV] C=3792.690190732246, fit_intercept=True, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=3792.690190732246, fit_intercept=True, penalty=l2, score=0.962, total=   1.7s\n",
            "[CV] C=3792.690190732246, fit_intercept=True, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=3792.690190732246, fit_intercept=True, penalty=l2, score=0.969, total=   1.7s\n",
            "[CV] C=3792.690190732246, fit_intercept=True, penalty=l2 .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=3792.690190732246, fit_intercept=True, penalty=l2, score=0.965, total=   1.7s\n",
            "[CV] C=3792.690190732246, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=3792.690190732246, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=3792.690190732246, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=3792.690190732246, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=3792.690190732246, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=3792.690190732246, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=3792.690190732246, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=3792.690190732246, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=3792.690190732246, fit_intercept=True, penalty=elasticnet .....\n",
            "[CV]  C=3792.690190732246, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=3792.690190732246, fit_intercept=True, penalty=none ...........\n",
            "[CV]  C=3792.690190732246, fit_intercept=True, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=3792.690190732246, fit_intercept=True, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=3792.690190732246, fit_intercept=True, penalty=none, score=0.965, total=   0.2s\n",
            "[CV] C=3792.690190732246, fit_intercept=True, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=3792.690190732246, fit_intercept=True, penalty=none, score=0.973, total=   0.2s\n",
            "[CV] C=3792.690190732246, fit_intercept=True, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=3792.690190732246, fit_intercept=True, penalty=none, score=0.981, total=   0.3s\n",
            "[CV] C=3792.690190732246, fit_intercept=True, penalty=none ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=3792.690190732246, fit_intercept=True, penalty=none, score=0.969, total=   0.3s\n",
            "[CV] C=3792.690190732246, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=3792.690190732246, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=3792.690190732246, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=3792.690190732246, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=3792.690190732246, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=3792.690190732246, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=3792.690190732246, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=3792.690190732246, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=3792.690190732246, fit_intercept=False, penalty=l1 ............\n",
            "[CV]  C=3792.690190732246, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=3792.690190732246, fit_intercept=False, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=3792.690190732246, fit_intercept=False, penalty=l2, score=0.975, total=   1.4s\n",
            "[CV] C=3792.690190732246, fit_intercept=False, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=3792.690190732246, fit_intercept=False, penalty=l2, score=0.965, total=   1.6s\n",
            "[CV] C=3792.690190732246, fit_intercept=False, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=3792.690190732246, fit_intercept=False, penalty=l2, score=0.962, total=   1.7s\n",
            "[CV] C=3792.690190732246, fit_intercept=False, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=3792.690190732246, fit_intercept=False, penalty=l2, score=0.975, total=   1.6s\n",
            "[CV] C=3792.690190732246, fit_intercept=False, penalty=l2 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=3792.690190732246, fit_intercept=False, penalty=l2, score=0.973, total=   1.6s\n",
            "[CV] C=3792.690190732246, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=3792.690190732246, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=3792.690190732246, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=3792.690190732246, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=3792.690190732246, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=3792.690190732246, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=3792.690190732246, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=3792.690190732246, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=3792.690190732246, fit_intercept=False, penalty=elasticnet ....\n",
            "[CV]  C=3792.690190732246, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=3792.690190732246, fit_intercept=False, penalty=none ..........\n",
            "[CV]  C=3792.690190732246, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=3792.690190732246, fit_intercept=False, penalty=none ..........\n",
            "[CV]  C=3792.690190732246, fit_intercept=False, penalty=none, score=0.962, total=   0.2s\n",
            "[CV] C=3792.690190732246, fit_intercept=False, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=3792.690190732246, fit_intercept=False, penalty=none, score=0.979, total=   0.3s\n",
            "[CV] C=3792.690190732246, fit_intercept=False, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=3792.690190732246, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=3792.690190732246, fit_intercept=False, penalty=none ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=3792.690190732246, fit_intercept=False, penalty=none, score=0.971, total=   0.3s\n",
            "[CV] C=10000.0, fit_intercept=True, penalty=l1 .......................\n",
            "[CV]  C=10000.0, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=10000.0, fit_intercept=True, penalty=l1 .......................\n",
            "[CV]  C=10000.0, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=10000.0, fit_intercept=True, penalty=l1 .......................\n",
            "[CV]  C=10000.0, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=10000.0, fit_intercept=True, penalty=l1 .......................\n",
            "[CV]  C=10000.0, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=10000.0, fit_intercept=True, penalty=l1 .......................\n",
            "[CV]  C=10000.0, fit_intercept=True, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=10000.0, fit_intercept=True, penalty=l2 .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10000.0, fit_intercept=True, penalty=l2, score=0.965, total=   1.3s\n",
            "[CV] C=10000.0, fit_intercept=True, penalty=l2 .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10000.0, fit_intercept=True, penalty=l2, score=0.965, total=   1.6s\n",
            "[CV] C=10000.0, fit_intercept=True, penalty=l2 .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10000.0, fit_intercept=True, penalty=l2, score=0.956, total=   1.8s\n",
            "[CV] C=10000.0, fit_intercept=True, penalty=l2 .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10000.0, fit_intercept=True, penalty=l2, score=0.971, total=   1.7s\n",
            "[CV] C=10000.0, fit_intercept=True, penalty=l2 .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10000.0, fit_intercept=True, penalty=l2, score=0.962, total=   1.7s\n",
            "[CV] C=10000.0, fit_intercept=True, penalty=elasticnet ...............\n",
            "[CV]  C=10000.0, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=10000.0, fit_intercept=True, penalty=elasticnet ...............\n",
            "[CV]  C=10000.0, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=10000.0, fit_intercept=True, penalty=elasticnet ...............\n",
            "[CV]  C=10000.0, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=10000.0, fit_intercept=True, penalty=elasticnet ...............\n",
            "[CV]  C=10000.0, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=10000.0, fit_intercept=True, penalty=elasticnet ...............\n",
            "[CV]  C=10000.0, fit_intercept=True, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=10000.0, fit_intercept=True, penalty=none .....................\n",
            "[CV]  C=10000.0, fit_intercept=True, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=10000.0, fit_intercept=True, penalty=none .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10000.0, fit_intercept=True, penalty=none, score=0.965, total=   0.2s\n",
            "[CV] C=10000.0, fit_intercept=True, penalty=none .....................\n",
            "[CV]  C=10000.0, fit_intercept=True, penalty=none, score=0.973, total=   0.2s\n",
            "[CV] C=10000.0, fit_intercept=True, penalty=none .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10000.0, fit_intercept=True, penalty=none, score=0.981, total=   0.3s\n",
            "[CV] C=10000.0, fit_intercept=True, penalty=none .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10000.0, fit_intercept=True, penalty=none, score=0.969, total=   0.3s\n",
            "[CV] C=10000.0, fit_intercept=False, penalty=l1 ......................\n",
            "[CV]  C=10000.0, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=10000.0, fit_intercept=False, penalty=l1 ......................\n",
            "[CV]  C=10000.0, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=10000.0, fit_intercept=False, penalty=l1 ......................\n",
            "[CV]  C=10000.0, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=10000.0, fit_intercept=False, penalty=l1 ......................\n",
            "[CV]  C=10000.0, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=10000.0, fit_intercept=False, penalty=l1 ......................\n",
            "[CV]  C=10000.0, fit_intercept=False, penalty=l1, score=nan, total=   0.0s\n",
            "[CV] C=10000.0, fit_intercept=False, penalty=l2 ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10000.0, fit_intercept=False, penalty=l2, score=0.975, total=   1.4s\n",
            "[CV] C=10000.0, fit_intercept=False, penalty=l2 ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10000.0, fit_intercept=False, penalty=l2, score=0.965, total=   1.6s\n",
            "[CV] C=10000.0, fit_intercept=False, penalty=l2 ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10000.0, fit_intercept=False, penalty=l2, score=0.958, total=   1.8s\n",
            "[CV] C=10000.0, fit_intercept=False, penalty=l2 ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10000.0, fit_intercept=False, penalty=l2, score=0.975, total=   1.6s\n",
            "[CV] C=10000.0, fit_intercept=False, penalty=l2 ......................\n",
            "[CV]  C=10000.0, fit_intercept=False, penalty=l2, score=0.973, total=   1.5s\n",
            "[CV] C=10000.0, fit_intercept=False, penalty=elasticnet ..............\n",
            "[CV]  C=10000.0, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=10000.0, fit_intercept=False, penalty=elasticnet ..............\n",
            "[CV]  C=10000.0, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=10000.0, fit_intercept=False, penalty=elasticnet ..............\n",
            "[CV]  C=10000.0, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=10000.0, fit_intercept=False, penalty=elasticnet ..............\n",
            "[CV]  C=10000.0, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=10000.0, fit_intercept=False, penalty=elasticnet ..............\n",
            "[CV]  C=10000.0, fit_intercept=False, penalty=elasticnet, score=nan, total=   0.0s\n",
            "[CV] C=10000.0, fit_intercept=False, penalty=none ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10000.0, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=10000.0, fit_intercept=False, penalty=none ....................\n",
            "[CV]  C=10000.0, fit_intercept=False, penalty=none, score=0.962, total=   0.2s\n",
            "[CV] C=10000.0, fit_intercept=False, penalty=none ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10000.0, fit_intercept=False, penalty=none, score=0.979, total=   0.3s\n",
            "[CV] C=10000.0, fit_intercept=False, penalty=none ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10000.0, fit_intercept=False, penalty=none, score=0.977, total=   0.3s\n",
            "[CV] C=10000.0, fit_intercept=False, penalty=none ....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  C=10000.0, fit_intercept=False, penalty=none, score=0.971, total=   0.3s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 800 out of 800 | elapsed:  4.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=1000, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=42, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'C': array([1.00000000e-04, 2.6...\n",
              "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
              "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
              "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
              "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
              "                          'fit_intercept': [True, False],\n",
              "                          'penalty': ['l1', 'l2', 'elasticnet', 'none']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQA4YFlhn7MR",
        "outputId": "2a2509bd-2db2-464e-bcdd-9c753a01d9e4"
      },
      "source": [
        "grid_search_log.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 0.615848211066026, 'fit_intercept': False, 'penalty': 'l2'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "449vFoBXn_6x",
        "outputId": "f0ea17a0-c9bc-45bc-a3a0-9fedd1ca9e75"
      },
      "source": [
        "grid_search_log.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9780769230769231"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e232w8kVoD77",
        "outputId": "bcb9d120-49e1-4f00-9ee9-707496fbe2dc"
      },
      "source": [
        "y_pred_log = grid_search_log.predict(X_test_transformed)\n",
        "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred_log)))\n",
        "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred_log)))\n",
        "print(\"f1 score: {:.2f}%\".format(100 * f1_score(y_test, y_pred_log)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 98.02%\n",
            "Recall: 95.19%\n",
            "f1 score: 96.59%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "dCAroau-QKEI",
        "outputId": "dd541a41-81f1-47bd-9f96-680ae01eece1"
      },
      "source": [
        "# Plot confusion matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plot_confusion_matrix(grid_search_log, X_test_transformed, y_test, cmap=plt.cm.Blues)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f5f9c6f0ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqN-LYO7LwhH"
      },
      "source": [
        "###2. KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPgpoom_LvME",
        "outputId": "4c9001c7-976c-4932-a0f0-2aeb781e1f38"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "param_grid = [{\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'n_neighbors': [2, 3, 4, 5, 6, 7, 8]\n",
        "}]\n",
        "knn_clf = KNeighborsClassifier()\n",
        "grid_search_knn = GridSearchCV(knn_clf, param_grid, cv=5, verbose=3)\n",
        "grid_search_knn.fit(X_train_transformed, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
            "[CV] n_neighbors=2, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=2, weights=uniform, score=0.923, total=   0.1s\n",
            "[CV] n_neighbors=2, weights=uniform ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ...... n_neighbors=2, weights=uniform, score=0.929, total=   0.1s\n",
            "[CV] n_neighbors=2, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=2, weights=uniform, score=0.929, total=   0.1s\n",
            "[CV] n_neighbors=2, weights=uniform ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ...... n_neighbors=2, weights=uniform, score=0.931, total=   0.1s\n",
            "[CV] n_neighbors=2, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=2, weights=uniform, score=0.935, total=   0.1s\n",
            "[CV] n_neighbors=2, weights=distance .................................\n",
            "[CV] ..... n_neighbors=2, weights=distance, score=0.937, total=   0.1s\n",
            "[CV] n_neighbors=2, weights=distance .................................\n",
            "[CV] ..... n_neighbors=2, weights=distance, score=0.940, total=   0.1s\n",
            "[CV] n_neighbors=2, weights=distance .................................\n",
            "[CV] ..... n_neighbors=2, weights=distance, score=0.919, total=   0.1s\n",
            "[CV] n_neighbors=2, weights=distance .................................\n",
            "[CV] ..... n_neighbors=2, weights=distance, score=0.940, total=   0.1s\n",
            "[CV] n_neighbors=2, weights=distance .................................\n",
            "[CV] ..... n_neighbors=2, weights=distance, score=0.946, total=   0.1s\n",
            "[CV] n_neighbors=3, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=3, weights=uniform, score=0.925, total=   0.1s\n",
            "[CV] n_neighbors=3, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=3, weights=uniform, score=0.929, total=   0.1s\n",
            "[CV] n_neighbors=3, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=3, weights=uniform, score=0.913, total=   0.1s\n",
            "[CV] n_neighbors=3, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=3, weights=uniform, score=0.937, total=   0.1s\n",
            "[CV] n_neighbors=3, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=3, weights=uniform, score=0.942, total=   0.1s\n",
            "[CV] n_neighbors=3, weights=distance .................................\n",
            "[CV] ..... n_neighbors=3, weights=distance, score=0.937, total=   0.1s\n",
            "[CV] n_neighbors=3, weights=distance .................................\n",
            "[CV] ..... n_neighbors=3, weights=distance, score=0.938, total=   0.1s\n",
            "[CV] n_neighbors=3, weights=distance .................................\n",
            "[CV] ..... n_neighbors=3, weights=distance, score=0.925, total=   0.1s\n",
            "[CV] n_neighbors=3, weights=distance .................................\n",
            "[CV] ..... n_neighbors=3, weights=distance, score=0.948, total=   0.1s\n",
            "[CV] n_neighbors=3, weights=distance .................................\n",
            "[CV] ..... n_neighbors=3, weights=distance, score=0.950, total=   0.1s\n",
            "[CV] n_neighbors=4, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=4, weights=uniform, score=0.917, total=   0.1s\n",
            "[CV] n_neighbors=4, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=4, weights=uniform, score=0.925, total=   0.1s\n",
            "[CV] n_neighbors=4, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=4, weights=uniform, score=0.919, total=   0.1s\n",
            "[CV] n_neighbors=4, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=4, weights=uniform, score=0.925, total=   0.1s\n",
            "[CV] n_neighbors=4, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=4, weights=uniform, score=0.929, total=   0.1s\n",
            "[CV] n_neighbors=4, weights=distance .................................\n",
            "[CV] ..... n_neighbors=4, weights=distance, score=0.937, total=   0.1s\n",
            "[CV] n_neighbors=4, weights=distance .................................\n",
            "[CV] ..... n_neighbors=4, weights=distance, score=0.940, total=   0.1s\n",
            "[CV] n_neighbors=4, weights=distance .................................\n",
            "[CV] ..... n_neighbors=4, weights=distance, score=0.929, total=   0.1s\n",
            "[CV] n_neighbors=4, weights=distance .................................\n",
            "[CV] ..... n_neighbors=4, weights=distance, score=0.952, total=   0.1s\n",
            "[CV] n_neighbors=4, weights=distance .................................\n",
            "[CV] ..... n_neighbors=4, weights=distance, score=0.944, total=   0.1s\n",
            "[CV] n_neighbors=5, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=5, weights=uniform, score=0.921, total=   0.1s\n",
            "[CV] n_neighbors=5, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=5, weights=uniform, score=0.923, total=   0.1s\n",
            "[CV] n_neighbors=5, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=5, weights=uniform, score=0.912, total=   0.1s\n",
            "[CV] n_neighbors=5, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=5, weights=uniform, score=0.927, total=   0.1s\n",
            "[CV] n_neighbors=5, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=5, weights=uniform, score=0.931, total=   0.1s\n",
            "[CV] n_neighbors=5, weights=distance .................................\n",
            "[CV] ..... n_neighbors=5, weights=distance, score=0.931, total=   0.1s\n",
            "[CV] n_neighbors=5, weights=distance .................................\n",
            "[CV] ..... n_neighbors=5, weights=distance, score=0.931, total=   0.1s\n",
            "[CV] n_neighbors=5, weights=distance .................................\n",
            "[CV] ..... n_neighbors=5, weights=distance, score=0.929, total=   0.1s\n",
            "[CV] n_neighbors=5, weights=distance .................................\n",
            "[CV] ..... n_neighbors=5, weights=distance, score=0.938, total=   0.1s\n",
            "[CV] n_neighbors=5, weights=distance .................................\n",
            "[CV] ..... n_neighbors=5, weights=distance, score=0.944, total=   0.1s\n",
            "[CV] n_neighbors=6, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=6, weights=uniform, score=0.906, total=   0.1s\n",
            "[CV] n_neighbors=6, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=6, weights=uniform, score=0.910, total=   0.1s\n",
            "[CV] n_neighbors=6, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=6, weights=uniform, score=0.904, total=   0.1s\n",
            "[CV] n_neighbors=6, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=6, weights=uniform, score=0.913, total=   0.1s\n",
            "[CV] n_neighbors=6, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=6, weights=uniform, score=0.921, total=   0.1s\n",
            "[CV] n_neighbors=6, weights=distance .................................\n",
            "[CV] ..... n_neighbors=6, weights=distance, score=0.933, total=   0.1s\n",
            "[CV] n_neighbors=6, weights=distance .................................\n",
            "[CV] ..... n_neighbors=6, weights=distance, score=0.933, total=   0.1s\n",
            "[CV] n_neighbors=6, weights=distance .................................\n",
            "[CV] ..... n_neighbors=6, weights=distance, score=0.933, total=   0.1s\n",
            "[CV] n_neighbors=6, weights=distance .................................\n",
            "[CV] ..... n_neighbors=6, weights=distance, score=0.942, total=   0.1s\n",
            "[CV] n_neighbors=6, weights=distance .................................\n",
            "[CV] ..... n_neighbors=6, weights=distance, score=0.940, total=   0.1s\n",
            "[CV] n_neighbors=7, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=7, weights=uniform, score=0.913, total=   0.1s\n",
            "[CV] n_neighbors=7, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=7, weights=uniform, score=0.913, total=   0.1s\n",
            "[CV] n_neighbors=7, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=7, weights=uniform, score=0.902, total=   0.1s\n",
            "[CV] n_neighbors=7, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=7, weights=uniform, score=0.919, total=   0.1s\n",
            "[CV] n_neighbors=7, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=7, weights=uniform, score=0.927, total=   0.1s\n",
            "[CV] n_neighbors=7, weights=distance .................................\n",
            "[CV] ..... n_neighbors=7, weights=distance, score=0.929, total=   0.1s\n",
            "[CV] n_neighbors=7, weights=distance .................................\n",
            "[CV] ..... n_neighbors=7, weights=distance, score=0.931, total=   0.1s\n",
            "[CV] n_neighbors=7, weights=distance .................................\n",
            "[CV] ..... n_neighbors=7, weights=distance, score=0.925, total=   0.1s\n",
            "[CV] n_neighbors=7, weights=distance .................................\n",
            "[CV] ..... n_neighbors=7, weights=distance, score=0.942, total=   0.1s\n",
            "[CV] n_neighbors=7, weights=distance .................................\n",
            "[CV] ..... n_neighbors=7, weights=distance, score=0.944, total=   0.1s\n",
            "[CV] n_neighbors=8, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=8, weights=uniform, score=0.902, total=   0.1s\n",
            "[CV] n_neighbors=8, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=8, weights=uniform, score=0.896, total=   0.1s\n",
            "[CV] n_neighbors=8, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=8, weights=uniform, score=0.902, total=   0.1s\n",
            "[CV] n_neighbors=8, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=8, weights=uniform, score=0.908, total=   0.1s\n",
            "[CV] n_neighbors=8, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=8, weights=uniform, score=0.898, total=   0.1s\n",
            "[CV] n_neighbors=8, weights=distance .................................\n",
            "[CV] ..... n_neighbors=8, weights=distance, score=0.931, total=   0.1s\n",
            "[CV] n_neighbors=8, weights=distance .................................\n",
            "[CV] ..... n_neighbors=8, weights=distance, score=0.931, total=   0.1s\n",
            "[CV] n_neighbors=8, weights=distance .................................\n",
            "[CV] ..... n_neighbors=8, weights=distance, score=0.927, total=   0.1s\n",
            "[CV] n_neighbors=8, weights=distance .................................\n",
            "[CV] ..... n_neighbors=8, weights=distance, score=0.937, total=   0.1s\n",
            "[CV] n_neighbors=8, weights=distance .................................\n",
            "[CV] ..... n_neighbors=8, weights=distance, score=0.944, total=   0.1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed:    7.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
              "                                            metric='minkowski',\n",
              "                                            metric_params=None, n_jobs=None,\n",
              "                                            n_neighbors=5, p=2,\n",
              "                                            weights='uniform'),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'n_neighbors': [2, 3, 4, 5, 6, 7, 8],\n",
              "                          'weights': ['uniform', 'distance']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzMgm-g3NQZC",
        "outputId": "866a8d6d-bd62-4cd5-a7e3-d6371e0b6248"
      },
      "source": [
        "grid_search_knn.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_neighbors': 4, 'weights': 'distance'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcN_kzeVNV2n",
        "outputId": "b1544c5b-ad57-4fe8-cd60-c46f1e8ede0c"
      },
      "source": [
        "grid_search_knn.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9403846153846154"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqQqXW-yNhfr",
        "outputId": "ae902aba-5695-484c-9cc4-250ebf93810a"
      },
      "source": [
        "y_pred_knn = grid_search_knn.predict(X_test_transformed)\n",
        "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred_knn)))\n",
        "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred_knn)))\n",
        "print(\"f1 score: {:.2f}%\".format(100 * f1_score(y_test, y_pred_knn)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 92.59%\n",
            "Recall: 72.12%\n",
            "f1 score: 81.08%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "RV5jFGbpQio5",
        "outputId": "fff6be6e-ebdb-4c9f-f1ba-b06e39e09173"
      },
      "source": [
        "plot_confusion_matrix(grid_search_knn, X_test_transformed, y_test, cmap=plt.cm.Blues)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f5f9c8e49d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGqRqVUzONUN",
        "outputId": "0725a36d-f30c-4eab-df9a-27f05441d185"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "knn_reg = KNeighborsRegressor()\n",
        "grid_search_knn_regressor = GridSearchCV(knn_reg, param_grid, cv=5, verbose=3)\n",
        "grid_search_knn_regressor.fit(X_train_transformed, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
            "[CV] n_neighbors=2, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=2, weights=uniform, score=0.548, total=   0.1s\n",
            "[CV] n_neighbors=2, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=2, weights=uniform, score=0.571, total=   0.1s\n",
            "[CV] n_neighbors=2, weights=uniform ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ...... n_neighbors=2, weights=uniform, score=0.434, total=   0.1s\n",
            "[CV] n_neighbors=2, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=2, weights=uniform, score=0.579, total=   0.1s\n",
            "[CV] n_neighbors=2, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=2, weights=uniform, score=0.598, total=   0.1s\n",
            "[CV] n_neighbors=2, weights=distance .................................\n",
            "[CV] ..... n_neighbors=2, weights=distance, score=0.578, total=   0.1s\n",
            "[CV] n_neighbors=2, weights=distance .................................\n",
            "[CV] ..... n_neighbors=2, weights=distance, score=0.597, total=   0.1s\n",
            "[CV] n_neighbors=2, weights=distance .................................\n",
            "[CV] ..... n_neighbors=2, weights=distance, score=0.470, total=   0.1s\n",
            "[CV] n_neighbors=2, weights=distance .................................\n",
            "[CV] ..... n_neighbors=2, weights=distance, score=0.600, total=   0.1s\n",
            "[CV] n_neighbors=2, weights=distance .................................\n",
            "[CV] ..... n_neighbors=2, weights=distance, score=0.623, total=   0.1s\n",
            "[CV] n_neighbors=3, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=3, weights=uniform, score=0.556, total=   0.1s\n",
            "[CV] n_neighbors=3, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=3, weights=uniform, score=0.572, total=   0.1s\n",
            "[CV] n_neighbors=3, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=3, weights=uniform, score=0.486, total=   0.1s\n",
            "[CV] n_neighbors=3, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=3, weights=uniform, score=0.558, total=   0.1s\n",
            "[CV] n_neighbors=3, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=3, weights=uniform, score=0.594, total=   0.1s\n",
            "[CV] n_neighbors=3, weights=distance .................................\n",
            "[CV] ..... n_neighbors=3, weights=distance, score=0.596, total=   0.1s\n",
            "[CV] n_neighbors=3, weights=distance .................................\n",
            "[CV] ..... n_neighbors=3, weights=distance, score=0.610, total=   0.1s\n",
            "[CV] n_neighbors=3, weights=distance .................................\n",
            "[CV] ..... n_neighbors=3, weights=distance, score=0.536, total=   0.1s\n",
            "[CV] n_neighbors=3, weights=distance .................................\n",
            "[CV] ..... n_neighbors=3, weights=distance, score=0.601, total=   0.1s\n",
            "[CV] n_neighbors=3, weights=distance .................................\n",
            "[CV] ..... n_neighbors=3, weights=distance, score=0.634, total=   0.1s\n",
            "[CV] n_neighbors=4, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=4, weights=uniform, score=0.540, total=   0.1s\n",
            "[CV] n_neighbors=4, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=4, weights=uniform, score=0.578, total=   0.1s\n",
            "[CV] n_neighbors=4, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=4, weights=uniform, score=0.501, total=   0.1s\n",
            "[CV] n_neighbors=4, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=4, weights=uniform, score=0.588, total=   0.1s\n",
            "[CV] n_neighbors=4, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=4, weights=uniform, score=0.570, total=   0.1s\n",
            "[CV] n_neighbors=4, weights=distance .................................\n",
            "[CV] ..... n_neighbors=4, weights=distance, score=0.599, total=   0.1s\n",
            "[CV] n_neighbors=4, weights=distance .................................\n",
            "[CV] ..... n_neighbors=4, weights=distance, score=0.628, total=   0.1s\n",
            "[CV] n_neighbors=4, weights=distance .................................\n",
            "[CV] ..... n_neighbors=4, weights=distance, score=0.561, total=   0.1s\n",
            "[CV] n_neighbors=4, weights=distance .................................\n",
            "[CV] ..... n_neighbors=4, weights=distance, score=0.639, total=   0.1s\n",
            "[CV] n_neighbors=4, weights=distance .................................\n",
            "[CV] ..... n_neighbors=4, weights=distance, score=0.619, total=   0.1s\n",
            "[CV] n_neighbors=5, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=5, weights=uniform, score=0.526, total=   0.1s\n",
            "[CV] n_neighbors=5, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=5, weights=uniform, score=0.538, total=   0.2s\n",
            "[CV] n_neighbors=5, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=5, weights=uniform, score=0.504, total=   0.1s\n",
            "[CV] n_neighbors=5, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=5, weights=uniform, score=0.579, total=   0.1s\n",
            "[CV] n_neighbors=5, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=5, weights=uniform, score=0.557, total=   0.1s\n",
            "[CV] n_neighbors=5, weights=distance .................................\n",
            "[CV] ..... n_neighbors=5, weights=distance, score=0.599, total=   0.1s\n",
            "[CV] n_neighbors=5, weights=distance .................................\n",
            "[CV] ..... n_neighbors=5, weights=distance, score=0.601, total=   0.1s\n",
            "[CV] n_neighbors=5, weights=distance .................................\n",
            "[CV] ..... n_neighbors=5, weights=distance, score=0.569, total=   0.1s\n",
            "[CV] n_neighbors=5, weights=distance .................................\n",
            "[CV] ..... n_neighbors=5, weights=distance, score=0.647, total=   0.1s\n",
            "[CV] n_neighbors=5, weights=distance .................................\n",
            "[CV] ..... n_neighbors=5, weights=distance, score=0.619, total=   0.1s\n",
            "[CV] n_neighbors=6, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=6, weights=uniform, score=0.512, total=   0.1s\n",
            "[CV] n_neighbors=6, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=6, weights=uniform, score=0.527, total=   0.1s\n",
            "[CV] n_neighbors=6, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=6, weights=uniform, score=0.517, total=   0.1s\n",
            "[CV] n_neighbors=6, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=6, weights=uniform, score=0.569, total=   0.1s\n",
            "[CV] n_neighbors=6, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=6, weights=uniform, score=0.529, total=   0.1s\n",
            "[CV] n_neighbors=6, weights=distance .................................\n",
            "[CV] ..... n_neighbors=6, weights=distance, score=0.598, total=   0.1s\n",
            "[CV] n_neighbors=6, weights=distance .................................\n",
            "[CV] ..... n_neighbors=6, weights=distance, score=0.601, total=   0.1s\n",
            "[CV] n_neighbors=6, weights=distance .................................\n",
            "[CV] ..... n_neighbors=6, weights=distance, score=0.596, total=   0.1s\n",
            "[CV] n_neighbors=6, weights=distance .................................\n",
            "[CV] ..... n_neighbors=6, weights=distance, score=0.652, total=   0.1s\n",
            "[CV] n_neighbors=6, weights=distance .................................\n",
            "[CV] ..... n_neighbors=6, weights=distance, score=0.607, total=   0.1s\n",
            "[CV] n_neighbors=7, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=7, weights=uniform, score=0.519, total=   0.1s\n",
            "[CV] n_neighbors=7, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=7, weights=uniform, score=0.497, total=   0.1s\n",
            "[CV] n_neighbors=7, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=7, weights=uniform, score=0.507, total=   0.1s\n",
            "[CV] n_neighbors=7, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=7, weights=uniform, score=0.552, total=   0.1s\n",
            "[CV] n_neighbors=7, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=7, weights=uniform, score=0.503, total=   0.1s\n",
            "[CV] n_neighbors=7, weights=distance .................................\n",
            "[CV] ..... n_neighbors=7, weights=distance, score=0.615, total=   0.1s\n",
            "[CV] n_neighbors=7, weights=distance .................................\n",
            "[CV] ..... n_neighbors=7, weights=distance, score=0.583, total=   0.1s\n",
            "[CV] n_neighbors=7, weights=distance .................................\n",
            "[CV] ..... n_neighbors=7, weights=distance, score=0.603, total=   0.1s\n",
            "[CV] n_neighbors=7, weights=distance .................................\n",
            "[CV] ..... n_neighbors=7, weights=distance, score=0.647, total=   0.1s\n",
            "[CV] n_neighbors=7, weights=distance .................................\n",
            "[CV] ..... n_neighbors=7, weights=distance, score=0.601, total=   0.1s\n",
            "[CV] n_neighbors=8, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=8, weights=uniform, score=0.501, total=   0.1s\n",
            "[CV] n_neighbors=8, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=8, weights=uniform, score=0.479, total=   0.1s\n",
            "[CV] n_neighbors=8, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=8, weights=uniform, score=0.492, total=   0.1s\n",
            "[CV] n_neighbors=8, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=8, weights=uniform, score=0.529, total=   0.1s\n",
            "[CV] n_neighbors=8, weights=uniform ..................................\n",
            "[CV] ...... n_neighbors=8, weights=uniform, score=0.478, total=   0.1s\n",
            "[CV] n_neighbors=8, weights=distance .................................\n",
            "[CV] ..... n_neighbors=8, weights=distance, score=0.607, total=   0.1s\n",
            "[CV] n_neighbors=8, weights=distance .................................\n",
            "[CV] ..... n_neighbors=8, weights=distance, score=0.572, total=   0.1s\n",
            "[CV] n_neighbors=8, weights=distance .................................\n",
            "[CV] ..... n_neighbors=8, weights=distance, score=0.599, total=   0.1s\n",
            "[CV] n_neighbors=8, weights=distance .................................\n",
            "[CV] ..... n_neighbors=8, weights=distance, score=0.639, total=   0.1s\n",
            "[CV] n_neighbors=8, weights=distance .................................\n",
            "[CV] ..... n_neighbors=8, weights=distance, score=0.586, total=   0.1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed:    6.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30,\n",
              "                                           metric='minkowski',\n",
              "                                           metric_params=None, n_jobs=None,\n",
              "                                           n_neighbors=5, p=2,\n",
              "                                           weights='uniform'),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'n_neighbors': [2, 3, 4, 5, 6, 7, 8],\n",
              "                          'weights': ['uniform', 'distance']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_Wk80FOO2LZ",
        "outputId": "81b8b201-c634-4bab-ebb0-f441a6791e26"
      },
      "source": [
        "grid_search_knn_regressor.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_neighbors': 6, 'weights': 'distance'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1S9cFaqiO4oW",
        "outputId": "f8dbb80a-e6a5-474c-9a33-3a5142cb87bd"
      },
      "source": [
        "grid_search_knn_regressor.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6108842445160895"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BYfDzG9RIbV"
      },
      "source": [
        "###3. Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc0U1At-RLeh",
        "outputId": "d24650ee-9f5b-4062-a0c4-46233124a978"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt_param_grid = [{\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'splitter': ['best', 'random'],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}]\n",
        "\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "grid_search_dt = GridSearchCV(dt_clf, param_grid=dt_param_grid, cv=5, verbose=3)\n",
        "grid_search_dt.fit(X_train_transformed, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            "[CV] criterion=gini, max_features=auto, splitter=best ................\n",
            "[CV]  criterion=gini, max_features=auto, splitter=best, score=0.927, total=   0.0s\n",
            "[CV] criterion=gini, max_features=auto, splitter=best ................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  criterion=gini, max_features=auto, splitter=best, score=0.902, total=   0.0s\n",
            "[CV] criterion=gini, max_features=auto, splitter=best ................\n",
            "[CV]  criterion=gini, max_features=auto, splitter=best, score=0.908, total=   0.0s\n",
            "[CV] criterion=gini, max_features=auto, splitter=best ................\n",
            "[CV]  criterion=gini, max_features=auto, splitter=best, score=0.927, total=   0.0s\n",
            "[CV] criterion=gini, max_features=auto, splitter=best ................\n",
            "[CV]  criterion=gini, max_features=auto, splitter=best, score=0.921, total=   0.0s\n",
            "[CV] criterion=gini, max_features=auto, splitter=random ..............\n",
            "[CV]  criterion=gini, max_features=auto, splitter=random, score=0.904, total=   0.0s\n",
            "[CV] criterion=gini, max_features=auto, splitter=random ..............\n",
            "[CV]  criterion=gini, max_features=auto, splitter=random, score=0.900, total=   0.0s\n",
            "[CV] criterion=gini, max_features=auto, splitter=random ..............\n",
            "[CV]  criterion=gini, max_features=auto, splitter=random, score=0.877, total=   0.0s\n",
            "[CV] criterion=gini, max_features=auto, splitter=random ..............\n",
            "[CV]  criterion=gini, max_features=auto, splitter=random, score=0.904, total=   0.0s\n",
            "[CV] criterion=gini, max_features=auto, splitter=random ..............\n",
            "[CV]  criterion=gini, max_features=auto, splitter=random, score=0.898, total=   0.0s\n",
            "[CV] criterion=gini, max_features=sqrt, splitter=best ................\n",
            "[CV]  criterion=gini, max_features=sqrt, splitter=best, score=0.927, total=   0.0s\n",
            "[CV] criterion=gini, max_features=sqrt, splitter=best ................\n",
            "[CV]  criterion=gini, max_features=sqrt, splitter=best, score=0.902, total=   0.0s\n",
            "[CV] criterion=gini, max_features=sqrt, splitter=best ................\n",
            "[CV]  criterion=gini, max_features=sqrt, splitter=best, score=0.908, total=   0.0s\n",
            "[CV] criterion=gini, max_features=sqrt, splitter=best ................\n",
            "[CV]  criterion=gini, max_features=sqrt, splitter=best, score=0.927, total=   0.0s\n",
            "[CV] criterion=gini, max_features=sqrt, splitter=best ................\n",
            "[CV]  criterion=gini, max_features=sqrt, splitter=best, score=0.921, total=   0.0s\n",
            "[CV] criterion=gini, max_features=sqrt, splitter=random ..............\n",
            "[CV]  criterion=gini, max_features=sqrt, splitter=random, score=0.904, total=   0.0s\n",
            "[CV] criterion=gini, max_features=sqrt, splitter=random ..............\n",
            "[CV]  criterion=gini, max_features=sqrt, splitter=random, score=0.900, total=   0.0s\n",
            "[CV] criterion=gini, max_features=sqrt, splitter=random ..............\n",
            "[CV]  criterion=gini, max_features=sqrt, splitter=random, score=0.877, total=   0.0s\n",
            "[CV] criterion=gini, max_features=sqrt, splitter=random ..............\n",
            "[CV]  criterion=gini, max_features=sqrt, splitter=random, score=0.904, total=   0.0s\n",
            "[CV] criterion=gini, max_features=sqrt, splitter=random ..............\n",
            "[CV]  criterion=gini, max_features=sqrt, splitter=random, score=0.898, total=   0.0s\n",
            "[CV] criterion=gini, max_features=log2, splitter=best ................\n",
            "[CV]  criterion=gini, max_features=log2, splitter=best, score=0.915, total=   0.0s\n",
            "[CV] criterion=gini, max_features=log2, splitter=best ................\n",
            "[CV]  criterion=gini, max_features=log2, splitter=best, score=0.906, total=   0.0s\n",
            "[CV] criterion=gini, max_features=log2, splitter=best ................\n",
            "[CV]  criterion=gini, max_features=log2, splitter=best, score=0.917, total=   0.0s\n",
            "[CV] criterion=gini, max_features=log2, splitter=best ................\n",
            "[CV]  criterion=gini, max_features=log2, splitter=best, score=0.892, total=   0.0s\n",
            "[CV] criterion=gini, max_features=log2, splitter=best ................\n",
            "[CV]  criterion=gini, max_features=log2, splitter=best, score=0.923, total=   0.0s\n",
            "[CV] criterion=gini, max_features=log2, splitter=random ..............\n",
            "[CV]  criterion=gini, max_features=log2, splitter=random, score=0.908, total=   0.0s\n",
            "[CV] criterion=gini, max_features=log2, splitter=random ..............\n",
            "[CV]  criterion=gini, max_features=log2, splitter=random, score=0.894, total=   0.0s\n",
            "[CV] criterion=gini, max_features=log2, splitter=random ..............\n",
            "[CV]  criterion=gini, max_features=log2, splitter=random, score=0.910, total=   0.0s\n",
            "[CV] criterion=gini, max_features=log2, splitter=random ..............\n",
            "[CV]  criterion=gini, max_features=log2, splitter=random, score=0.913, total=   0.0s\n",
            "[CV] criterion=gini, max_features=log2, splitter=random ..............\n",
            "[CV]  criterion=gini, max_features=log2, splitter=random, score=0.896, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=auto, splitter=best .............\n",
            "[CV]  criterion=entropy, max_features=auto, splitter=best, score=0.940, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=auto, splitter=best .............\n",
            "[CV]  criterion=entropy, max_features=auto, splitter=best, score=0.927, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=auto, splitter=best .............\n",
            "[CV]  criterion=entropy, max_features=auto, splitter=best, score=0.937, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=auto, splitter=best .............\n",
            "[CV]  criterion=entropy, max_features=auto, splitter=best, score=0.935, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=auto, splitter=best .............\n",
            "[CV]  criterion=entropy, max_features=auto, splitter=best, score=0.917, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=auto, splitter=random ...........\n",
            "[CV]  criterion=entropy, max_features=auto, splitter=random, score=0.921, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=auto, splitter=random ...........\n",
            "[CV]  criterion=entropy, max_features=auto, splitter=random, score=0.875, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=auto, splitter=random ...........\n",
            "[CV]  criterion=entropy, max_features=auto, splitter=random, score=0.902, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=auto, splitter=random ...........\n",
            "[CV]  criterion=entropy, max_features=auto, splitter=random, score=0.913, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=auto, splitter=random ...........\n",
            "[CV]  criterion=entropy, max_features=auto, splitter=random, score=0.921, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=sqrt, splitter=best .............\n",
            "[CV]  criterion=entropy, max_features=sqrt, splitter=best, score=0.940, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=sqrt, splitter=best .............\n",
            "[CV]  criterion=entropy, max_features=sqrt, splitter=best, score=0.927, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=sqrt, splitter=best .............\n",
            "[CV]  criterion=entropy, max_features=sqrt, splitter=best, score=0.937, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=sqrt, splitter=best .............\n",
            "[CV]  criterion=entropy, max_features=sqrt, splitter=best, score=0.935, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=sqrt, splitter=best .............\n",
            "[CV]  criterion=entropy, max_features=sqrt, splitter=best, score=0.917, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=sqrt, splitter=random ...........\n",
            "[CV]  criterion=entropy, max_features=sqrt, splitter=random, score=0.921, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=sqrt, splitter=random ...........\n",
            "[CV]  criterion=entropy, max_features=sqrt, splitter=random, score=0.875, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=sqrt, splitter=random ...........\n",
            "[CV]  criterion=entropy, max_features=sqrt, splitter=random, score=0.902, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=sqrt, splitter=random ...........\n",
            "[CV]  criterion=entropy, max_features=sqrt, splitter=random, score=0.913, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=sqrt, splitter=random ...........\n",
            "[CV]  criterion=entropy, max_features=sqrt, splitter=random, score=0.921, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=log2, splitter=best .............\n",
            "[CV]  criterion=entropy, max_features=log2, splitter=best, score=0.887, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=log2, splitter=best .............\n",
            "[CV]  criterion=entropy, max_features=log2, splitter=best, score=0.906, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=log2, splitter=best .............\n",
            "[CV]  criterion=entropy, max_features=log2, splitter=best, score=0.917, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=log2, splitter=best .............\n",
            "[CV]  criterion=entropy, max_features=log2, splitter=best, score=0.915, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=log2, splitter=best .............\n",
            "[CV]  criterion=entropy, max_features=log2, splitter=best, score=0.915, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=log2, splitter=random ...........\n",
            "[CV]  criterion=entropy, max_features=log2, splitter=random, score=0.887, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=log2, splitter=random ...........\n",
            "[CV]  criterion=entropy, max_features=log2, splitter=random, score=0.915, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=log2, splitter=random ...........\n",
            "[CV]  criterion=entropy, max_features=log2, splitter=random, score=0.908, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=log2, splitter=random ...........\n",
            "[CV]  criterion=entropy, max_features=log2, splitter=random, score=0.900, total=   0.0s\n",
            "[CV] criterion=entropy, max_features=log2, splitter=random ...........\n",
            "[CV]  criterion=entropy, max_features=log2, splitter=random, score=0.900, total=   0.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    1.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features=None,\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              presort='deprecated',\n",
              "                                              random_state=42,\n",
              "                                              splitter='best'),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'criterion': ['gini', 'entropy'],\n",
              "                          'max_features': ['auto', 'sqrt', 'log2'],\n",
              "                          'splitter': ['best', 'random']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwqiealSTiDg",
        "outputId": "71d7a80d-3f91-4f55-aa49-07289d489548"
      },
      "source": [
        "grid_search_dt.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'entropy', 'max_features': 'auto', 'splitter': 'best'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5X7wSXmTk5J",
        "outputId": "0ce4a8d3-ff7e-4eeb-a082-63939acb56d0"
      },
      "source": [
        "grid_search_dt.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9311538461538461"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ds-1CIaiTo2M",
        "outputId": "a2112932-50ef-411b-868e-6f12d2d4d7c5"
      },
      "source": [
        "y_pred_dt = grid_search_dt.predict(X_test_transformed)\n",
        "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred_dt)))\n",
        "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred_dt)))\n",
        "print(\"f1 score: {:.2f}%\".format(100 * f1_score(y_test, y_pred_dt)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 80.36%\n",
            "Recall: 86.54%\n",
            "f1 score: 83.33%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "1avmwp41SdqP",
        "outputId": "31907d7b-0f64-4ad3-dfa7-5234940c9aec"
      },
      "source": [
        "plot_confusion_matrix(grid_search_dt, X_test_transformed, y_test, cmap=plt.cm.Blues)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f5f9c751d10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agtI1-QZT9JW"
      },
      "source": [
        "###4. Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV2yrJBmT5Ul",
        "outputId": "82c555e4-efad-4a9d-e3c8-c17198e88e7a"
      },
      "source": [
        "import random\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "n_estimators = []\n",
        "for i in range(0, 10):\n",
        "  n = random.randint(0, 200)\n",
        "  n_estimators.append(n)\n",
        "\n",
        "rf_param_grid = [{\n",
        "    'n_estimators': n_estimators,\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'bootstrap': [True, False],\n",
        "}]\n",
        "\n",
        "rf_clf = RandomForestClassifier(random_state=42)\n",
        "grid_search_rf = GridSearchCV(rf_clf, param_grid=rf_param_grid, cv=5, verbose=3)\n",
        "grid_search_rf.fit(X_train_transformed, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=153 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=153, score=0.979, total=   1.4s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=153 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=153, score=0.967, total=   1.5s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=153 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=153, score=0.977, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=153 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=153, score=0.977, total=   1.4s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=153 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=153, score=0.975, total=   1.4s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=139, score=0.973, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=139, score=0.967, total=   1.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=139, score=0.975, total=   1.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=139, score=0.977, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=139, score=0.975, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=55, score=0.979, total=   0.5s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=55, score=0.960, total=   0.5s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=55, score=0.975, total=   0.5s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=55, score=0.969, total=   0.5s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=55, score=0.975, total=   0.5s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=89, score=0.979, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=89, score=0.963, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=89, score=0.977, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=89, score=0.973, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=89, score=0.975, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=19, score=0.969, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=19, score=0.965, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=19, score=0.979, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=19, score=0.965, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=19, score=0.969, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=198, score=0.977, total=   1.8s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=198, score=0.965, total=   1.8s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=198, score=0.975, total=   1.7s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=198, score=0.977, total=   1.8s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=198, score=0.975, total=   1.8s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=144, score=0.977, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=144, score=0.967, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=144, score=0.975, total=   1.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=144, score=0.977, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=144, score=0.977, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=94, score=0.975, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=94, score=0.963, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=94, score=0.979, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=94, score=0.973, total=   0.9s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=94, score=0.975, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=26, score=0.973, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=26, score=0.965, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=26, score=0.979, total=   0.3s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=26, score=0.971, total=   0.3s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=26, score=0.962, total=   0.3s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=112, score=0.975, total=   1.0s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=112, score=0.965, total=   1.0s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=112, score=0.977, total=   1.0s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=112, score=0.977, total=   1.0s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=auto, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=auto, n_estimators=112, score=0.977, total=   1.0s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=153 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=153, score=0.979, total=   1.4s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=153 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=153, score=0.967, total=   1.4s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=153 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=153, score=0.977, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=153 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=153, score=0.977, total=   1.4s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=153 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=153, score=0.975, total=   1.4s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=139, score=0.973, total=   1.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=139, score=0.967, total=   1.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=139, score=0.975, total=   1.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=139, score=0.977, total=   1.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=139, score=0.975, total=   1.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=55, score=0.979, total=   0.5s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=55, score=0.960, total=   0.5s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=55, score=0.975, total=   0.5s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=55, score=0.969, total=   0.5s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=55, score=0.975, total=   0.5s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=89, score=0.979, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=89, score=0.963, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=89, score=0.977, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=89, score=0.973, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=89, score=0.975, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=19, score=0.969, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=19, score=0.965, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=19, score=0.979, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=19, score=0.965, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=19, score=0.969, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=198, score=0.977, total=   1.8s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=198, score=0.965, total=   1.8s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=198, score=0.975, total=   1.7s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=198, score=0.977, total=   1.7s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=198, score=0.975, total=   1.8s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=144, score=0.977, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=144, score=0.967, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=144, score=0.975, total=   1.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=144, score=0.977, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=144, score=0.977, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=94, score=0.975, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=94, score=0.963, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=94, score=0.979, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=94, score=0.973, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=94, score=0.975, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=26, score=0.973, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=26, score=0.965, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=26, score=0.979, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=26, score=0.971, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=26, score=0.962, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=112, score=0.975, total=   1.0s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=112, score=0.965, total=   1.0s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=112, score=0.977, total=   1.0s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=112, score=0.977, total=   1.0s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=sqrt, n_estimators=112, score=0.977, total=   1.0s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=153 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=153, score=0.971, total=   1.0s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=153 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=153, score=0.954, total=   1.0s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=153 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=153, score=0.965, total=   0.9s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=153 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=153, score=0.962, total=   0.9s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=153 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=153, score=0.967, total=   0.9s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=139, score=0.971, total=   0.9s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=139, score=0.954, total=   0.9s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=139, score=0.965, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=139, score=0.967, total=   0.9s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=139, score=0.971, total=   0.9s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=55, score=0.975, total=   0.3s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=55, score=0.952, total=   0.3s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=55, score=0.969, total=   0.3s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=55, score=0.962, total=   0.3s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=55, score=0.967, total=   0.4s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=89, score=0.975, total=   0.6s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=89, score=0.956, total=   0.6s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=89, score=0.969, total=   0.5s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=89, score=0.967, total=   0.5s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=89, score=0.969, total=   0.5s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=19, score=0.969, total=   0.1s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=19, score=0.948, total=   0.1s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=19, score=0.963, total=   0.1s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=19, score=0.965, total=   0.1s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=19, score=0.958, total=   0.1s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=198, score=0.971, total=   1.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=198, score=0.950, total=   1.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=198, score=0.965, total=   1.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=198, score=0.958, total=   1.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=198, score=0.967, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=144, score=0.971, total=   0.9s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=144, score=0.952, total=   0.9s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=144, score=0.965, total=   0.9s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=144, score=0.967, total=   0.9s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=144, score=0.969, total=   0.9s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=94, score=0.975, total=   0.6s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=94, score=0.956, total=   0.6s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=94, score=0.969, total=   0.6s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=94, score=0.963, total=   0.6s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=94, score=0.969, total=   0.6s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=26, score=0.967, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=26, score=0.950, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=26, score=0.965, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=26, score=0.960, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=26, score=0.960, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=112, score=0.973, total=   0.7s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=112, score=0.954, total=   0.7s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=112, score=0.965, total=   0.7s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=112, score=0.963, total=   0.7s\n",
            "[CV] bootstrap=True, criterion=gini, max_features=log2, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=gini, max_features=log2, n_estimators=112, score=0.965, total=   0.7s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=153 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=153, score=0.981, total=   1.4s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=153 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=153, score=0.967, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=153 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=153, score=0.975, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=153 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=153, score=0.973, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=153 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=153, score=0.971, total=   1.4s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=139, score=0.981, total=   1.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=139, score=0.967, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=139, score=0.977, total=   1.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=139, score=0.973, total=   1.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=139, score=0.971, total=   1.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=55, score=0.979, total=   0.5s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=55, score=0.965, total=   0.5s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=55, score=0.973, total=   0.5s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=55, score=0.977, total=   0.5s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=55, score=0.975, total=   0.5s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=89, score=0.979, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=89, score=0.967, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=89, score=0.973, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=89, score=0.969, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=89, score=0.973, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=19, score=0.969, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=19, score=0.965, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=19, score=0.971, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=19, score=0.962, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=19, score=0.973, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=198, score=0.977, total=   1.8s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=198, score=0.967, total=   1.7s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=198, score=0.975, total=   1.7s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=198, score=0.971, total=   1.8s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=198, score=0.973, total=   1.7s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=144, score=0.981, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=144, score=0.967, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=144, score=0.975, total=   1.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=144, score=0.973, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=144, score=0.971, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=94, score=0.979, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=94, score=0.971, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=94, score=0.975, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=94, score=0.971, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=94, score=0.973, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=26, score=0.975, total=   0.3s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=26, score=0.958, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=26, score=0.975, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=26, score=0.969, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=26, score=0.979, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=112, score=0.981, total=   1.0s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=112, score=0.969, total=   1.0s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=112, score=0.977, total=   1.0s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=112, score=0.971, total=   1.0s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=auto, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=auto, n_estimators=112, score=0.971, total=   1.0s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=153 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=153, score=0.981, total=   1.4s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=153 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=153, score=0.967, total=   1.4s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=153 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=153, score=0.975, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=153 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=153, score=0.973, total=   1.4s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=153 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=153, score=0.971, total=   1.4s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=139, score=0.981, total=   1.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=139, score=0.967, total=   1.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=139, score=0.977, total=   1.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=139, score=0.973, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=139, score=0.971, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=55, score=0.979, total=   0.5s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=55, score=0.965, total=   0.5s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=55, score=0.973, total=   0.5s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=55, score=0.977, total=   0.5s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=55, score=0.975, total=   0.5s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=89, score=0.979, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=89, score=0.967, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=89, score=0.973, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=89, score=0.969, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=89, score=0.973, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=19, score=0.969, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=19, score=0.965, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=19, score=0.971, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=19, score=0.962, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=19, score=0.973, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=198, score=0.977, total=   1.8s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=198, score=0.967, total=   1.8s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=198, score=0.975, total=   1.7s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=198, score=0.971, total=   1.8s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=198, score=0.973, total=   1.8s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=144, score=0.981, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=144, score=0.967, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=144, score=0.975, total=   1.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=144, score=0.973, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=144, score=0.971, total=   1.3s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=94, score=0.979, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=94, score=0.971, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=94, score=0.975, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=94, score=0.971, total=   0.9s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=94, score=0.973, total=   0.8s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=26, score=0.975, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=26, score=0.958, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=26, score=0.975, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=26, score=0.969, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=26, score=0.979, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=112, score=0.981, total=   1.0s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=112, score=0.969, total=   1.0s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=112, score=0.977, total=   1.0s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=112, score=0.971, total=   1.0s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=sqrt, n_estimators=112, score=0.971, total=   1.0s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=153 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=153, score=0.969, total=   1.0s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=153 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=153, score=0.956, total=   1.0s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=153 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=153, score=0.967, total=   0.9s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=153 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=153, score=0.967, total=   0.9s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=153 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=153, score=0.967, total=   0.9s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=139, score=0.969, total=   0.9s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=139, score=0.956, total=   0.9s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=139, score=0.967, total=   0.9s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=139, score=0.969, total=   0.9s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=139 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=139, score=0.969, total=   0.9s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=55, score=0.973, total=   0.4s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=55, score=0.956, total=   0.4s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=55, score=0.956, total=   0.3s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=55, score=0.973, total=   0.4s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=55 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=55, score=0.967, total=   0.3s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=89, score=0.969, total=   0.6s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=89, score=0.958, total=   0.6s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=89, score=0.965, total=   0.6s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=89, score=0.969, total=   0.6s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=89 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=89, score=0.965, total=   0.6s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=19, score=0.967, total=   0.1s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=19, score=0.956, total=   0.1s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=19, score=0.960, total=   0.1s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=19, score=0.965, total=   0.1s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=19 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=19, score=0.962, total=   0.1s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=198, score=0.971, total=   1.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=198, score=0.954, total=   1.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=198, score=0.967, total=   1.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=198, score=0.967, total=   1.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=198 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=198, score=0.967, total=   1.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=144, score=0.969, total=   0.9s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=144, score=0.956, total=   0.9s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=144, score=0.967, total=   0.9s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=144, score=0.967, total=   0.9s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=144 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=144, score=0.967, total=   0.9s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=94, score=0.969, total=   0.6s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=94, score=0.958, total=   0.6s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=94, score=0.963, total=   0.6s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=94, score=0.969, total=   0.6s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=94 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=94, score=0.963, total=   0.6s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=26, score=0.969, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=26, score=0.952, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=26, score=0.954, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=26, score=0.963, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=26 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=26, score=0.965, total=   0.2s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=112, score=0.969, total=   0.7s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=112, score=0.954, total=   0.7s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=112, score=0.967, total=   0.7s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=112, score=0.965, total=   0.7s\n",
            "[CV] bootstrap=True, criterion=entropy, max_features=log2, n_estimators=112 \n",
            "[CV]  bootstrap=True, criterion=entropy, max_features=log2, n_estimators=112, score=0.967, total=   0.7s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=153, score=0.981, total=   1.4s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=153, score=0.963, total=   1.4s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=153, score=0.975, total=   1.4s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=153, score=0.975, total=   1.4s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=153, score=0.975, total=   1.4s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=139, score=0.981, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=139, score=0.963, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=139, score=0.975, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=139, score=0.977, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=139, score=0.975, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=55, score=0.979, total=   0.5s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=55, score=0.960, total=   0.5s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=55, score=0.973, total=   0.5s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=55, score=0.971, total=   0.5s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=55, score=0.975, total=   0.5s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=89, score=0.983, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=89, score=0.962, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=89, score=0.975, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=89, score=0.971, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=89, score=0.975, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=19, score=0.973, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=19, score=0.952, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=19, score=0.971, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=19, score=0.967, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=19, score=0.973, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=198, score=0.979, total=   1.9s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=198, score=0.965, total=   1.8s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=198, score=0.977, total=   1.8s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=198, score=0.973, total=   1.9s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=198, score=0.975, total=   1.9s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=144, score=0.981, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=144, score=0.963, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=144, score=0.975, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=144, score=0.975, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=144, score=0.975, total=   1.4s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=94, score=0.983, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=94, score=0.962, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=94, score=0.975, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=94, score=0.971, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=94, score=0.975, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=26, score=0.981, total=   0.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=26, score=0.954, total=   0.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=26, score=0.969, total=   0.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=26, score=0.965, total=   0.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=26, score=0.971, total=   0.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=112, score=0.981, total=   1.1s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=112, score=0.963, total=   1.0s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=112, score=0.975, total=   1.0s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=112, score=0.973, total=   1.0s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=auto, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=auto, n_estimators=112, score=0.975, total=   1.1s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=153, score=0.981, total=   1.4s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=153, score=0.963, total=   1.4s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=153, score=0.975, total=   1.4s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=153, score=0.975, total=   1.4s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=153, score=0.975, total=   1.4s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=139, score=0.981, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=139, score=0.963, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=139, score=0.975, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=139, score=0.977, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=139, score=0.975, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=55, score=0.979, total=   0.5s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=55, score=0.960, total=   0.5s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=55, score=0.973, total=   0.5s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=55, score=0.971, total=   0.5s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=55, score=0.975, total=   0.5s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=89, score=0.983, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=89, score=0.962, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=89, score=0.975, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=89, score=0.971, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=89, score=0.975, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=19, score=0.973, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=19, score=0.952, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=19, score=0.971, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=19, score=0.967, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=19, score=0.973, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=198, score=0.979, total=   1.9s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=198, score=0.965, total=   1.8s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=198, score=0.977, total=   1.8s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=198, score=0.973, total=   1.9s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=198, score=0.975, total=   1.9s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=144, score=0.981, total=   1.4s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=144, score=0.963, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=144, score=0.975, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=144, score=0.975, total=   1.4s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=144, score=0.975, total=   1.4s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=94, score=0.983, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=94, score=0.962, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=94, score=0.975, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=94, score=0.971, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=94, score=0.975, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=26, score=0.981, total=   0.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=26, score=0.954, total=   0.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=26, score=0.969, total=   0.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=26, score=0.965, total=   0.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=26, score=0.971, total=   0.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=112, score=0.981, total=   1.1s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=112, score=0.963, total=   1.1s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=112, score=0.975, total=   1.0s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=112, score=0.973, total=   1.1s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=sqrt, n_estimators=112, score=0.975, total=   1.1s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=153, score=0.971, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=153, score=0.948, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=153, score=0.971, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=153, score=0.967, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=153, score=0.975, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=139, score=0.973, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=139, score=0.952, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=139, score=0.971, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=139, score=0.965, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=139, score=0.973, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=55, score=0.963, total=   0.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=55, score=0.956, total=   0.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=55, score=0.967, total=   0.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=55, score=0.965, total=   0.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=55, score=0.969, total=   0.3s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=89, score=0.973, total=   0.5s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=89, score=0.952, total=   0.5s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=89, score=0.969, total=   0.5s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=89, score=0.967, total=   0.5s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=89, score=0.973, total=   0.6s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=19, score=0.960, total=   0.1s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=19, score=0.956, total=   0.1s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=19, score=0.967, total=   0.1s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=19, score=0.960, total=   0.1s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=19, score=0.963, total=   0.1s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=198, score=0.967, total=   1.2s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=198, score=0.950, total=   1.2s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=198, score=0.975, total=   1.2s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=198, score=0.960, total=   1.2s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=198, score=0.971, total=   1.2s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=144, score=0.971, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=144, score=0.950, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=144, score=0.971, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=144, score=0.963, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=144, score=0.971, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=94, score=0.969, total=   0.6s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=94, score=0.950, total=   0.6s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=94, score=0.969, total=   0.6s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=94, score=0.965, total=   0.6s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=94, score=0.973, total=   0.6s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=26, score=0.962, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=26, score=0.958, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=26, score=0.967, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=26, score=0.960, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=26, score=0.965, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=112, score=0.967, total=   0.7s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=112, score=0.948, total=   0.7s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=112, score=0.969, total=   0.7s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=112, score=0.963, total=   0.7s\n",
            "[CV] bootstrap=False, criterion=gini, max_features=log2, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=gini, max_features=log2, n_estimators=112, score=0.973, total=   0.7s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=153, score=0.981, total=   1.4s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=153, score=0.965, total=   1.4s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=153, score=0.975, total=   1.4s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=153, score=0.975, total=   1.4s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=153, score=0.975, total=   1.5s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=139, score=0.981, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=139, score=0.965, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=139, score=0.977, total=   1.2s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=139, score=0.975, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=139, score=0.975, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=55, score=0.981, total=   0.5s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=55, score=0.965, total=   0.5s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=55, score=0.977, total=   0.5s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=55, score=0.975, total=   0.5s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=55, score=0.975, total=   0.5s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=89, score=0.983, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=89, score=0.965, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=89, score=0.975, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=89, score=0.977, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=89, score=0.975, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=19, score=0.979, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=19, score=0.960, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=19, score=0.965, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=19, score=0.977, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=19, score=0.971, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=198, score=0.981, total=   1.8s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=198, score=0.967, total=   1.8s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=198, score=0.977, total=   1.7s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=198, score=0.975, total=   1.8s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=198, score=0.973, total=   1.9s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=144, score=0.981, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=144, score=0.963, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=144, score=0.975, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=144, score=0.975, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=144, score=0.975, total=   1.4s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=94, score=0.983, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=94, score=0.963, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=94, score=0.977, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=94, score=0.977, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=94, score=0.975, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=26, score=0.975, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=26, score=0.960, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=26, score=0.971, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=26, score=0.977, total=   0.3s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=26, score=0.969, total=   0.3s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=112, score=0.981, total=   1.0s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=112, score=0.963, total=   1.0s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=112, score=0.975, total=   1.0s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=112, score=0.977, total=   1.0s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=auto, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=auto, n_estimators=112, score=0.975, total=   1.1s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=153, score=0.981, total=   1.4s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=153, score=0.965, total=   1.4s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=153, score=0.975, total=   1.4s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=153, score=0.975, total=   1.4s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=153, score=0.975, total=   1.4s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=139, score=0.981, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=139, score=0.965, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=139, score=0.977, total=   1.2s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=139, score=0.975, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=139, score=0.975, total=   1.4s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=55, score=0.981, total=   0.5s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=55, score=0.965, total=   0.5s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=55, score=0.977, total=   0.5s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=55, score=0.975, total=   0.5s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=55, score=0.975, total=   0.5s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=89, score=0.983, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=89, score=0.965, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=89, score=0.975, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=89, score=0.977, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=89, score=0.975, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=19, score=0.979, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=19, score=0.960, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=19, score=0.965, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=19, score=0.977, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=19, score=0.971, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=198, score=0.981, total=   1.8s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=198, score=0.967, total=   1.8s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=198, score=0.977, total=   1.8s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=198, score=0.975, total=   1.8s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=198, score=0.973, total=   1.9s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=144, score=0.981, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=144, score=0.963, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=144, score=0.975, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=144, score=0.975, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=144, score=0.975, total=   1.3s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=94, score=0.983, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=94, score=0.963, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=94, score=0.977, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=94, score=0.977, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=94, score=0.975, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=26, score=0.975, total=   0.3s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=26, score=0.960, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=26, score=0.971, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=26, score=0.977, total=   0.3s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=26, score=0.969, total=   0.3s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=112, score=0.981, total=   1.1s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=112, score=0.963, total=   1.0s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=112, score=0.975, total=   1.0s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=112, score=0.977, total=   1.0s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=sqrt, n_estimators=112, score=0.975, total=   1.1s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=153, score=0.969, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=153, score=0.958, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=153, score=0.967, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=153, score=0.969, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=153 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=153, score=0.969, total=   1.0s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=139, score=0.971, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=139, score=0.958, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=139, score=0.967, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=139, score=0.967, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=139 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=139, score=0.975, total=   0.8s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=55, score=0.969, total=   0.4s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=55, score=0.960, total=   0.3s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=55, score=0.963, total=   0.3s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=55, score=0.969, total=   0.4s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=55 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=55, score=0.975, total=   0.3s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=89, score=0.965, total=   0.6s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=89, score=0.962, total=   0.6s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=89, score=0.965, total=   0.5s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=89, score=0.969, total=   0.5s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=89 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=89, score=0.971, total=   0.6s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=19, score=0.962, total=   0.1s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=19, score=0.965, total=   0.1s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=19, score=0.956, total=   0.1s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=19, score=0.973, total=   0.1s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=19 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=19, score=0.969, total=   0.1s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=198, score=0.969, total=   1.2s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=198, score=0.958, total=   1.2s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=198, score=0.967, total=   1.2s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=198, score=0.969, total=   1.2s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=198 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=198, score=0.973, total=   1.2s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=144, score=0.969, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=144, score=0.958, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=144, score=0.969, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=144, score=0.971, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=144 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=144, score=0.973, total=   0.9s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=94, score=0.965, total=   0.6s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=94, score=0.962, total=   0.6s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=94, score=0.965, total=   0.6s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=94, score=0.967, total=   0.6s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=94 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=94, score=0.971, total=   0.6s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=26, score=0.962, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=26, score=0.962, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=26, score=0.962, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=26, score=0.973, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=26 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=26, score=0.973, total=   0.2s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=112, score=0.969, total=   0.7s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=112, score=0.962, total=   0.7s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=112, score=0.967, total=   0.7s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=112, score=0.965, total=   0.7s\n",
            "[CV] bootstrap=False, criterion=entropy, max_features=log2, n_estimators=112 \n",
            "[CV]  bootstrap=False, criterion=entropy, max_features=log2, n_estimators=112, score=0.969, total=   0.7s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed:  8.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False, random_state=42,\n",
              "                                              verbose=0, warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'bootstrap': [True, False],\n",
              "                          'criterion': ['gini', 'entropy'],\n",
              "                          'max_features': ['auto', 'sqrt', 'log2'],\n",
              "                          'n_estimators': [153, 139, 55, 89, 19, 198, 144, 94,\n",
              "                                           26, 112]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IK1fAh1apac",
        "outputId": "99f8e32c-a6be-40ee-aede-7a83b597bf99"
      },
      "source": [
        "grid_search_rf.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': True,\n",
              " 'criterion': 'gini',\n",
              " 'max_features': 'auto',\n",
              " 'n_estimators': 153}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXsu9gWJauX7",
        "outputId": "4858cc16-111b-45b8-e76d-1f003987c18e"
      },
      "source": [
        "grid_search_rf.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.975"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHc-0XYAayIu",
        "outputId": "4a4340ca-c52a-40e4-e5bc-c8a38057df17"
      },
      "source": [
        "y_pred_rf = grid_search_rf.predict(X_test_transformed)\n",
        "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred_rf)))\n",
        "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred_rf)))\n",
        "print(\"f1 score: {:.2f}%\".format(100 * f1_score(y_test, y_pred_rf)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 98.97%\n",
            "Recall: 92.31%\n",
            "f1 score: 95.52%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "AAWufauia5lY",
        "outputId": "027d8ba3-17b7-4070-edc7-8c3c877b5102"
      },
      "source": [
        "plot_confusion_matrix(grid_search_rf, X_test_transformed, y_test, cmap=plt.cm.Blues)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f5f9c99b6d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShmIpv6EfN0_"
      },
      "source": [
        "###5. Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5TuEeUTfXBS"
      },
      "source": [
        "####1. Gaussian NB\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKJfk6BCesEy",
        "outputId": "8c87f936-6973-497a-9f3e-4b7876a4ac3b"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "gnb_clf = GaussianNB()\n",
        "gnb_clf.fit(X_train_transformed.toarray(), y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4tMLyt9OhdI",
        "outputId": "12ea909b-66c1-4933-d6de-be2701ae4bd2"
      },
      "source": [
        "y_pred_gnb = gnb_clf.predict(X_test_transformed.toarray())\n",
        "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred_gnb)))\n",
        "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred_gnb)))\n",
        "print(\"f1 score: {:.2f}%\".format(100 * f1_score(y_test, y_pred_gnb)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 41.08%\n",
            "Recall: 95.19%\n",
            "f1 score: 57.39%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5-5m1cukqNm",
        "outputId": "aedf73af-47dd-47ef-fc18-684a467c8478"
      },
      "source": [
        "# Hyperparameter tuning\n",
        "nb_param_grid = [{\n",
        "    'var_smoothing': [1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11, 1e-12, 1e-13, 1e-14, 1e-15]\n",
        "}]\n",
        "\n",
        "gnb_clf = GaussianNB()\n",
        "grid_search_nb = GridSearchCV(gnb_clf, param_grid=nb_param_grid, cv=5, verbose=3)\n",
        "grid_search_nb.fit(X_train_transformed.toarray(), y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
            "[CV] var_smoothing=1e-05 .............................................\n",
            "[CV] ................. var_smoothing=1e-05, score=0.885, total=   0.0s\n",
            "[CV] var_smoothing=1e-05 .............................................\n",
            "[CV] ................. var_smoothing=1e-05, score=0.327, total=   0.0s\n",
            "[CV] var_smoothing=1e-05 .............................................\n",
            "[CV] ................. var_smoothing=1e-05, score=0.844, total=   0.0s\n",
            "[CV] var_smoothing=1e-05 .............................................\n",
            "[CV] ................. var_smoothing=1e-05, score=0.883, total=   0.0s\n",
            "[CV] var_smoothing=1e-05 .............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................. var_smoothing=1e-05, score=0.588, total=   0.1s\n",
            "[CV] var_smoothing=1e-06 .............................................\n",
            "[CV] ................. var_smoothing=1e-06, score=0.667, total=   0.0s\n",
            "[CV] var_smoothing=1e-06 .............................................\n",
            "[CV] ................. var_smoothing=1e-06, score=0.510, total=   0.0s\n",
            "[CV] var_smoothing=1e-06 .............................................\n",
            "[CV] ................. var_smoothing=1e-06, score=0.904, total=   0.0s\n",
            "[CV] var_smoothing=1e-06 .............................................\n",
            "[CV] ................. var_smoothing=1e-06, score=0.819, total=   0.0s\n",
            "[CV] var_smoothing=1e-06 .............................................\n",
            "[CV] ................. var_smoothing=1e-06, score=0.596, total=   0.0s\n",
            "[CV] var_smoothing=1e-07 .............................................\n",
            "[CV] ................. var_smoothing=1e-07, score=0.712, total=   0.0s\n",
            "[CV] var_smoothing=1e-07 .............................................\n",
            "[CV] ................. var_smoothing=1e-07, score=0.690, total=   0.0s\n",
            "[CV] var_smoothing=1e-07 .............................................\n",
            "[CV] ................. var_smoothing=1e-07, score=0.892, total=   0.0s\n",
            "[CV] var_smoothing=1e-07 .............................................\n",
            "[CV] ................. var_smoothing=1e-07, score=0.804, total=   0.1s\n",
            "[CV] var_smoothing=1e-07 .............................................\n",
            "[CV] ................. var_smoothing=1e-07, score=0.717, total=   0.0s\n",
            "[CV] var_smoothing=1e-08 .............................................\n",
            "[CV] ................. var_smoothing=1e-08, score=0.750, total=   0.0s\n",
            "[CV] var_smoothing=1e-08 .............................................\n",
            "[CV] ................. var_smoothing=1e-08, score=0.779, total=   0.0s\n",
            "[CV] var_smoothing=1e-08 .............................................\n",
            "[CV] ................. var_smoothing=1e-08, score=0.865, total=   0.0s\n",
            "[CV] var_smoothing=1e-08 .............................................\n",
            "[CV] ................. var_smoothing=1e-08, score=0.800, total=   0.1s\n",
            "[CV] var_smoothing=1e-08 .............................................\n",
            "[CV] ................. var_smoothing=1e-08, score=0.825, total=   0.0s\n",
            "[CV] var_smoothing=1e-09 .............................................\n",
            "[CV] ................. var_smoothing=1e-09, score=0.744, total=   0.0s\n",
            "[CV] var_smoothing=1e-09 .............................................\n",
            "[CV] ................. var_smoothing=1e-09, score=0.779, total=   0.1s\n",
            "[CV] var_smoothing=1e-09 .............................................\n",
            "[CV] ................. var_smoothing=1e-09, score=0.867, total=   0.0s\n",
            "[CV] var_smoothing=1e-09 .............................................\n",
            "[CV] ................. var_smoothing=1e-09, score=0.787, total=   0.0s\n",
            "[CV] var_smoothing=1e-09 .............................................\n",
            "[CV] ................. var_smoothing=1e-09, score=0.825, total=   0.0s\n",
            "[CV] var_smoothing=1e-10 .............................................\n",
            "[CV] ................. var_smoothing=1e-10, score=0.738, total=   0.0s\n",
            "[CV] var_smoothing=1e-10 .............................................\n",
            "[CV] ................. var_smoothing=1e-10, score=0.777, total=   0.0s\n",
            "[CV] var_smoothing=1e-10 .............................................\n",
            "[CV] ................. var_smoothing=1e-10, score=0.788, total=   0.0s\n",
            "[CV] var_smoothing=1e-10 .............................................\n",
            "[CV] ................. var_smoothing=1e-10, score=0.773, total=   0.0s\n",
            "[CV] var_smoothing=1e-10 .............................................\n",
            "[CV] ................. var_smoothing=1e-10, score=0.819, total=   0.0s\n",
            "[CV] var_smoothing=1e-11 .............................................\n",
            "[CV] ................. var_smoothing=1e-11, score=0.731, total=   0.0s\n",
            "[CV] var_smoothing=1e-11 .............................................\n",
            "[CV] ................. var_smoothing=1e-11, score=0.775, total=   0.0s\n",
            "[CV] var_smoothing=1e-11 .............................................\n",
            "[CV] ................. var_smoothing=1e-11, score=0.775, total=   0.0s\n",
            "[CV] var_smoothing=1e-11 .............................................\n",
            "[CV] ................. var_smoothing=1e-11, score=0.769, total=   0.0s\n",
            "[CV] var_smoothing=1e-11 .............................................\n",
            "[CV] ................. var_smoothing=1e-11, score=0.815, total=   0.0s\n",
            "[CV] var_smoothing=1e-12 .............................................\n",
            "[CV] ................. var_smoothing=1e-12, score=0.723, total=   0.0s\n",
            "[CV] var_smoothing=1e-12 .............................................\n",
            "[CV] ................. var_smoothing=1e-12, score=0.773, total=   0.0s\n",
            "[CV] var_smoothing=1e-12 .............................................\n",
            "[CV] ................. var_smoothing=1e-12, score=0.767, total=   0.0s\n",
            "[CV] var_smoothing=1e-12 .............................................\n",
            "[CV] ................. var_smoothing=1e-12, score=0.763, total=   0.0s\n",
            "[CV] var_smoothing=1e-12 .............................................\n",
            "[CV] ................. var_smoothing=1e-12, score=0.815, total=   0.0s\n",
            "[CV] var_smoothing=1e-13 .............................................\n",
            "[CV] ................. var_smoothing=1e-13, score=0.721, total=   0.0s\n",
            "[CV] var_smoothing=1e-13 .............................................\n",
            "[CV] ................. var_smoothing=1e-13, score=0.773, total=   0.0s\n",
            "[CV] var_smoothing=1e-13 .............................................\n",
            "[CV] ................. var_smoothing=1e-13, score=0.758, total=   0.0s\n",
            "[CV] var_smoothing=1e-13 .............................................\n",
            "[CV] ................. var_smoothing=1e-13, score=0.762, total=   0.0s\n",
            "[CV] var_smoothing=1e-13 .............................................\n",
            "[CV] ................. var_smoothing=1e-13, score=0.813, total=   0.1s\n",
            "[CV] var_smoothing=1e-14 .............................................\n",
            "[CV] ................. var_smoothing=1e-14, score=0.713, total=   0.0s\n",
            "[CV] var_smoothing=1e-14 .............................................\n",
            "[CV] ................. var_smoothing=1e-14, score=0.773, total=   0.0s\n",
            "[CV] var_smoothing=1e-14 .............................................\n",
            "[CV] ................. var_smoothing=1e-14, score=0.756, total=   0.0s\n",
            "[CV] var_smoothing=1e-14 .............................................\n",
            "[CV] ................. var_smoothing=1e-14, score=0.754, total=   0.0s\n",
            "[CV] var_smoothing=1e-14 .............................................\n",
            "[CV] ................. var_smoothing=1e-14, score=0.813, total=   0.0s\n",
            "[CV] var_smoothing=1e-15 .............................................\n",
            "[CV] ................. var_smoothing=1e-15, score=0.706, total=   0.0s\n",
            "[CV] var_smoothing=1e-15 .............................................\n",
            "[CV] ................. var_smoothing=1e-15, score=0.773, total=   0.0s\n",
            "[CV] var_smoothing=1e-15 .............................................\n",
            "[CV] ................. var_smoothing=1e-15, score=0.754, total=   0.0s\n",
            "[CV] var_smoothing=1e-15 .............................................\n",
            "[CV] ................. var_smoothing=1e-15, score=0.750, total=   0.0s\n",
            "[CV] var_smoothing=1e-15 .............................................\n",
            "[CV] ................. var_smoothing=1e-15, score=0.812, total=   0.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  55 out of  55 | elapsed:    2.6s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=GaussianNB(priors=None, var_smoothing=1e-09),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'var_smoothing': [1e-05, 1e-06, 1e-07, 1e-08, 1e-09,\n",
              "                                            1e-10, 1e-11, 1e-12, 1e-13, 1e-14,\n",
              "                                            1e-15]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwIo5atdlt6i",
        "outputId": "c5c40d3d-13dc-4b88-96f2-9c1b783a5932"
      },
      "source": [
        "grid_search_nb.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'var_smoothing': 1e-08}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZco-G3_lyVd",
        "outputId": "ec3c875a-514f-48f6-940c-ca6e61484506"
      },
      "source": [
        "grid_search_nb.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8038461538461539"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZ8QTxJdl2Js",
        "outputId": "8ef709e6-e3d7-454d-a50e-1b872459a552"
      },
      "source": [
        "y_pred_gnb = grid_search_nb.predict(X_test_transformed.toarray())\n",
        "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred_gnb)))\n",
        "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred_gnb)))\n",
        "print(\"f1 score: {:.2f}%\".format(100 * f1_score(y_test, y_pred_gnb)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 42.13%\n",
            "Recall: 95.19%\n",
            "f1 score: 58.41%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "jqghKo-JTBZO",
        "outputId": "873b2caf-c216-4a52-ecc5-f37a9a888f8c"
      },
      "source": [
        "plot_confusion_matrix(grid_search_nb, X_test_transformed.toarray(), y_test, cmap=plt.cm.Blues)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f5f9c99b950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVj5_hX2m78R"
      },
      "source": [
        "###2. Multinomial Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WczCbgRanFll",
        "outputId": "9ce2c586-cbb5-434d-92a7-3c21c53fa163"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "\n",
        "\n",
        "mnb_param_grid = [{\n",
        "    'alpha' : np.random.uniform(size=(10,)),\n",
        "    'fit_prior': [True, False],\n",
        "}]\n",
        "\n",
        "mnb_clf = MultinomialNB()\n",
        "grid_search_mnb = GridSearchCV(mnb_clf, param_grid=mnb_param_grid, cv=5, verbose=3)\n",
        "grid_search_mnb.fit(X_train_transformed.toarray(), y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "[CV] alpha=0.27589515353983063, fit_prior=True .......................\n",
            "[CV]  alpha=0.27589515353983063, fit_prior=True, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.27589515353983063, fit_prior=True .......................\n",
            "[CV]  alpha=0.27589515353983063, fit_prior=True, score=0.965, total=   0.1s\n",
            "[CV] alpha=0.27589515353983063, fit_prior=True .......................\n",
            "[CV]  alpha=0.27589515353983063, fit_prior=True, score=0.962, total=   0.0s\n",
            "[CV] alpha=0.27589515353983063, fit_prior=True .......................\n",
            "[CV]  alpha=0.27589515353983063, fit_prior=True, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.27589515353983063, fit_prior=True .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  alpha=0.27589515353983063, fit_prior=True, score=0.956, total=   0.0s\n",
            "[CV] alpha=0.27589515353983063, fit_prior=False ......................\n",
            "[CV]  alpha=0.27589515353983063, fit_prior=False, score=0.971, total=   0.0s\n",
            "[CV] alpha=0.27589515353983063, fit_prior=False ......................\n",
            "[CV]  alpha=0.27589515353983063, fit_prior=False, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.27589515353983063, fit_prior=False ......................\n",
            "[CV]  alpha=0.27589515353983063, fit_prior=False, score=0.956, total=   0.0s\n",
            "[CV] alpha=0.27589515353983063, fit_prior=False ......................\n",
            "[CV]  alpha=0.27589515353983063, fit_prior=False, score=0.963, total=   0.0s\n",
            "[CV] alpha=0.27589515353983063, fit_prior=False ......................\n",
            "[CV]  alpha=0.27589515353983063, fit_prior=False, score=0.960, total=   0.0s\n",
            "[CV] alpha=0.7130675212983979, fit_prior=True ........................\n",
            "[CV]  alpha=0.7130675212983979, fit_prior=True, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.7130675212983979, fit_prior=True ........................\n",
            "[CV]  alpha=0.7130675212983979, fit_prior=True, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.7130675212983979, fit_prior=True ........................\n",
            "[CV]  alpha=0.7130675212983979, fit_prior=True, score=0.962, total=   0.0s\n",
            "[CV] alpha=0.7130675212983979, fit_prior=True ........................\n",
            "[CV]  alpha=0.7130675212983979, fit_prior=True, score=0.963, total=   0.0s\n",
            "[CV] alpha=0.7130675212983979, fit_prior=True ........................\n",
            "[CV]  alpha=0.7130675212983979, fit_prior=True, score=0.956, total=   0.0s\n",
            "[CV] alpha=0.7130675212983979, fit_prior=False .......................\n",
            "[CV]  alpha=0.7130675212983979, fit_prior=False, score=0.971, total=   0.1s\n",
            "[CV] alpha=0.7130675212983979, fit_prior=False .......................\n",
            "[CV]  alpha=0.7130675212983979, fit_prior=False, score=0.969, total=   0.0s\n",
            "[CV] alpha=0.7130675212983979, fit_prior=False .......................\n",
            "[CV]  alpha=0.7130675212983979, fit_prior=False, score=0.956, total=   0.0s\n",
            "[CV] alpha=0.7130675212983979, fit_prior=False .......................\n",
            "[CV]  alpha=0.7130675212983979, fit_prior=False, score=0.963, total=   0.0s\n",
            "[CV] alpha=0.7130675212983979, fit_prior=False .......................\n",
            "[CV]  alpha=0.7130675212983979, fit_prior=False, score=0.960, total=   0.0s\n",
            "[CV] alpha=0.45386414479471304, fit_prior=True .......................\n",
            "[CV]  alpha=0.45386414479471304, fit_prior=True, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.45386414479471304, fit_prior=True .......................\n",
            "[CV]  alpha=0.45386414479471304, fit_prior=True, score=0.969, total=   0.0s\n",
            "[CV] alpha=0.45386414479471304, fit_prior=True .......................\n",
            "[CV]  alpha=0.45386414479471304, fit_prior=True, score=0.962, total=   0.0s\n",
            "[CV] alpha=0.45386414479471304, fit_prior=True .......................\n",
            "[CV]  alpha=0.45386414479471304, fit_prior=True, score=0.963, total=   0.1s\n",
            "[CV] alpha=0.45386414479471304, fit_prior=True .......................\n",
            "[CV]  alpha=0.45386414479471304, fit_prior=True, score=0.956, total=   0.0s\n",
            "[CV] alpha=0.45386414479471304, fit_prior=False ......................\n",
            "[CV]  alpha=0.45386414479471304, fit_prior=False, score=0.971, total=   0.0s\n",
            "[CV] alpha=0.45386414479471304, fit_prior=False ......................\n",
            "[CV]  alpha=0.45386414479471304, fit_prior=False, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.45386414479471304, fit_prior=False ......................\n",
            "[CV]  alpha=0.45386414479471304, fit_prior=False, score=0.956, total=   0.0s\n",
            "[CV] alpha=0.45386414479471304, fit_prior=False ......................\n",
            "[CV]  alpha=0.45386414479471304, fit_prior=False, score=0.963, total=   0.0s\n",
            "[CV] alpha=0.45386414479471304, fit_prior=False ......................\n",
            "[CV]  alpha=0.45386414479471304, fit_prior=False, score=0.960, total=   0.0s\n",
            "[CV] alpha=0.6380050714427364, fit_prior=True ........................\n",
            "[CV]  alpha=0.6380050714427364, fit_prior=True, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.6380050714427364, fit_prior=True ........................\n",
            "[CV]  alpha=0.6380050714427364, fit_prior=True, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.6380050714427364, fit_prior=True ........................\n",
            "[CV]  alpha=0.6380050714427364, fit_prior=True, score=0.962, total=   0.0s\n",
            "[CV] alpha=0.6380050714427364, fit_prior=True ........................\n",
            "[CV]  alpha=0.6380050714427364, fit_prior=True, score=0.963, total=   0.0s\n",
            "[CV] alpha=0.6380050714427364, fit_prior=True ........................\n",
            "[CV]  alpha=0.6380050714427364, fit_prior=True, score=0.956, total=   0.0s\n",
            "[CV] alpha=0.6380050714427364, fit_prior=False .......................\n",
            "[CV]  alpha=0.6380050714427364, fit_prior=False, score=0.971, total=   0.1s\n",
            "[CV] alpha=0.6380050714427364, fit_prior=False .......................\n",
            "[CV]  alpha=0.6380050714427364, fit_prior=False, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.6380050714427364, fit_prior=False .......................\n",
            "[CV]  alpha=0.6380050714427364, fit_prior=False, score=0.956, total=   0.0s\n",
            "[CV] alpha=0.6380050714427364, fit_prior=False .......................\n",
            "[CV]  alpha=0.6380050714427364, fit_prior=False, score=0.963, total=   0.0s\n",
            "[CV] alpha=0.6380050714427364, fit_prior=False .......................\n",
            "[CV]  alpha=0.6380050714427364, fit_prior=False, score=0.960, total=   0.0s\n",
            "[CV] alpha=0.9784994035236168, fit_prior=True ........................\n",
            "[CV]  alpha=0.9784994035236168, fit_prior=True, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.9784994035236168, fit_prior=True ........................\n",
            "[CV]  alpha=0.9784994035236168, fit_prior=True, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.9784994035236168, fit_prior=True ........................\n",
            "[CV]  alpha=0.9784994035236168, fit_prior=True, score=0.962, total=   0.0s\n",
            "[CV] alpha=0.9784994035236168, fit_prior=True ........................\n",
            "[CV]  alpha=0.9784994035236168, fit_prior=True, score=0.965, total=   0.0s\n",
            "[CV] alpha=0.9784994035236168, fit_prior=True ........................\n",
            "[CV]  alpha=0.9784994035236168, fit_prior=True, score=0.956, total=   0.0s\n",
            "[CV] alpha=0.9784994035236168, fit_prior=False .......................\n",
            "[CV]  alpha=0.9784994035236168, fit_prior=False, score=0.971, total=   0.0s\n",
            "[CV] alpha=0.9784994035236168, fit_prior=False .......................\n",
            "[CV]  alpha=0.9784994035236168, fit_prior=False, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.9784994035236168, fit_prior=False .......................\n",
            "[CV]  alpha=0.9784994035236168, fit_prior=False, score=0.956, total=   0.0s\n",
            "[CV] alpha=0.9784994035236168, fit_prior=False .......................\n",
            "[CV]  alpha=0.9784994035236168, fit_prior=False, score=0.963, total=   0.0s\n",
            "[CV] alpha=0.9784994035236168, fit_prior=False .......................\n",
            "[CV]  alpha=0.9784994035236168, fit_prior=False, score=0.958, total=   0.0s\n",
            "[CV] alpha=0.342706553511956, fit_prior=True .........................\n",
            "[CV]  alpha=0.342706553511956, fit_prior=True, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.342706553511956, fit_prior=True .........................\n",
            "[CV]  alpha=0.342706553511956, fit_prior=True, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.342706553511956, fit_prior=True .........................\n",
            "[CV]  alpha=0.342706553511956, fit_prior=True, score=0.962, total=   0.0s\n",
            "[CV] alpha=0.342706553511956, fit_prior=True .........................\n",
            "[CV]  alpha=0.342706553511956, fit_prior=True, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.342706553511956, fit_prior=True .........................\n",
            "[CV]  alpha=0.342706553511956, fit_prior=True, score=0.956, total=   0.0s\n",
            "[CV] alpha=0.342706553511956, fit_prior=False ........................\n",
            "[CV]  alpha=0.342706553511956, fit_prior=False, score=0.971, total=   0.1s\n",
            "[CV] alpha=0.342706553511956, fit_prior=False ........................\n",
            "[CV]  alpha=0.342706553511956, fit_prior=False, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.342706553511956, fit_prior=False ........................\n",
            "[CV]  alpha=0.342706553511956, fit_prior=False, score=0.956, total=   0.0s\n",
            "[CV] alpha=0.342706553511956, fit_prior=False ........................\n",
            "[CV]  alpha=0.342706553511956, fit_prior=False, score=0.963, total=   0.0s\n",
            "[CV] alpha=0.342706553511956, fit_prior=False ........................\n",
            "[CV]  alpha=0.342706553511956, fit_prior=False, score=0.960, total=   0.0s\n",
            "[CV] alpha=0.03435042418656198, fit_prior=True .......................\n",
            "[CV]  alpha=0.03435042418656198, fit_prior=True, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.03435042418656198, fit_prior=True .......................\n",
            "[CV]  alpha=0.03435042418656198, fit_prior=True, score=0.963, total=   0.0s\n",
            "[CV] alpha=0.03435042418656198, fit_prior=True .......................\n",
            "[CV]  alpha=0.03435042418656198, fit_prior=True, score=0.963, total=   0.0s\n",
            "[CV] alpha=0.03435042418656198, fit_prior=True .......................\n",
            "[CV]  alpha=0.03435042418656198, fit_prior=True, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.03435042418656198, fit_prior=True .......................\n",
            "[CV]  alpha=0.03435042418656198, fit_prior=True, score=0.958, total=   0.1s\n",
            "[CV] alpha=0.03435042418656198, fit_prior=False ......................\n",
            "[CV]  alpha=0.03435042418656198, fit_prior=False, score=0.971, total=   0.0s\n",
            "[CV] alpha=0.03435042418656198, fit_prior=False ......................\n",
            "[CV]  alpha=0.03435042418656198, fit_prior=False, score=0.965, total=   0.0s\n",
            "[CV] alpha=0.03435042418656198, fit_prior=False ......................\n",
            "[CV]  alpha=0.03435042418656198, fit_prior=False, score=0.958, total=   0.0s\n",
            "[CV] alpha=0.03435042418656198, fit_prior=False ......................\n",
            "[CV]  alpha=0.03435042418656198, fit_prior=False, score=0.965, total=   0.0s\n",
            "[CV] alpha=0.03435042418656198, fit_prior=False ......................\n",
            "[CV]  alpha=0.03435042418656198, fit_prior=False, score=0.962, total=   0.0s\n",
            "[CV] alpha=0.07773946210594596, fit_prior=True .......................\n",
            "[CV]  alpha=0.07773946210594596, fit_prior=True, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.07773946210594596, fit_prior=True .......................\n",
            "[CV]  alpha=0.07773946210594596, fit_prior=True, score=0.965, total=   0.1s\n",
            "[CV] alpha=0.07773946210594596, fit_prior=True .......................\n",
            "[CV]  alpha=0.07773946210594596, fit_prior=True, score=0.963, total=   0.0s\n",
            "[CV] alpha=0.07773946210594596, fit_prior=True .......................\n",
            "[CV]  alpha=0.07773946210594596, fit_prior=True, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.07773946210594596, fit_prior=True .......................\n",
            "[CV]  alpha=0.07773946210594596, fit_prior=True, score=0.958, total=   0.0s\n",
            "[CV] alpha=0.07773946210594596, fit_prior=False ......................\n",
            "[CV]  alpha=0.07773946210594596, fit_prior=False, score=0.971, total=   0.1s\n",
            "[CV] alpha=0.07773946210594596, fit_prior=False ......................\n",
            "[CV]  alpha=0.07773946210594596, fit_prior=False, score=0.965, total=   0.1s\n",
            "[CV] alpha=0.07773946210594596, fit_prior=False ......................\n",
            "[CV]  alpha=0.07773946210594596, fit_prior=False, score=0.956, total=   0.1s\n",
            "[CV] alpha=0.07773946210594596, fit_prior=False ......................\n",
            "[CV]  alpha=0.07773946210594596, fit_prior=False, score=0.965, total=   0.0s\n",
            "[CV] alpha=0.07773946210594596, fit_prior=False ......................\n",
            "[CV]  alpha=0.07773946210594596, fit_prior=False, score=0.962, total=   0.0s\n",
            "[CV] alpha=0.958369135322628, fit_prior=True .........................\n",
            "[CV]  alpha=0.958369135322628, fit_prior=True, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.958369135322628, fit_prior=True .........................\n",
            "[CV]  alpha=0.958369135322628, fit_prior=True, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.958369135322628, fit_prior=True .........................\n",
            "[CV]  alpha=0.958369135322628, fit_prior=True, score=0.962, total=   0.0s\n",
            "[CV] alpha=0.958369135322628, fit_prior=True .........................\n",
            "[CV]  alpha=0.958369135322628, fit_prior=True, score=0.965, total=   0.0s\n",
            "[CV] alpha=0.958369135322628, fit_prior=True .........................\n",
            "[CV]  alpha=0.958369135322628, fit_prior=True, score=0.956, total=   0.0s\n",
            "[CV] alpha=0.958369135322628, fit_prior=False ........................\n",
            "[CV]  alpha=0.958369135322628, fit_prior=False, score=0.971, total=   0.0s\n",
            "[CV] alpha=0.958369135322628, fit_prior=False ........................\n",
            "[CV]  alpha=0.958369135322628, fit_prior=False, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.958369135322628, fit_prior=False ........................\n",
            "[CV]  alpha=0.958369135322628, fit_prior=False, score=0.956, total=   0.0s\n",
            "[CV] alpha=0.958369135322628, fit_prior=False ........................\n",
            "[CV]  alpha=0.958369135322628, fit_prior=False, score=0.963, total=   0.0s\n",
            "[CV] alpha=0.958369135322628, fit_prior=False ........................\n",
            "[CV]  alpha=0.958369135322628, fit_prior=False, score=0.958, total=   0.0s\n",
            "[CV] alpha=0.8894976694730933, fit_prior=True ........................\n",
            "[CV]  alpha=0.8894976694730933, fit_prior=True, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.8894976694730933, fit_prior=True ........................\n",
            "[CV]  alpha=0.8894976694730933, fit_prior=True, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.8894976694730933, fit_prior=True ........................\n",
            "[CV]  alpha=0.8894976694730933, fit_prior=True, score=0.962, total=   0.0s\n",
            "[CV] alpha=0.8894976694730933, fit_prior=True ........................\n",
            "[CV]  alpha=0.8894976694730933, fit_prior=True, score=0.965, total=   0.0s\n",
            "[CV] alpha=0.8894976694730933, fit_prior=True ........................\n",
            "[CV]  alpha=0.8894976694730933, fit_prior=True, score=0.956, total=   0.1s\n",
            "[CV] alpha=0.8894976694730933, fit_prior=False .......................\n",
            "[CV]  alpha=0.8894976694730933, fit_prior=False, score=0.971, total=   0.0s\n",
            "[CV] alpha=0.8894976694730933, fit_prior=False .......................\n",
            "[CV]  alpha=0.8894976694730933, fit_prior=False, score=0.967, total=   0.1s\n",
            "[CV] alpha=0.8894976694730933, fit_prior=False .......................\n",
            "[CV]  alpha=0.8894976694730933, fit_prior=False, score=0.956, total=   0.1s\n",
            "[CV] alpha=0.8894976694730933, fit_prior=False .......................\n",
            "[CV]  alpha=0.8894976694730933, fit_prior=False, score=0.963, total=   0.0s\n",
            "[CV] alpha=0.8894976694730933, fit_prior=False .......................\n",
            "[CV]  alpha=0.8894976694730933, fit_prior=False, score=0.958, total=   0.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    5.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=MultinomialNB(alpha=1.0, class_prior=None,\n",
              "                                     fit_prior=True),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'alpha': array([0.27589515, 0.71306752, 0.45386414, 0.63800507, 0.9784994 ,\n",
              "       0.34270655, 0.03435042, 0.07773946, 0.95836914, 0.88949767]),\n",
              "                          'fit_prior': [True, False]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDF44XDrolHX",
        "outputId": "ca16071c-5f67-417a-aee2-d1a1ec98d002"
      },
      "source": [
        "grid_search_mnb.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.03435042418656198, 'fit_prior': False}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kOpZsC2osx7",
        "outputId": "2910541c-7886-4c32-fcf6-ffa5ff9418c6"
      },
      "source": [
        "grid_search_mnb.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9642307692307692"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PmPUGkFowPZ",
        "outputId": "616d9554-eba9-4ef0-9c7b-a126ce374b4f"
      },
      "source": [
        "y_pred_mnb = grid_search_mnb.predict(X_test_transformed.toarray())\n",
        "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred_mnb)))\n",
        "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred_mnb)))\n",
        "print(\"f1 score: {:.2f}%\".format(100 * f1_score(y_test, y_pred_mnb)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 90.10%\n",
            "Recall: 87.50%\n",
            "f1 score: 88.78%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "VQOhV50oo7WF",
        "outputId": "41e55035-07e6-46ef-9441-1994de8abc1a"
      },
      "source": [
        "plot_confusion_matrix(grid_search_mnb, X_test_transformed.toarray(), y_test, cmap=plt.cm.Blues)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f5f9c670f50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAEGCAYAAADxD4m3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZ7UlEQVR4nO3debQU5Z3/8ffngiIoKMgiCriMREWNSoioJAbxZwJqgmZijFs4SiTGJY6JM4OJCcbRxMTMYNzHiApxX0d0EHFQg7gCLoiiI66gKLKI4pIM+v390XWxWe69VdJNdxWfl6fO7X66uup7L8fPeZ5anlJEYGZWRA21LsDMrFoccGZWWA44MyssB5yZFZYDzswKq3WtCyin1m1DG7avdRmWwR479ap1CZbB66+/xsKFC7U222jVYeuI5R+nWjc+fvfeiBi8NvtbG/UVcBu2p80O3691GZbBw49fXOsSLIMB/fut9TZi+cep/z/95OlLOq/1DtdCXQWcmeWBQPk4uuWAM7NsBDS0qnUVqTjgzCw7rdVhvHXGAWdmGXmIamZF5h6cmRWScA/OzIpK7sGZWYH5LKqZFZNPMphZUYncDFHzEcNmVl/UkG5paTPSa5KelfS0pOlJWydJ90l6KfnZMWmXpAslzZE0U1LflrbvgDOzjFSxgEvsFxG7R0TjjbIjgckR0RuYnLwHGAL0TpYRwGUtbdgBZ2bZCGjVKt3yxQwFxiavxwKHlLWPi5LHgM0kdW9uQw44M8tOSrdAZ0nTy5YRq2wpgEmSZpR91i0i5iev3wa6Ja+3AuaWfXde0tYkn2Qws4wynUVdWDb0XJOvRcSbkroC90l6ofzDiAhJX/jRf+7BmVl26XtwzYqIN5OfC4A7gD2BdxqHnsnPBcnqbwI9y77eI2lrkgPOzLKrwEkGSRtLat/4GvgmMAsYDwxLVhsG3Jm8Hg/8MDmbuhewtGwou0YeoppZNil7Zyl0A+5QaVutgesjYqKkacDNkoYDrwON0wdPAA4E5gAfAce2tAMHnJllV4FbtSLiFWC3NbQvAvZfQ3sAJ2XZhwPOzDLyrVpmVmQ5uVXLAWdm2Xg+ODMrLg9RzazIPB+cmRWWj8GZWSHJQ1QzKzL34MysqOSAM7MiKs1Y7oAzsyKSUIMDzswKyj04MyssB5yZFZYDzsyKScmSAw44M8tEyD04MyuuhgbfyWBmBeUenJkVk4/BmVmRuQdnZoXkkwxmVmi+VcvMikkeoppZgTngzKywHHBmVkg+yWBmxZaPfHPAmVlG8q1aZlZgHqKaWXHlI98ccGvyzJ2/YdlHf+PTzz5j+fLPGDTsD2tcb48+vZg05ucM/+XVjL//6bXa52Yd2nHVb4+jV/dOvDF/MceeMYalH3zMYYP7ceoPD0ASyz76hJ+fdxOzXnpzrfZlnzv57Gu5d+osOndsz6M3/RKAJUs/5LhfXMUb8xfTq3snrv7dcDbr0K7GldaXvPTgqjqQljRY0ouS5kgaWc19Vdq3T/gT+x51XpPh1tAgzjp5KA88/kKm7Q7o25tLRh29Wvtpww5gyrQX6fePZzNl2oucNuybALz+1iIO+vEFDDjit5w/ZiKjf3FE9l/GmnTEwXtx64UnrdQ2eux97PvVHZhx+yj2/eoOjB47qUbV1SdJqZdaq1rASWoFXAIMAfoAR0jqU639rWsjDv8Gdz3wDO8u+WCl9lOO3p/JY/+ZqdefwcgRB6be3pBvfJkb7n4cgBvufpwDB34ZgCdmvsrSDz4GYNqzr7Jl180q9BsYwIC+29Nxld7ZPX+dyREH9wfgiIP7M+HBmbUora5VMuAktZL0lKS7k/fbSno86RjdJGnDpL1N8n5O8vk2LW27mj24PYE5EfFKRPwduBEYWsX9VUxEcPvFJ/PAuH9h2KEDVvu8e5dNOXjgboy59aGV2vfrvyPb9erK/sPO5+tHncfuO/Zinz3+IdU+u3ZqzzuL3gfgnUXv07VT+9XWOWboPvzPI89/gd/Isliw+AO26LwpAN0278CCxR+08I31jxqUaknpVGB22fvfA6MjYntgCTA8aR8OLEnaRyfrNauax+C2AuaWvZ8H9F91JUkjgBEAbLBJFctJb8jxo5n/7lI6d9yEOy4+mZdee5tHnnp5xee//dk/ctZFdxIRK31vv712YlD/HZlyXWk0vnHbNmzXsyuPPPUy9119Om02bM3GbdvQsUO7FeucddGd3P/YbFa1yqb52ld6c/R39mbI8aMr/Ntac0o9kVpXUX8qNfyU1AM4CDgX+JlKGx4EHJmsMhY4C7iMUgfprKT9VuBiSYpV/0csU/OTDBFxBXAFQEO7rk0Wui7Nf3cpAAuXLOPuB2fSd+dtVgq4PXbqxZhzjwWg02abcMA+O7P808+QYPQ1k7jmjodX2+YBx/4RKB2DO/Lb/TnpN9eu9PmCxR/QbfMOvLPofbpt3mGloe/O22/JhWceyWGnXsaSpR9W/Pe1lXXt1J63Fy5li86b8vbCpXTpuHpver1W2ZvtLwD+BWj8I28OvBcRy5P38yh1lqCs0xQRyyUtTdZf2NTGqzlEfRPoWfa+R9JW19pttCGbtGuz4vWgvXZk9stvrbTO7oecxW5DR7Hb0FGMv/8pTv/9TUz460zuf3Q2R31nbzZuuyFQGsp27piuVzpxyrMrHfe556+l4z49unVk3B+O54RR43j5jQWV+jWtGYP33XWl46FDvvHlGldUXwRI6Rags6TpZcuIFduRDgYWRMSMatVazR7cNKC3pG0pBdsP+LzbWbe6bN6ea/9wPACtWrfitonTmfzobI797tcAuPr2qU1+94HHX+BL227BpKtOB2DZR3/jx78ey8Ily1rc7+ix93H1747j6O/szdy3F3PsGVcB8M8/GkKnTTfmj/96OECzl61YdsN/eTUPz3iJRe8tY+eDzmTkiAM5bdgBHHvGVVw7/lF6btGJq393XK3LrDOZzpAujIh+TXw2APiOpAOBjYAOwJ+AzSS1Tnpx5R2jxk7TPEmtgU2BRc1W2szwda0lhV8AtAKuiohzm1u/oV3XaLPD96tWj1XekmkX17oEy2BA/37MmDF9rcaXG23xpdh62EWp1v3fPwye0UzArSBpIHB6RBws6Rbgtoi4UdLlwMyIuFTSScCuEXGCpB8A342IZgOjqsfgImICMKGa+zCzdezz4We1/Ctwo6RzgKeAMUn7GOAvkuYAiymNCptV85MMZpYvonSheyVFxIPAg8nrVyhdZrbqOp8Ah2XZrgPOzDLLy6UzDjgzy6websNKwwFnZtlU/xhcxTjgzCwTIU94aWbF5R6cmRWWj8GZWTH5GJyZFVXpXtR8JJwDzswyy0m+OeDMLLtK38lQLQ44M8umsvPBVZUDzswyaZwPLg8ccGaWUX08MSsNB5yZZZaTfHPAmVlG8kkGMysoXwdnZoXmgDOzwspJvjngzCw79+DMrJh8s72ZFVVpwst8JJwDzswya8hJF84BZ2aZ5STfHHBmlo18s72ZFVlODsE1HXCSLgKiqc8j4qdVqcjM6l4RTjJMX2dVmFluiNKZ1DxoMuAiYmz5e0ntIuKj6pdkZvUuJx04Wnx6q6S9JT0PvJC8303SpVWvzMzqk0rzwaVZai3N46kvAL4FLAKIiGeAfatZlJnVNyndUmupzqJGxNxV0vjT6pRjZvVOFOtC37mS9gFC0gbAqcDs6pZlZvUsL2dR0wxRTwBOArYC3gJ2T96b2Xoo7fC0Hjp5LfbgImIhcNQ6qMXMcqISQ1RJGwFTgDaUsujWiBglaVvgRmBzYAZwTET8XVIbYBzwFUrnBA6PiNearTNFEdtJukvSu5IWSLpT0nZr9ZuZWa4p5dKCvwGDImI3SiPDwZL2An4PjI6I7YElwPBk/eHAkqR9dLJes9IMUa8Hbga6A1sCtwA3pPiemRVUJS4TiZJlydsNkiWAQcCtSftY4JDk9dDkPcnn+6uFnaQJuHYR8ZeIWJ4s1wIbpfiemRVQ6SxqugXoLGl62TJipW1JrSQ9DSwA7gNeBt6LiOXJKvMoHf8n+TkXIPl8KaVhbJOauxe1U/LyHkkjKY2JAzgcmJDyb2FmRaNME14ujIh+TX0YEZ8Cu0vaDLgD2LECFa7Q3EmGGZQCrfE3+XF5XcAZlSzEzPKj0ncpRMR7kh4A9gY2k9Q66aX1AN5MVnsT6AnMk9Qa2JTkBoSmNHcv6rYVqdzMCqVxiLrW25G6AP+XhFtb4ABKJw4eAL5HadQ4DLgz+cr45P2jyef3R0STMx5ByjsZJO0C9KHs2FtEjMv025hZYVSoB9cdGCupFaXzATdHxN3Jve83SjoHeAoYk6w/BviLpDnAYuAHLe2gxYCTNAoYSCngJgBDgKmUrkcxs/VQJeItImYCe6yh/RVgzzW0fwIclmUfac6ifg/YH3g7Io4FdqM09jWz9ZAErRqUaqm1NEPUjyPiM0nLJXWgdDq3Z5XrMrM6Vg9TIaWRJuCmJ6dw/0zpzOoySgf5zGw9lZN8S3Uv6onJy8slTQQ6JGNnM1sPCeV/uiRJfZv7LCKerE5JZlbX6mSmkDSa68H9ezOfNd4vVlG779SLhx+7qNKbtSp6faEf05Enf1v+WUW2k/tjcBGx37osxMzyQUCrvAecmVlT6uAKkFQccGaWmQPOzAqpNB15PhIuzYy+knS0pF8n73tJWu02CjNbf2SYD662daZY51JKU5gckbz/ALikahWZWd0rzENngP4R0VfSUwARsUTShlWuy8zqlIDW9ZBeKaQJuP9LpjMJWDGHU2UupjGzXMpJvqUKuAspTSXcVdK5lGYXObOqVZlZ3ZIKcKtWo4i4TtIMSlMmCTgkIvxke7P1WE7yLdWEl72Aj4C7ytsi4o1qFmZm9asezpCmkWaI+t98/vCZjYBtgReBnatYl5nVKUFdTGaZRpoh6q7l75NZRk5sYnUzK7o6ucYtjcx3MkTEk5L6V6MYM8sHVeSpDNWX5hjcz8reNgB9gbeqVpGZ1bVKPTZwXUjTg2tf9no5pWNyt1WnHDPLg0IEXHKBb/uIOH0d1WNmOZCXm+2bm7K8dUQslzRgXRZkZvWt9NjAWleRTnM9uCcoHW97WtJ44Bbgw8YPI+L2KtdmZnWqMHcyULr2bRGlZzA0Xg8XgAPObD1UlJMMXZMzqLP4PNgaRVWrMrO6lpMOXLMB1wrYBNZ4wYsDzmy9JRoKcB3c/Ig4e51VYma5IIrRg8vJr2Bm65SgdU4OwjUXcPuvsyrMLDcK0YOLiMXrshAzy4+8XCaSk8v1zKyeVOKhM5J6SnpA0vOSnpN0atLeSdJ9kl5KfnZM2iXpQklzJM1MZjZqlgPOzDIRpeBIs7RgOfDziOgD7AWcJKkPMBKYHBG9gcnJe4AhQO9kGQFc1tIOHHBmlo1KQ9Q0S3MiYn5EPJm8/gCYDWwFDAXGJquNBQ5JXg8FxkXJY8Bmkro3tw8/2d7MMindyZD6GFxnSdPL3l8REVestk1pG2AP4HGgW0TMTz56G+iWvN4KmFv2tXlJ23ya4IAzs8wynGJYGBH9mt2WtAmlKdj+KSLeL5+pJCJC0he+scBDVDPLrFJPtpe0AaVwu65sAo93Goeeyc8FSfubQM+yr/dI2prkgDOzjISUbml2K6UVxgCzI+I/yj4aDwxLXg8D7ixr/2FyNnUvYGnZUHaNPEQ1s0waz6JWwADgGOBZSU8nbb8AzgNuljQceB34fvLZBOBAYA6lR5ke29IOHHBmllklLvSNiKk0fThvtTupIiKAk7LswwFnZtmoAFOWm5mtSQWHqFXngDOzzNyDM7PCyke8OeDMLCMBrdyDM7Oiykm+OeDMLCuhnAxSHXBmlpl7cGZWSKXLRPKRcA44M8sm5Y309cABZ2aZ5eWZDA44M8ukNOFlratIxwFnZpn5LKqZFVZORqgOuEo7+d+uY9LUWXTu2J5HbvwFAOdefjf3THmWBonOndpzya+PpnuXTWtcqTW67r+mcvvEx4mA7w7ek6MP/TqTHprJ5dfex6tzF3DtBSez85d6tryh9UheenBVmxRA0lWSFkiaVa191KMjD+rPLX86caW2U47en6nXn8GU60byra/tzPlX3lOj6mxVc157m9snPs61F5zCzZf+Ew89MZs33lrI9lt34z9+dQx9d9m21iXWncZjcGmWWqvmrCfXAIOruP26tE/f7enYod1KbR02abvi9Ucf/z03MzGsD16Zu4Bdd+hF2402pHWrVnxl1+2Y/PAstuvVjW16dK11efUp5SMD6+FMa9WGqBExJXkUmAHnXHoXN054gg6btGX8ZafUuhxLbL91Ny4eO5H33v+QNhtuwNRpL9Cnd49al1X3ah9d6dR83jpJIyRNlzR94cJ3a11O1Zx54reZdfe/cdjgfvz5lim1LscS2/XqxrGHDeQnv7ySk341hh2225KGhpr/b1HXGp+LmoceXM3/JSPiiojoFxH9OnfuUutyqu6wwf246/5nal2GlTn0W3tyw0WnctX5P6F9+7Zs3aNzrUuqe0q51FrNA2598PIbC1a8nvDXZ+m9Tbdm1rZ1bfF7ywCYv2AJ9z88iyED96hxRTmQk4TzZSIV9qMzr+bhGXNY9N4ydj74V4w8/kDue+Q55ry+gIYG0XOLTvz7yMNrXaaV+fk541j6/ke0bt2KM048hA6btOX+h2dx3mV3smTpMk4ZdTU7bLcll537o1qXWjfqYfiZRtUCTtINwECgs6R5wKiIGFOt/dWLK89Z/VGNxwzduwaVWFpX//HE1doGDdiFQQN2qUE1+ZCPeKvuWdQjqrVtM6uxnCSch6hmlknp8Fo+Es4BZ2bZeD44MyuynOSbA87MslJubjd0wJlZZjnJNwecmWVTJ9fwpuKAM7PscpJwDjgzyywvl4n4XlQzy0xKt7S8ndUnxpXUSdJ9kl5KfnZM2iXpQklzJM2U1Lel7TvgzCyblOGW8kTENaw+Me5IYHJE9AYmJ+8BhgC9k2UEcFlLG3fAmVlmSvlfSyJiCrB4leahwNjk9VjgkLL2cVHyGLCZpO7Nbd8BZ2aZiIr24NakW0TMT16/DTTOL7YVMLdsvXlJW5N8ksHMMsuQXZ0lTS97f0VEXJH2yxERkiJDaStxwJlZdukTbmFE9Mu49XckdY+I+ckQtHHG2DeB8uc39kjamuQhqpllVuVnMowHhiWvhwF3lrX/MDmbuhewtGwou0buwZlZZpW6Cm5NE+MC5wE3SxoOvA58P1l9AnAgMAf4CFh9dtlVOODMLLsKJVwzE+Puv4Z1Azgpy/YdcGaWiSe8NLPi8oSXZlZkOck3B5yZZeUJL82swHKSbw44M8vGE16aWbHlJOEccGaWmS8TMbPC8jE4MysmQYMDzsyKKx8J54Azs0waJ7zMAwecmWWWk3xzwJlZdu7BmVlh+VYtMyusfMSbA87MMlrLJ2atUw44M8vMdzKYWXHlI98ccGaWXU7yzQFnZlmt1SMB1ykHnJllkqc7GfzgZzMrLPfgzCyzvPTgHHBmlpkvEzGzYvKFvmZWVHk6yeCAM7PMPEQ1s8JyD87MCisn+eaAM7MvICcJ54Azs0wEublVSxFR6xpWkPQu8Hqt66iCzsDCWhdhmRT132zriOiyNhuQNJHS3yeNhRExeG32tzbqKuCKStL0iOhX6zosPf+bFYPvRTWzwnLAmVlhOeDWjStqXYBl5n+zAvAxODMrLPfgzKywHHBmVlgOuCqSNFjSi5LmSBpZ63qsZZKukrRA0qxa12JrzwFXJZJaAZcAQ4A+wBGS+tS2KkvhGqBmF6ZaZTngqmdPYE5EvBIRfwduBIbWuCZrQURMARbXug6rDAdc9WwFzC17Py9pM7N1xAFnZoXlgKueN4GeZe97JG1mto444KpnGtBb0raSNgR+AIyvcU1m6xUHXJVExHLgZOBeYDZwc0Q8V9uqrCWSbgAeBXaQNE/S8FrXZF+cb9Uys8JyD87MCssBZ2aF5YAzs8JywJlZYTngzKywHHA5IulTSU9LmiXpFknt1mJb10j6XvL6yuYmApA0UNI+X2Afr0la7elLTbWvss6yjPs6S9LpWWu0YnPA5cvHEbF7ROwC/B04ofxDSV/oObcR8aOIeL6ZVQYCmQPOrNYccPn1ELB90rt6SNJ44HlJrSSdL2mapJmSfgygkouT+en+B+jauCFJD0rql7weLOlJSc9ImixpG0pBelrSe/y6pC6Sbkv2MU3SgOS7m0uaJOk5SVeS4vnnkv5L0ozkOyNW+Wx00j5ZUpek7R8kTUy+85CkHSvxx7Ri8pPtcyjpqQ0BJiZNfYFdIuLVJCSWRsRXJbUBHpY0CdgD2IHS3HTdgOeBq1bZbhfgz8C+ybY6RcRiSZcDyyLij8l61wOjI2KqpF6U7tbYCRgFTI2IsyUdBKS5C+C4ZB9tgWmSbouIRcDGwPSIOE3Sr5Ntn0zpYTAnRMRLkvoDlwKDvsCf0dYDDrh8aSvp6eT1Q8AYSkPHJyLi1aT9m8CXG4+vAZsCvYF9gRsi4lPgLUn3r2H7ewFTGrcVEU3Ni/b/gD7Sig5aB0mbJPv4bvLd/5a0JMXv9FNJhyaveya1LgI+A25K2q8Fbk/2sQ9wS9m+26TYh62nHHD58nFE7F7ekPyP/mF5E3BKRNy7ynoHVrCOBmCviPhkDbWkJmkgpbDcOyI+kvQgsFETq0ey3/dW/RuYNcXH4IrnXuAnkjYAkPQlSRsDU4DDk2N03YH91vDdx4B9JW2bfLdT0v4B0L5svUnAKY1vJDUGzhTgyKRtCNCxhVo3BZYk4bYjpR5kowagsRd6JKWh7/vAq5IOS/YhSbu1sA9bjzngiudKSsfXnkwenPKflHrqdwAvJZ+NozRjxkoi4l1gBKXh4DN8PkS8Czi08SQD8FOgX3IS43k+P5v7G0oB+RyloeobLdQ6EWgtaTZwHqWAbfQhsGfyOwwCzk7ajwKGJ/U9h6eBt2Z4NhEzKyz34MyssBxwZlZYDjgzKywHnJkVlgPOzArLAWdmheWAM7PC+v/PXlepQkau2AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cpzOGLPxlC5"
      },
      "source": [
        "####3. Complement Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u98tKj5SpC-X",
        "outputId": "2418c799-e72d-4207-9607-673915fe3212"
      },
      "source": [
        "from sklearn.naive_bayes import ComplementNB\n",
        "\n",
        "cnb_param_grid = {\n",
        "    'alpha' : np.random.uniform(size=(10,)),\n",
        "    'fit_prior': [True, False],\n",
        "    'norm': [True, False],\n",
        "}\n",
        "\n",
        "cnb_clf = ComplementNB()\n",
        "grid_search_cnb = GridSearchCV(cnb_clf, cnb_param_grid, cv=5, verbose=3)\n",
        "grid_search_cnb.fit(X_train_transformed.toarray(), y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
            "[CV] alpha=0.0996628228988693, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.0996628228988693, fit_prior=True, norm=True, score=0.562, total=   0.0s\n",
            "[CV] alpha=0.0996628228988693, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.0996628228988693, fit_prior=True, norm=True, score=0.621, total=   0.0s\n",
            "[CV] alpha=0.0996628228988693, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.0996628228988693, fit_prior=True, norm=True, score=0.550, total=   0.1s\n",
            "[CV] alpha=0.0996628228988693, fit_prior=True, norm=True .............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  alpha=0.0996628228988693, fit_prior=True, norm=True, score=0.625, total=   0.1s\n",
            "[CV] alpha=0.0996628228988693, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.0996628228988693, fit_prior=True, norm=True, score=0.621, total=   0.0s\n",
            "[CV] alpha=0.0996628228988693, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.0996628228988693, fit_prior=True, norm=False, score=0.971, total=   0.0s\n",
            "[CV] alpha=0.0996628228988693, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.0996628228988693, fit_prior=True, norm=False, score=0.963, total=   0.0s\n",
            "[CV] alpha=0.0996628228988693, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.0996628228988693, fit_prior=True, norm=False, score=0.956, total=   0.1s\n",
            "[CV] alpha=0.0996628228988693, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.0996628228988693, fit_prior=True, norm=False, score=0.965, total=   0.0s\n",
            "[CV] alpha=0.0996628228988693, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.0996628228988693, fit_prior=True, norm=False, score=0.962, total=   0.0s\n",
            "[CV] alpha=0.0996628228988693, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.0996628228988693, fit_prior=False, norm=True, score=0.562, total=   0.0s\n",
            "[CV] alpha=0.0996628228988693, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.0996628228988693, fit_prior=False, norm=True, score=0.621, total=   0.1s\n",
            "[CV] alpha=0.0996628228988693, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.0996628228988693, fit_prior=False, norm=True, score=0.550, total=   0.0s\n",
            "[CV] alpha=0.0996628228988693, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.0996628228988693, fit_prior=False, norm=True, score=0.625, total=   0.0s\n",
            "[CV] alpha=0.0996628228988693, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.0996628228988693, fit_prior=False, norm=True, score=0.621, total=   0.0s\n",
            "[CV] alpha=0.0996628228988693, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.0996628228988693, fit_prior=False, norm=False, score=0.971, total=   0.0s\n",
            "[CV] alpha=0.0996628228988693, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.0996628228988693, fit_prior=False, norm=False, score=0.963, total=   0.1s\n",
            "[CV] alpha=0.0996628228988693, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.0996628228988693, fit_prior=False, norm=False, score=0.956, total=   0.0s\n",
            "[CV] alpha=0.0996628228988693, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.0996628228988693, fit_prior=False, norm=False, score=0.965, total=   0.0s\n",
            "[CV] alpha=0.0996628228988693, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.0996628228988693, fit_prior=False, norm=False, score=0.962, total=   0.0s\n",
            "[CV] alpha=0.5366679966910082, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.5366679966910082, fit_prior=True, norm=True, score=0.631, total=   0.0s\n",
            "[CV] alpha=0.5366679966910082, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.5366679966910082, fit_prior=True, norm=True, score=0.729, total=   0.0s\n",
            "[CV] alpha=0.5366679966910082, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.5366679966910082, fit_prior=True, norm=True, score=0.600, total=   0.1s\n",
            "[CV] alpha=0.5366679966910082, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.5366679966910082, fit_prior=True, norm=True, score=0.679, total=   0.1s\n",
            "[CV] alpha=0.5366679966910082, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.5366679966910082, fit_prior=True, norm=True, score=0.673, total=   0.0s\n",
            "[CV] alpha=0.5366679966910082, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.5366679966910082, fit_prior=True, norm=False, score=0.971, total=   0.0s\n",
            "[CV] alpha=0.5366679966910082, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.5366679966910082, fit_prior=True, norm=False, score=0.967, total=   0.1s\n",
            "[CV] alpha=0.5366679966910082, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.5366679966910082, fit_prior=True, norm=False, score=0.956, total=   0.0s\n",
            "[CV] alpha=0.5366679966910082, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.5366679966910082, fit_prior=True, norm=False, score=0.963, total=   0.1s\n",
            "[CV] alpha=0.5366679966910082, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.5366679966910082, fit_prior=True, norm=False, score=0.960, total=   0.0s\n",
            "[CV] alpha=0.5366679966910082, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.5366679966910082, fit_prior=False, norm=True, score=0.631, total=   0.0s\n",
            "[CV] alpha=0.5366679966910082, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.5366679966910082, fit_prior=False, norm=True, score=0.729, total=   0.0s\n",
            "[CV] alpha=0.5366679966910082, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.5366679966910082, fit_prior=False, norm=True, score=0.600, total=   0.0s\n",
            "[CV] alpha=0.5366679966910082, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.5366679966910082, fit_prior=False, norm=True, score=0.679, total=   0.0s\n",
            "[CV] alpha=0.5366679966910082, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.5366679966910082, fit_prior=False, norm=True, score=0.673, total=   0.0s\n",
            "[CV] alpha=0.5366679966910082, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.5366679966910082, fit_prior=False, norm=False, score=0.971, total=   0.0s\n",
            "[CV] alpha=0.5366679966910082, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.5366679966910082, fit_prior=False, norm=False, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.5366679966910082, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.5366679966910082, fit_prior=False, norm=False, score=0.956, total=   0.0s\n",
            "[CV] alpha=0.5366679966910082, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.5366679966910082, fit_prior=False, norm=False, score=0.963, total=   0.1s\n",
            "[CV] alpha=0.5366679966910082, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.5366679966910082, fit_prior=False, norm=False, score=0.960, total=   0.1s\n",
            "[CV] alpha=0.45088065542337663, fit_prior=True, norm=True ............\n",
            "[CV]  alpha=0.45088065542337663, fit_prior=True, norm=True, score=0.619, total=   0.0s\n",
            "[CV] alpha=0.45088065542337663, fit_prior=True, norm=True ............\n",
            "[CV]  alpha=0.45088065542337663, fit_prior=True, norm=True, score=0.712, total=   0.0s\n",
            "[CV] alpha=0.45088065542337663, fit_prior=True, norm=True ............\n",
            "[CV]  alpha=0.45088065542337663, fit_prior=True, norm=True, score=0.598, total=   0.0s\n",
            "[CV] alpha=0.45088065542337663, fit_prior=True, norm=True ............\n",
            "[CV]  alpha=0.45088065542337663, fit_prior=True, norm=True, score=0.669, total=   0.0s\n",
            "[CV] alpha=0.45088065542337663, fit_prior=True, norm=True ............\n",
            "[CV]  alpha=0.45088065542337663, fit_prior=True, norm=True, score=0.673, total=   0.1s\n",
            "[CV] alpha=0.45088065542337663, fit_prior=True, norm=False ...........\n",
            "[CV]  alpha=0.45088065542337663, fit_prior=True, norm=False, score=0.971, total=   0.0s\n",
            "[CV] alpha=0.45088065542337663, fit_prior=True, norm=False ...........\n",
            "[CV]  alpha=0.45088065542337663, fit_prior=True, norm=False, score=0.967, total=   0.1s\n",
            "[CV] alpha=0.45088065542337663, fit_prior=True, norm=False ...........\n",
            "[CV]  alpha=0.45088065542337663, fit_prior=True, norm=False, score=0.956, total=   0.0s\n",
            "[CV] alpha=0.45088065542337663, fit_prior=True, norm=False ...........\n",
            "[CV]  alpha=0.45088065542337663, fit_prior=True, norm=False, score=0.963, total=   0.1s\n",
            "[CV] alpha=0.45088065542337663, fit_prior=True, norm=False ...........\n",
            "[CV]  alpha=0.45088065542337663, fit_prior=True, norm=False, score=0.960, total=   0.0s\n",
            "[CV] alpha=0.45088065542337663, fit_prior=False, norm=True ...........\n",
            "[CV]  alpha=0.45088065542337663, fit_prior=False, norm=True, score=0.619, total=   0.0s\n",
            "[CV] alpha=0.45088065542337663, fit_prior=False, norm=True ...........\n",
            "[CV]  alpha=0.45088065542337663, fit_prior=False, norm=True, score=0.712, total=   0.1s\n",
            "[CV] alpha=0.45088065542337663, fit_prior=False, norm=True ...........\n",
            "[CV]  alpha=0.45088065542337663, fit_prior=False, norm=True, score=0.598, total=   0.1s\n",
            "[CV] alpha=0.45088065542337663, fit_prior=False, norm=True ...........\n",
            "[CV]  alpha=0.45088065542337663, fit_prior=False, norm=True, score=0.669, total=   0.0s\n",
            "[CV] alpha=0.45088065542337663, fit_prior=False, norm=True ...........\n",
            "[CV]  alpha=0.45088065542337663, fit_prior=False, norm=True, score=0.673, total=   0.0s\n",
            "[CV] alpha=0.45088065542337663, fit_prior=False, norm=False ..........\n",
            "[CV]  alpha=0.45088065542337663, fit_prior=False, norm=False, score=0.971, total=   0.0s\n",
            "[CV] alpha=0.45088065542337663, fit_prior=False, norm=False ..........\n",
            "[CV]  alpha=0.45088065542337663, fit_prior=False, norm=False, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.45088065542337663, fit_prior=False, norm=False ..........\n",
            "[CV]  alpha=0.45088065542337663, fit_prior=False, norm=False, score=0.956, total=   0.1s\n",
            "[CV] alpha=0.45088065542337663, fit_prior=False, norm=False ..........\n",
            "[CV]  alpha=0.45088065542337663, fit_prior=False, norm=False, score=0.963, total=   0.0s\n",
            "[CV] alpha=0.45088065542337663, fit_prior=False, norm=False ..........\n",
            "[CV]  alpha=0.45088065542337663, fit_prior=False, norm=False, score=0.960, total=   0.0s\n",
            "[CV] alpha=0.8254066339240771, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.8254066339240771, fit_prior=True, norm=True, score=0.658, total=   0.0s\n",
            "[CV] alpha=0.8254066339240771, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.8254066339240771, fit_prior=True, norm=True, score=0.760, total=   0.0s\n",
            "[CV] alpha=0.8254066339240771, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.8254066339240771, fit_prior=True, norm=True, score=0.629, total=   0.1s\n",
            "[CV] alpha=0.8254066339240771, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.8254066339240771, fit_prior=True, norm=True, score=0.702, total=   0.1s\n",
            "[CV] alpha=0.8254066339240771, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.8254066339240771, fit_prior=True, norm=True, score=0.696, total=   0.0s\n",
            "[CV] alpha=0.8254066339240771, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.8254066339240771, fit_prior=True, norm=False, score=0.971, total=   0.0s\n",
            "[CV] alpha=0.8254066339240771, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.8254066339240771, fit_prior=True, norm=False, score=0.969, total=   0.0s\n",
            "[CV] alpha=0.8254066339240771, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.8254066339240771, fit_prior=True, norm=False, score=0.956, total=   0.1s\n",
            "[CV] alpha=0.8254066339240771, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.8254066339240771, fit_prior=True, norm=False, score=0.963, total=   0.1s\n",
            "[CV] alpha=0.8254066339240771, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.8254066339240771, fit_prior=True, norm=False, score=0.960, total=   0.0s\n",
            "[CV] alpha=0.8254066339240771, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.8254066339240771, fit_prior=False, norm=True, score=0.658, total=   0.1s\n",
            "[CV] alpha=0.8254066339240771, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.8254066339240771, fit_prior=False, norm=True, score=0.760, total=   0.0s\n",
            "[CV] alpha=0.8254066339240771, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.8254066339240771, fit_prior=False, norm=True, score=0.629, total=   0.0s\n",
            "[CV] alpha=0.8254066339240771, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.8254066339240771, fit_prior=False, norm=True, score=0.702, total=   0.0s\n",
            "[CV] alpha=0.8254066339240771, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.8254066339240771, fit_prior=False, norm=True, score=0.696, total=   0.0s\n",
            "[CV] alpha=0.8254066339240771, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.8254066339240771, fit_prior=False, norm=False, score=0.971, total=   0.1s\n",
            "[CV] alpha=0.8254066339240771, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.8254066339240771, fit_prior=False, norm=False, score=0.969, total=   0.1s\n",
            "[CV] alpha=0.8254066339240771, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.8254066339240771, fit_prior=False, norm=False, score=0.956, total=   0.0s\n",
            "[CV] alpha=0.8254066339240771, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.8254066339240771, fit_prior=False, norm=False, score=0.963, total=   0.0s\n",
            "[CV] alpha=0.8254066339240771, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.8254066339240771, fit_prior=False, norm=False, score=0.960, total=   0.0s\n",
            "[CV] alpha=0.08028170889354014, fit_prior=True, norm=True ............\n",
            "[CV]  alpha=0.08028170889354014, fit_prior=True, norm=True, score=0.560, total=   0.1s\n",
            "[CV] alpha=0.08028170889354014, fit_prior=True, norm=True ............\n",
            "[CV]  alpha=0.08028170889354014, fit_prior=True, norm=True, score=0.617, total=   0.0s\n",
            "[CV] alpha=0.08028170889354014, fit_prior=True, norm=True ............\n",
            "[CV]  alpha=0.08028170889354014, fit_prior=True, norm=True, score=0.544, total=   0.0s\n",
            "[CV] alpha=0.08028170889354014, fit_prior=True, norm=True ............\n",
            "[CV]  alpha=0.08028170889354014, fit_prior=True, norm=True, score=0.617, total=   0.0s\n",
            "[CV] alpha=0.08028170889354014, fit_prior=True, norm=True ............\n",
            "[CV]  alpha=0.08028170889354014, fit_prior=True, norm=True, score=0.617, total=   0.1s\n",
            "[CV] alpha=0.08028170889354014, fit_prior=True, norm=False ...........\n",
            "[CV]  alpha=0.08028170889354014, fit_prior=True, norm=False, score=0.971, total=   0.1s\n",
            "[CV] alpha=0.08028170889354014, fit_prior=True, norm=False ...........\n",
            "[CV]  alpha=0.08028170889354014, fit_prior=True, norm=False, score=0.965, total=   0.0s\n",
            "[CV] alpha=0.08028170889354014, fit_prior=True, norm=False ...........\n",
            "[CV]  alpha=0.08028170889354014, fit_prior=True, norm=False, score=0.956, total=   0.1s\n",
            "[CV] alpha=0.08028170889354014, fit_prior=True, norm=False ...........\n",
            "[CV]  alpha=0.08028170889354014, fit_prior=True, norm=False, score=0.965, total=   0.1s\n",
            "[CV] alpha=0.08028170889354014, fit_prior=True, norm=False ...........\n",
            "[CV]  alpha=0.08028170889354014, fit_prior=True, norm=False, score=0.962, total=   0.0s\n",
            "[CV] alpha=0.08028170889354014, fit_prior=False, norm=True ...........\n",
            "[CV]  alpha=0.08028170889354014, fit_prior=False, norm=True, score=0.560, total=   0.0s\n",
            "[CV] alpha=0.08028170889354014, fit_prior=False, norm=True ...........\n",
            "[CV]  alpha=0.08028170889354014, fit_prior=False, norm=True, score=0.617, total=   0.0s\n",
            "[CV] alpha=0.08028170889354014, fit_prior=False, norm=True ...........\n",
            "[CV]  alpha=0.08028170889354014, fit_prior=False, norm=True, score=0.544, total=   0.1s\n",
            "[CV] alpha=0.08028170889354014, fit_prior=False, norm=True ...........\n",
            "[CV]  alpha=0.08028170889354014, fit_prior=False, norm=True, score=0.617, total=   0.0s\n",
            "[CV] alpha=0.08028170889354014, fit_prior=False, norm=True ...........\n",
            "[CV]  alpha=0.08028170889354014, fit_prior=False, norm=True, score=0.617, total=   0.0s\n",
            "[CV] alpha=0.08028170889354014, fit_prior=False, norm=False ..........\n",
            "[CV]  alpha=0.08028170889354014, fit_prior=False, norm=False, score=0.971, total=   0.0s\n",
            "[CV] alpha=0.08028170889354014, fit_prior=False, norm=False ..........\n",
            "[CV]  alpha=0.08028170889354014, fit_prior=False, norm=False, score=0.965, total=   0.0s\n",
            "[CV] alpha=0.08028170889354014, fit_prior=False, norm=False ..........\n",
            "[CV]  alpha=0.08028170889354014, fit_prior=False, norm=False, score=0.956, total=   0.1s\n",
            "[CV] alpha=0.08028170889354014, fit_prior=False, norm=False ..........\n",
            "[CV]  alpha=0.08028170889354014, fit_prior=False, norm=False, score=0.965, total=   0.0s\n",
            "[CV] alpha=0.08028170889354014, fit_prior=False, norm=False ..........\n",
            "[CV]  alpha=0.08028170889354014, fit_prior=False, norm=False, score=0.962, total=   0.0s\n",
            "[CV] alpha=0.7455202658748334, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.7455202658748334, fit_prior=True, norm=True, score=0.652, total=   0.1s\n",
            "[CV] alpha=0.7455202658748334, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.7455202658748334, fit_prior=True, norm=True, score=0.744, total=   0.1s\n",
            "[CV] alpha=0.7455202658748334, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.7455202658748334, fit_prior=True, norm=True, score=0.617, total=   0.0s\n",
            "[CV] alpha=0.7455202658748334, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.7455202658748334, fit_prior=True, norm=True, score=0.698, total=   0.0s\n",
            "[CV] alpha=0.7455202658748334, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.7455202658748334, fit_prior=True, norm=True, score=0.692, total=   0.1s\n",
            "[CV] alpha=0.7455202658748334, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.7455202658748334, fit_prior=True, norm=False, score=0.971, total=   0.1s\n",
            "[CV] alpha=0.7455202658748334, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.7455202658748334, fit_prior=True, norm=False, score=0.969, total=   0.0s\n",
            "[CV] alpha=0.7455202658748334, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.7455202658748334, fit_prior=True, norm=False, score=0.956, total=   0.1s\n",
            "[CV] alpha=0.7455202658748334, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.7455202658748334, fit_prior=True, norm=False, score=0.963, total=   0.1s\n",
            "[CV] alpha=0.7455202658748334, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.7455202658748334, fit_prior=True, norm=False, score=0.960, total=   0.1s\n",
            "[CV] alpha=0.7455202658748334, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.7455202658748334, fit_prior=False, norm=True, score=0.652, total=   0.0s\n",
            "[CV] alpha=0.7455202658748334, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.7455202658748334, fit_prior=False, norm=True, score=0.744, total=   0.0s\n",
            "[CV] alpha=0.7455202658748334, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.7455202658748334, fit_prior=False, norm=True, score=0.617, total=   0.0s\n",
            "[CV] alpha=0.7455202658748334, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.7455202658748334, fit_prior=False, norm=True, score=0.698, total=   0.0s\n",
            "[CV] alpha=0.7455202658748334, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.7455202658748334, fit_prior=False, norm=True, score=0.692, total=   0.1s\n",
            "[CV] alpha=0.7455202658748334, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.7455202658748334, fit_prior=False, norm=False, score=0.971, total=   0.1s\n",
            "[CV] alpha=0.7455202658748334, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.7455202658748334, fit_prior=False, norm=False, score=0.969, total=   0.0s\n",
            "[CV] alpha=0.7455202658748334, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.7455202658748334, fit_prior=False, norm=False, score=0.956, total=   0.0s\n",
            "[CV] alpha=0.7455202658748334, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.7455202658748334, fit_prior=False, norm=False, score=0.963, total=   0.1s\n",
            "[CV] alpha=0.7455202658748334, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.7455202658748334, fit_prior=False, norm=False, score=0.960, total=   0.0s\n",
            "[CV] alpha=0.17471181948635972, fit_prior=True, norm=True ............\n",
            "[CV]  alpha=0.17471181948635972, fit_prior=True, norm=True, score=0.583, total=   0.0s\n",
            "[CV] alpha=0.17471181948635972, fit_prior=True, norm=True ............\n",
            "[CV]  alpha=0.17471181948635972, fit_prior=True, norm=True, score=0.652, total=   0.0s\n",
            "[CV] alpha=0.17471181948635972, fit_prior=True, norm=True ............\n",
            "[CV]  alpha=0.17471181948635972, fit_prior=True, norm=True, score=0.571, total=   0.0s\n",
            "[CV] alpha=0.17471181948635972, fit_prior=True, norm=True ............\n",
            "[CV]  alpha=0.17471181948635972, fit_prior=True, norm=True, score=0.646, total=   0.1s\n",
            "[CV] alpha=0.17471181948635972, fit_prior=True, norm=True ............\n",
            "[CV]  alpha=0.17471181948635972, fit_prior=True, norm=True, score=0.640, total=   0.0s\n",
            "[CV] alpha=0.17471181948635972, fit_prior=True, norm=False ...........\n",
            "[CV]  alpha=0.17471181948635972, fit_prior=True, norm=False, score=0.971, total=   0.0s\n",
            "[CV] alpha=0.17471181948635972, fit_prior=True, norm=False ...........\n",
            "[CV]  alpha=0.17471181948635972, fit_prior=True, norm=False, score=0.963, total=   0.1s\n",
            "[CV] alpha=0.17471181948635972, fit_prior=True, norm=False ...........\n",
            "[CV]  alpha=0.17471181948635972, fit_prior=True, norm=False, score=0.956, total=   0.1s\n",
            "[CV] alpha=0.17471181948635972, fit_prior=True, norm=False ...........\n",
            "[CV]  alpha=0.17471181948635972, fit_prior=True, norm=False, score=0.963, total=   0.0s\n",
            "[CV] alpha=0.17471181948635972, fit_prior=True, norm=False ...........\n",
            "[CV]  alpha=0.17471181948635972, fit_prior=True, norm=False, score=0.960, total=   0.0s\n",
            "[CV] alpha=0.17471181948635972, fit_prior=False, norm=True ...........\n",
            "[CV]  alpha=0.17471181948635972, fit_prior=False, norm=True, score=0.583, total=   0.0s\n",
            "[CV] alpha=0.17471181948635972, fit_prior=False, norm=True ...........\n",
            "[CV]  alpha=0.17471181948635972, fit_prior=False, norm=True, score=0.652, total=   0.0s\n",
            "[CV] alpha=0.17471181948635972, fit_prior=False, norm=True ...........\n",
            "[CV]  alpha=0.17471181948635972, fit_prior=False, norm=True, score=0.571, total=   0.1s\n",
            "[CV] alpha=0.17471181948635972, fit_prior=False, norm=True ...........\n",
            "[CV]  alpha=0.17471181948635972, fit_prior=False, norm=True, score=0.646, total=   0.0s\n",
            "[CV] alpha=0.17471181948635972, fit_prior=False, norm=True ...........\n",
            "[CV]  alpha=0.17471181948635972, fit_prior=False, norm=True, score=0.640, total=   0.1s\n",
            "[CV] alpha=0.17471181948635972, fit_prior=False, norm=False ..........\n",
            "[CV]  alpha=0.17471181948635972, fit_prior=False, norm=False, score=0.971, total=   0.0s\n",
            "[CV] alpha=0.17471181948635972, fit_prior=False, norm=False ..........\n",
            "[CV]  alpha=0.17471181948635972, fit_prior=False, norm=False, score=0.963, total=   0.1s\n",
            "[CV] alpha=0.17471181948635972, fit_prior=False, norm=False ..........\n",
            "[CV]  alpha=0.17471181948635972, fit_prior=False, norm=False, score=0.956, total=   0.0s\n",
            "[CV] alpha=0.17471181948635972, fit_prior=False, norm=False ..........\n",
            "[CV]  alpha=0.17471181948635972, fit_prior=False, norm=False, score=0.963, total=   0.0s\n",
            "[CV] alpha=0.17471181948635972, fit_prior=False, norm=False ..........\n",
            "[CV]  alpha=0.17471181948635972, fit_prior=False, norm=False, score=0.960, total=   0.0s\n",
            "[CV] alpha=0.3779303474997573, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.3779303474997573, fit_prior=True, norm=True, score=0.612, total=   0.1s\n",
            "[CV] alpha=0.3779303474997573, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.3779303474997573, fit_prior=True, norm=True, score=0.696, total=   0.0s\n",
            "[CV] alpha=0.3779303474997573, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.3779303474997573, fit_prior=True, norm=True, score=0.588, total=   0.0s\n",
            "[CV] alpha=0.3779303474997573, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.3779303474997573, fit_prior=True, norm=True, score=0.662, total=   0.0s\n",
            "[CV] alpha=0.3779303474997573, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.3779303474997573, fit_prior=True, norm=True, score=0.669, total=   0.0s\n",
            "[CV] alpha=0.3779303474997573, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.3779303474997573, fit_prior=True, norm=False, score=0.971, total=   0.1s\n",
            "[CV] alpha=0.3779303474997573, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.3779303474997573, fit_prior=True, norm=False, score=0.967, total=   0.1s\n",
            "[CV] alpha=0.3779303474997573, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.3779303474997573, fit_prior=True, norm=False, score=0.956, total=   0.0s\n",
            "[CV] alpha=0.3779303474997573, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.3779303474997573, fit_prior=True, norm=False, score=0.963, total=   0.0s\n",
            "[CV] alpha=0.3779303474997573, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.3779303474997573, fit_prior=True, norm=False, score=0.960, total=   0.1s\n",
            "[CV] alpha=0.3779303474997573, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.3779303474997573, fit_prior=False, norm=True, score=0.612, total=   0.0s\n",
            "[CV] alpha=0.3779303474997573, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.3779303474997573, fit_prior=False, norm=True, score=0.696, total=   0.0s\n",
            "[CV] alpha=0.3779303474997573, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.3779303474997573, fit_prior=False, norm=True, score=0.588, total=   0.0s\n",
            "[CV] alpha=0.3779303474997573, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.3779303474997573, fit_prior=False, norm=True, score=0.662, total=   0.1s\n",
            "[CV] alpha=0.3779303474997573, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.3779303474997573, fit_prior=False, norm=True, score=0.669, total=   0.0s\n",
            "[CV] alpha=0.3779303474997573, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.3779303474997573, fit_prior=False, norm=False, score=0.971, total=   0.0s\n",
            "[CV] alpha=0.3779303474997573, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.3779303474997573, fit_prior=False, norm=False, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.3779303474997573, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.3779303474997573, fit_prior=False, norm=False, score=0.956, total=   0.0s\n",
            "[CV] alpha=0.3779303474997573, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.3779303474997573, fit_prior=False, norm=False, score=0.963, total=   0.1s\n",
            "[CV] alpha=0.3779303474997573, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.3779303474997573, fit_prior=False, norm=False, score=0.960, total=   0.0s\n",
            "[CV] alpha=0.8269344750046854, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.8269344750046854, fit_prior=True, norm=True, score=0.658, total=   0.0s\n",
            "[CV] alpha=0.8269344750046854, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.8269344750046854, fit_prior=True, norm=True, score=0.760, total=   0.1s\n",
            "[CV] alpha=0.8269344750046854, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.8269344750046854, fit_prior=True, norm=True, score=0.629, total=   0.1s\n",
            "[CV] alpha=0.8269344750046854, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.8269344750046854, fit_prior=True, norm=True, score=0.704, total=   0.0s\n",
            "[CV] alpha=0.8269344750046854, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.8269344750046854, fit_prior=True, norm=True, score=0.696, total=   0.0s\n",
            "[CV] alpha=0.8269344750046854, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.8269344750046854, fit_prior=True, norm=False, score=0.971, total=   0.0s\n",
            "[CV] alpha=0.8269344750046854, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.8269344750046854, fit_prior=True, norm=False, score=0.969, total=   0.1s\n",
            "[CV] alpha=0.8269344750046854, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.8269344750046854, fit_prior=True, norm=False, score=0.956, total=   0.1s\n",
            "[CV] alpha=0.8269344750046854, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.8269344750046854, fit_prior=True, norm=False, score=0.963, total=   0.0s\n",
            "[CV] alpha=0.8269344750046854, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.8269344750046854, fit_prior=True, norm=False, score=0.960, total=   0.0s\n",
            "[CV] alpha=0.8269344750046854, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.8269344750046854, fit_prior=False, norm=True, score=0.658, total=   0.0s\n",
            "[CV] alpha=0.8269344750046854, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.8269344750046854, fit_prior=False, norm=True, score=0.760, total=   0.1s\n",
            "[CV] alpha=0.8269344750046854, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.8269344750046854, fit_prior=False, norm=True, score=0.629, total=   0.0s\n",
            "[CV] alpha=0.8269344750046854, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.8269344750046854, fit_prior=False, norm=True, score=0.704, total=   0.0s\n",
            "[CV] alpha=0.8269344750046854, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.8269344750046854, fit_prior=False, norm=True, score=0.696, total=   0.1s\n",
            "[CV] alpha=0.8269344750046854, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.8269344750046854, fit_prior=False, norm=False, score=0.971, total=   0.1s\n",
            "[CV] alpha=0.8269344750046854, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.8269344750046854, fit_prior=False, norm=False, score=0.969, total=   0.0s\n",
            "[CV] alpha=0.8269344750046854, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.8269344750046854, fit_prior=False, norm=False, score=0.956, total=   0.0s\n",
            "[CV] alpha=0.8269344750046854, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.8269344750046854, fit_prior=False, norm=False, score=0.963, total=   0.0s\n",
            "[CV] alpha=0.8269344750046854, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.8269344750046854, fit_prior=False, norm=False, score=0.960, total=   0.0s\n",
            "[CV] alpha=0.6466228999385912, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.6466228999385912, fit_prior=True, norm=True, score=0.648, total=   0.0s\n",
            "[CV] alpha=0.6466228999385912, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.6466228999385912, fit_prior=True, norm=True, score=0.738, total=   0.0s\n",
            "[CV] alpha=0.6466228999385912, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.6466228999385912, fit_prior=True, norm=True, score=0.610, total=   0.0s\n",
            "[CV] alpha=0.6466228999385912, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.6466228999385912, fit_prior=True, norm=True, score=0.687, total=   0.0s\n",
            "[CV] alpha=0.6466228999385912, fit_prior=True, norm=True .............\n",
            "[CV]  alpha=0.6466228999385912, fit_prior=True, norm=True, score=0.681, total=   0.0s\n",
            "[CV] alpha=0.6466228999385912, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.6466228999385912, fit_prior=True, norm=False, score=0.971, total=   0.1s\n",
            "[CV] alpha=0.6466228999385912, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.6466228999385912, fit_prior=True, norm=False, score=0.967, total=   0.0s\n",
            "[CV] alpha=0.6466228999385912, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.6466228999385912, fit_prior=True, norm=False, score=0.956, total=   0.1s\n",
            "[CV] alpha=0.6466228999385912, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.6466228999385912, fit_prior=True, norm=False, score=0.963, total=   0.0s\n",
            "[CV] alpha=0.6466228999385912, fit_prior=True, norm=False ............\n",
            "[CV]  alpha=0.6466228999385912, fit_prior=True, norm=False, score=0.960, total=   0.0s\n",
            "[CV] alpha=0.6466228999385912, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.6466228999385912, fit_prior=False, norm=True, score=0.648, total=   0.0s\n",
            "[CV] alpha=0.6466228999385912, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.6466228999385912, fit_prior=False, norm=True, score=0.738, total=   0.0s\n",
            "[CV] alpha=0.6466228999385912, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.6466228999385912, fit_prior=False, norm=True, score=0.610, total=   0.0s\n",
            "[CV] alpha=0.6466228999385912, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.6466228999385912, fit_prior=False, norm=True, score=0.687, total=   0.0s\n",
            "[CV] alpha=0.6466228999385912, fit_prior=False, norm=True ............\n",
            "[CV]  alpha=0.6466228999385912, fit_prior=False, norm=True, score=0.681, total=   0.0s\n",
            "[CV] alpha=0.6466228999385912, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.6466228999385912, fit_prior=False, norm=False, score=0.971, total=   0.0s\n",
            "[CV] alpha=0.6466228999385912, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.6466228999385912, fit_prior=False, norm=False, score=0.967, total=   0.1s\n",
            "[CV] alpha=0.6466228999385912, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.6466228999385912, fit_prior=False, norm=False, score=0.956, total=   0.0s\n",
            "[CV] alpha=0.6466228999385912, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.6466228999385912, fit_prior=False, norm=False, score=0.963, total=   0.0s\n",
            "[CV] alpha=0.6466228999385912, fit_prior=False, norm=False ...........\n",
            "[CV]  alpha=0.6466228999385912, fit_prior=False, norm=False, score=0.960, total=   0.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:   10.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=ComplementNB(alpha=1.0, class_prior=None, fit_prior=True,\n",
              "                                    norm=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'alpha': array([0.09966282, 0.536668  , 0.45088066, 0.82540663, 0.08028171,\n",
              "       0.74552027, 0.17471182, 0.37793035, 0.82693448, 0.6466229 ]),\n",
              "                         'fit_prior': [True, False], 'norm': [True, False]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsVafzCyp-Mp",
        "outputId": "7c6d1b4d-9717-44c7-ad28-852ab1eadbe8"
      },
      "source": [
        "grid_search_cnb.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.8254066339240771, 'fit_prior': True, 'norm': False}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLqomTycqBKU",
        "outputId": "c3c0b928-ca0b-4a26-d369-bfa240612dd0"
      },
      "source": [
        "grid_search_cnb.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9638461538461538"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ll57LMIqD-K",
        "outputId": "76debe0b-1280-43be-eb3e-5fd76ddb2cc8"
      },
      "source": [
        "y_pred_cnb = grid_search_cnb.predict(X_test_transformed.toarray())\n",
        "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred_cnb)))\n",
        "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred_cnb)))\n",
        "print(\"f1 score: {:.2f}%\".format(100 * f1_score(y_test, y_pred_cnb)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 90.10%\n",
            "Recall: 87.50%\n",
            "f1 score: 88.78%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "aEbrEf2gqM2W",
        "outputId": "2e7d65fc-12c9-44fc-9e67-8efb557c11ad"
      },
      "source": [
        "plot_confusion_matrix(grid_search_cnb, X_test_transformed.toarray(), y_test, cmap=plt.cm.Blues)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f5f9bb86c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VguHOT_nqnBy"
      },
      "source": [
        "####4. Bernoulli Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggYSPRkqqdlG",
        "outputId": "7dc4b42c-59a3-4702-93e5-889e7319de89"
      },
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "bnb_clf = BernoulliNB()\n",
        "grid_search_bnb = GridSearchCV(bnb_clf, param_grid=mnb_param_grid, cv=5, verbose=3)\n",
        "grid_search_bnb.fit(X_train_transformed.toarray(), y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "[CV] alpha=0.27589515353983063, fit_prior=True .......................\n",
            "[CV]  alpha=0.27589515353983063, fit_prior=True, score=0.950, total=   0.1s\n",
            "[CV] alpha=0.27589515353983063, fit_prior=True .......................\n",
            "[CV]  alpha=0.27589515353983063, fit_prior=True, score=0.952, total=   0.1s\n",
            "[CV] alpha=0.27589515353983063, fit_prior=True .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  alpha=0.27589515353983063, fit_prior=True, score=0.935, total=   0.1s\n",
            "[CV] alpha=0.27589515353983063, fit_prior=True .......................\n",
            "[CV]  alpha=0.27589515353983063, fit_prior=True, score=0.950, total=   0.1s\n",
            "[CV] alpha=0.27589515353983063, fit_prior=True .......................\n",
            "[CV]  alpha=0.27589515353983063, fit_prior=True, score=0.954, total=   0.1s\n",
            "[CV] alpha=0.27589515353983063, fit_prior=False ......................\n",
            "[CV]  alpha=0.27589515353983063, fit_prior=False, score=0.948, total=   0.1s\n",
            "[CV] alpha=0.27589515353983063, fit_prior=False ......................\n",
            "[CV]  alpha=0.27589515353983063, fit_prior=False, score=0.952, total=   0.1s\n",
            "[CV] alpha=0.27589515353983063, fit_prior=False ......................\n",
            "[CV]  alpha=0.27589515353983063, fit_prior=False, score=0.933, total=   0.1s\n",
            "[CV] alpha=0.27589515353983063, fit_prior=False ......................\n",
            "[CV]  alpha=0.27589515353983063, fit_prior=False, score=0.950, total=   0.1s\n",
            "[CV] alpha=0.27589515353983063, fit_prior=False ......................\n",
            "[CV]  alpha=0.27589515353983063, fit_prior=False, score=0.950, total=   0.1s\n",
            "[CV] alpha=0.7130675212983979, fit_prior=True ........................\n",
            "[CV]  alpha=0.7130675212983979, fit_prior=True, score=0.937, total=   0.1s\n",
            "[CV] alpha=0.7130675212983979, fit_prior=True ........................\n",
            "[CV]  alpha=0.7130675212983979, fit_prior=True, score=0.948, total=   0.1s\n",
            "[CV] alpha=0.7130675212983979, fit_prior=True ........................\n",
            "[CV]  alpha=0.7130675212983979, fit_prior=True, score=0.927, total=   0.1s\n",
            "[CV] alpha=0.7130675212983979, fit_prior=True ........................\n",
            "[CV]  alpha=0.7130675212983979, fit_prior=True, score=0.944, total=   0.1s\n",
            "[CV] alpha=0.7130675212983979, fit_prior=True ........................\n",
            "[CV]  alpha=0.7130675212983979, fit_prior=True, score=0.942, total=   0.1s\n",
            "[CV] alpha=0.7130675212983979, fit_prior=False .......................\n",
            "[CV]  alpha=0.7130675212983979, fit_prior=False, score=0.940, total=   0.1s\n",
            "[CV] alpha=0.7130675212983979, fit_prior=False .......................\n",
            "[CV]  alpha=0.7130675212983979, fit_prior=False, score=0.950, total=   0.1s\n",
            "[CV] alpha=0.7130675212983979, fit_prior=False .......................\n",
            "[CV]  alpha=0.7130675212983979, fit_prior=False, score=0.927, total=   0.1s\n",
            "[CV] alpha=0.7130675212983979, fit_prior=False .......................\n",
            "[CV]  alpha=0.7130675212983979, fit_prior=False, score=0.944, total=   0.1s\n",
            "[CV] alpha=0.7130675212983979, fit_prior=False .......................\n",
            "[CV]  alpha=0.7130675212983979, fit_prior=False, score=0.942, total=   0.1s\n",
            "[CV] alpha=0.45386414479471304, fit_prior=True .......................\n",
            "[CV]  alpha=0.45386414479471304, fit_prior=True, score=0.942, total=   0.1s\n",
            "[CV] alpha=0.45386414479471304, fit_prior=True .......................\n",
            "[CV]  alpha=0.45386414479471304, fit_prior=True, score=0.952, total=   0.1s\n",
            "[CV] alpha=0.45386414479471304, fit_prior=True .......................\n",
            "[CV]  alpha=0.45386414479471304, fit_prior=True, score=0.931, total=   0.1s\n",
            "[CV] alpha=0.45386414479471304, fit_prior=True .......................\n",
            "[CV]  alpha=0.45386414479471304, fit_prior=True, score=0.950, total=   0.1s\n",
            "[CV] alpha=0.45386414479471304, fit_prior=True .......................\n",
            "[CV]  alpha=0.45386414479471304, fit_prior=True, score=0.950, total=   0.1s\n",
            "[CV] alpha=0.45386414479471304, fit_prior=False ......................\n",
            "[CV]  alpha=0.45386414479471304, fit_prior=False, score=0.944, total=   0.1s\n",
            "[CV] alpha=0.45386414479471304, fit_prior=False ......................\n",
            "[CV]  alpha=0.45386414479471304, fit_prior=False, score=0.952, total=   0.1s\n",
            "[CV] alpha=0.45386414479471304, fit_prior=False ......................\n",
            "[CV]  alpha=0.45386414479471304, fit_prior=False, score=0.931, total=   0.1s\n",
            "[CV] alpha=0.45386414479471304, fit_prior=False ......................\n",
            "[CV]  alpha=0.45386414479471304, fit_prior=False, score=0.944, total=   0.1s\n",
            "[CV] alpha=0.45386414479471304, fit_prior=False ......................\n",
            "[CV]  alpha=0.45386414479471304, fit_prior=False, score=0.946, total=   0.1s\n",
            "[CV] alpha=0.6380050714427364, fit_prior=True ........................\n",
            "[CV]  alpha=0.6380050714427364, fit_prior=True, score=0.937, total=   0.1s\n",
            "[CV] alpha=0.6380050714427364, fit_prior=True ........................\n",
            "[CV]  alpha=0.6380050714427364, fit_prior=True, score=0.948, total=   0.1s\n",
            "[CV] alpha=0.6380050714427364, fit_prior=True ........................\n",
            "[CV]  alpha=0.6380050714427364, fit_prior=True, score=0.931, total=   0.1s\n",
            "[CV] alpha=0.6380050714427364, fit_prior=True ........................\n",
            "[CV]  alpha=0.6380050714427364, fit_prior=True, score=0.946, total=   0.1s\n",
            "[CV] alpha=0.6380050714427364, fit_prior=True ........................\n",
            "[CV]  alpha=0.6380050714427364, fit_prior=True, score=0.944, total=   0.1s\n",
            "[CV] alpha=0.6380050714427364, fit_prior=False .......................\n",
            "[CV]  alpha=0.6380050714427364, fit_prior=False, score=0.942, total=   0.1s\n",
            "[CV] alpha=0.6380050714427364, fit_prior=False .......................\n",
            "[CV]  alpha=0.6380050714427364, fit_prior=False, score=0.952, total=   0.1s\n",
            "[CV] alpha=0.6380050714427364, fit_prior=False .......................\n",
            "[CV]  alpha=0.6380050714427364, fit_prior=False, score=0.929, total=   0.1s\n",
            "[CV] alpha=0.6380050714427364, fit_prior=False .......................\n",
            "[CV]  alpha=0.6380050714427364, fit_prior=False, score=0.944, total=   0.1s\n",
            "[CV] alpha=0.6380050714427364, fit_prior=False .......................\n",
            "[CV]  alpha=0.6380050714427364, fit_prior=False, score=0.942, total=   0.1s\n",
            "[CV] alpha=0.9784994035236168, fit_prior=True ........................\n",
            "[CV]  alpha=0.9784994035236168, fit_prior=True, score=0.931, total=   0.1s\n",
            "[CV] alpha=0.9784994035236168, fit_prior=True ........................\n",
            "[CV]  alpha=0.9784994035236168, fit_prior=True, score=0.942, total=   0.1s\n",
            "[CV] alpha=0.9784994035236168, fit_prior=True ........................\n",
            "[CV]  alpha=0.9784994035236168, fit_prior=True, score=0.925, total=   0.1s\n",
            "[CV] alpha=0.9784994035236168, fit_prior=True ........................\n",
            "[CV]  alpha=0.9784994035236168, fit_prior=True, score=0.942, total=   0.1s\n",
            "[CV] alpha=0.9784994035236168, fit_prior=True ........................\n",
            "[CV]  alpha=0.9784994035236168, fit_prior=True, score=0.942, total=   0.1s\n",
            "[CV] alpha=0.9784994035236168, fit_prior=False .......................\n",
            "[CV]  alpha=0.9784994035236168, fit_prior=False, score=0.933, total=   0.1s\n",
            "[CV] alpha=0.9784994035236168, fit_prior=False .......................\n",
            "[CV]  alpha=0.9784994035236168, fit_prior=False, score=0.950, total=   0.1s\n",
            "[CV] alpha=0.9784994035236168, fit_prior=False .......................\n",
            "[CV]  alpha=0.9784994035236168, fit_prior=False, score=0.925, total=   0.1s\n",
            "[CV] alpha=0.9784994035236168, fit_prior=False .......................\n",
            "[CV]  alpha=0.9784994035236168, fit_prior=False, score=0.940, total=   0.1s\n",
            "[CV] alpha=0.9784994035236168, fit_prior=False .......................\n",
            "[CV]  alpha=0.9784994035236168, fit_prior=False, score=0.942, total=   0.1s\n",
            "[CV] alpha=0.342706553511956, fit_prior=True .........................\n",
            "[CV]  alpha=0.342706553511956, fit_prior=True, score=0.942, total=   0.1s\n",
            "[CV] alpha=0.342706553511956, fit_prior=True .........................\n",
            "[CV]  alpha=0.342706553511956, fit_prior=True, score=0.952, total=   0.1s\n",
            "[CV] alpha=0.342706553511956, fit_prior=True .........................\n",
            "[CV]  alpha=0.342706553511956, fit_prior=True, score=0.935, total=   0.1s\n",
            "[CV] alpha=0.342706553511956, fit_prior=True .........................\n",
            "[CV]  alpha=0.342706553511956, fit_prior=True, score=0.950, total=   0.1s\n",
            "[CV] alpha=0.342706553511956, fit_prior=True .........................\n",
            "[CV]  alpha=0.342706553511956, fit_prior=True, score=0.954, total=   0.1s\n",
            "[CV] alpha=0.342706553511956, fit_prior=False ........................\n",
            "[CV]  alpha=0.342706553511956, fit_prior=False, score=0.946, total=   0.1s\n",
            "[CV] alpha=0.342706553511956, fit_prior=False ........................\n",
            "[CV]  alpha=0.342706553511956, fit_prior=False, score=0.952, total=   0.1s\n",
            "[CV] alpha=0.342706553511956, fit_prior=False ........................\n",
            "[CV]  alpha=0.342706553511956, fit_prior=False, score=0.931, total=   0.1s\n",
            "[CV] alpha=0.342706553511956, fit_prior=False ........................\n",
            "[CV]  alpha=0.342706553511956, fit_prior=False, score=0.948, total=   0.1s\n",
            "[CV] alpha=0.342706553511956, fit_prior=False ........................\n",
            "[CV]  alpha=0.342706553511956, fit_prior=False, score=0.946, total=   0.1s\n",
            "[CV] alpha=0.03435042418656198, fit_prior=True .......................\n",
            "[CV]  alpha=0.03435042418656198, fit_prior=True, score=0.956, total=   0.1s\n",
            "[CV] alpha=0.03435042418656198, fit_prior=True .......................\n",
            "[CV]  alpha=0.03435042418656198, fit_prior=True, score=0.952, total=   0.1s\n",
            "[CV] alpha=0.03435042418656198, fit_prior=True .......................\n",
            "[CV]  alpha=0.03435042418656198, fit_prior=True, score=0.942, total=   0.1s\n",
            "[CV] alpha=0.03435042418656198, fit_prior=True .......................\n",
            "[CV]  alpha=0.03435042418656198, fit_prior=True, score=0.954, total=   0.1s\n",
            "[CV] alpha=0.03435042418656198, fit_prior=True .......................\n",
            "[CV]  alpha=0.03435042418656198, fit_prior=True, score=0.956, total=   0.1s\n",
            "[CV] alpha=0.03435042418656198, fit_prior=False ......................\n",
            "[CV]  alpha=0.03435042418656198, fit_prior=False, score=0.958, total=   0.1s\n",
            "[CV] alpha=0.03435042418656198, fit_prior=False ......................\n",
            "[CV]  alpha=0.03435042418656198, fit_prior=False, score=0.952, total=   0.1s\n",
            "[CV] alpha=0.03435042418656198, fit_prior=False ......................\n",
            "[CV]  alpha=0.03435042418656198, fit_prior=False, score=0.940, total=   0.1s\n",
            "[CV] alpha=0.03435042418656198, fit_prior=False ......................\n",
            "[CV]  alpha=0.03435042418656198, fit_prior=False, score=0.954, total=   0.1s\n",
            "[CV] alpha=0.03435042418656198, fit_prior=False ......................\n",
            "[CV]  alpha=0.03435042418656198, fit_prior=False, score=0.954, total=   0.1s\n",
            "[CV] alpha=0.07773946210594596, fit_prior=True .......................\n",
            "[CV]  alpha=0.07773946210594596, fit_prior=True, score=0.954, total=   0.1s\n",
            "[CV] alpha=0.07773946210594596, fit_prior=True .......................\n",
            "[CV]  alpha=0.07773946210594596, fit_prior=True, score=0.952, total=   0.1s\n",
            "[CV] alpha=0.07773946210594596, fit_prior=True .......................\n",
            "[CV]  alpha=0.07773946210594596, fit_prior=True, score=0.940, total=   0.1s\n",
            "[CV] alpha=0.07773946210594596, fit_prior=True .......................\n",
            "[CV]  alpha=0.07773946210594596, fit_prior=True, score=0.954, total=   0.1s\n",
            "[CV] alpha=0.07773946210594596, fit_prior=True .......................\n",
            "[CV]  alpha=0.07773946210594596, fit_prior=True, score=0.956, total=   0.1s\n",
            "[CV] alpha=0.07773946210594596, fit_prior=False ......................\n",
            "[CV]  alpha=0.07773946210594596, fit_prior=False, score=0.956, total=   0.1s\n",
            "[CV] alpha=0.07773946210594596, fit_prior=False ......................\n",
            "[CV]  alpha=0.07773946210594596, fit_prior=False, score=0.952, total=   0.1s\n",
            "[CV] alpha=0.07773946210594596, fit_prior=False ......................\n",
            "[CV]  alpha=0.07773946210594596, fit_prior=False, score=0.938, total=   0.1s\n",
            "[CV] alpha=0.07773946210594596, fit_prior=False ......................\n",
            "[CV]  alpha=0.07773946210594596, fit_prior=False, score=0.952, total=   0.1s\n",
            "[CV] alpha=0.07773946210594596, fit_prior=False ......................\n",
            "[CV]  alpha=0.07773946210594596, fit_prior=False, score=0.954, total=   0.1s\n",
            "[CV] alpha=0.958369135322628, fit_prior=True .........................\n",
            "[CV]  alpha=0.958369135322628, fit_prior=True, score=0.931, total=   0.1s\n",
            "[CV] alpha=0.958369135322628, fit_prior=True .........................\n",
            "[CV]  alpha=0.958369135322628, fit_prior=True, score=0.942, total=   0.1s\n",
            "[CV] alpha=0.958369135322628, fit_prior=True .........................\n",
            "[CV]  alpha=0.958369135322628, fit_prior=True, score=0.925, total=   0.1s\n",
            "[CV] alpha=0.958369135322628, fit_prior=True .........................\n",
            "[CV]  alpha=0.958369135322628, fit_prior=True, score=0.942, total=   0.1s\n",
            "[CV] alpha=0.958369135322628, fit_prior=True .........................\n",
            "[CV]  alpha=0.958369135322628, fit_prior=True, score=0.942, total=   0.1s\n",
            "[CV] alpha=0.958369135322628, fit_prior=False ........................\n",
            "[CV]  alpha=0.958369135322628, fit_prior=False, score=0.935, total=   0.1s\n",
            "[CV] alpha=0.958369135322628, fit_prior=False ........................\n",
            "[CV]  alpha=0.958369135322628, fit_prior=False, score=0.950, total=   0.1s\n",
            "[CV] alpha=0.958369135322628, fit_prior=False ........................\n",
            "[CV]  alpha=0.958369135322628, fit_prior=False, score=0.925, total=   0.1s\n",
            "[CV] alpha=0.958369135322628, fit_prior=False ........................\n",
            "[CV]  alpha=0.958369135322628, fit_prior=False, score=0.940, total=   0.1s\n",
            "[CV] alpha=0.958369135322628, fit_prior=False ........................\n",
            "[CV]  alpha=0.958369135322628, fit_prior=False, score=0.942, total=   0.1s\n",
            "[CV] alpha=0.8894976694730933, fit_prior=True ........................\n",
            "[CV]  alpha=0.8894976694730933, fit_prior=True, score=0.935, total=   0.1s\n",
            "[CV] alpha=0.8894976694730933, fit_prior=True ........................\n",
            "[CV]  alpha=0.8894976694730933, fit_prior=True, score=0.944, total=   0.1s\n",
            "[CV] alpha=0.8894976694730933, fit_prior=True ........................\n",
            "[CV]  alpha=0.8894976694730933, fit_prior=True, score=0.927, total=   0.1s\n",
            "[CV] alpha=0.8894976694730933, fit_prior=True ........................\n",
            "[CV]  alpha=0.8894976694730933, fit_prior=True, score=0.944, total=   0.1s\n",
            "[CV] alpha=0.8894976694730933, fit_prior=True ........................\n",
            "[CV]  alpha=0.8894976694730933, fit_prior=True, score=0.942, total=   0.1s\n",
            "[CV] alpha=0.8894976694730933, fit_prior=False .......................\n",
            "[CV]  alpha=0.8894976694730933, fit_prior=False, score=0.937, total=   0.1s\n",
            "[CV] alpha=0.8894976694730933, fit_prior=False .......................\n",
            "[CV]  alpha=0.8894976694730933, fit_prior=False, score=0.950, total=   0.1s\n",
            "[CV] alpha=0.8894976694730933, fit_prior=False .......................\n",
            "[CV]  alpha=0.8894976694730933, fit_prior=False, score=0.925, total=   0.1s\n",
            "[CV] alpha=0.8894976694730933, fit_prior=False .......................\n",
            "[CV]  alpha=0.8894976694730933, fit_prior=False, score=0.940, total=   0.1s\n",
            "[CV] alpha=0.8894976694730933, fit_prior=False .......................\n",
            "[CV]  alpha=0.8894976694730933, fit_prior=False, score=0.942, total=   0.1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    8.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None,\n",
              "                                   fit_prior=True),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'alpha': array([0.27589515, 0.71306752, 0.45386414, 0.63800507, 0.9784994 ,\n",
              "       0.34270655, 0.03435042, 0.07773946, 0.95836914, 0.88949767]),\n",
              "                          'fit_prior': [True, False]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LIkiDPQysdT",
        "outputId": "fe73f1e1-afe6-4e75-8c06-6edb299703cf"
      },
      "source": [
        "grid_search_bnb.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.03435042418656198, 'fit_prior': True}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySji4wSHyvln",
        "outputId": "07da510b-3af4-428b-be26-8dffcef3ca16"
      },
      "source": [
        "grid_search_bnb.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9519230769230769"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtwBG5kvzXo9",
        "outputId": "d88ed995-f66e-4424-c7a7-583d5d8473ce"
      },
      "source": [
        "y_pred_bnb = grid_search_bnb.predict(X_test_transformed.toarray())\n",
        "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred_bnb)))\n",
        "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred_bnb)))\n",
        "print(\"f1 score: {:.2f}%\".format(100 * f1_score(y_test, y_pred_bnb)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 90.53%\n",
            "Recall: 82.69%\n",
            "f1 score: 86.43%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "kjMXZJAL6h2c",
        "outputId": "77cd1188-24ef-4db1-faa7-41aeeff55159"
      },
      "source": [
        "plot_confusion_matrix(grid_search_bnb, X_test_transformed.toarray(), y_test, cmap=plt.cm.Blues)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f5f9b143050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89Xa4bAbS-tg"
      },
      "source": [
        "###6. SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGY9TC4aTF0X",
        "outputId": "d48b0a36-107d-403f-8745-5d5d1389e466"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svc_param_grid = [{\n",
        "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "    'gamma': ['scale', 'auto'],\n",
        "    'shrinking': [True, False],\n",
        "    'tol': [1e-1, 1e-2, 1e-3, 1e-4, 1e-5],\n",
        "    'probability': [True, False]\n",
        "}]\n",
        "\n",
        "svc = SVC(random_state=42)\n",
        "grid_search_svc = GridSearchCV(svc, param_grid=svc_param_grid, cv=5, verbose=3)\n",
        "grid_search_svc.fit(X_train_transformed, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.1 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.1, score=0.983, total=   2.8s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.1 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.1, score=0.967, total=   2.6s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.1 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    5.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.1, score=0.954, total=   2.5s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.1, score=0.979, total=   2.7s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.1, score=0.969, total=   2.5s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.01, score=0.981, total=   2.7s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.01, score=0.967, total=   2.7s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.01, score=0.954, total=   2.6s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.01, score=0.979, total=   2.8s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.01, score=0.969, total=   2.6s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.001, score=0.981, total=   2.9s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.001, score=0.967, total=   2.8s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.001, score=0.954, total=   2.9s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.001, score=0.979, total=   3.0s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.001, score=0.969, total=   2.7s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.0001, score=0.981, total=   3.0s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.0001, score=0.967, total=   3.0s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.0001, score=0.954, total=   3.2s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.0001, score=0.979, total=   3.3s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=True, tol=0.0001, score=0.969, total=   2.8s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=True, tol=1e-05, score=0.981, total=   3.2s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=True, tol=1e-05, score=0.967, total=   3.3s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=True, tol=1e-05, score=0.954, total=   3.5s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=True, tol=1e-05, score=0.979, total=   3.6s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=True, tol=1e-05, score=0.969, total=   3.0s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.1, score=0.983, total=   3.1s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.1, score=0.967, total=   3.2s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.1, score=0.954, total=   3.5s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.1, score=0.979, total=   3.6s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.1, score=0.969, total=   2.8s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.01, score=0.981, total=   3.6s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.01, score=0.967, total=   3.9s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.01, score=0.954, total=   4.4s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.01, score=0.979, total=   4.4s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.01, score=0.969, total=   3.3s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.001, score=0.981, total=   4.1s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.001, score=0.967, total=   4.6s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.001, score=0.954, total=   5.6s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.001, score=0.979, total=   5.3s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.001, score=0.969, total=   3.8s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.0001, score=0.981, total=   4.6s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.0001, score=0.967, total=   5.3s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.0001, score=0.954, total=   6.9s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.0001, score=0.979, total=   6.3s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=False, tol=0.0001, score=0.969, total=   4.3s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=False, tol=1e-05, score=0.981, total=   5.1s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=False, tol=1e-05, score=0.967, total=   6.1s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=False, tol=1e-05, score=0.954, total=   8.1s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=False, tol=1e-05, score=0.979, total=   7.2s\n",
            "[CV] gamma=scale, kernel=linear, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=linear, probability=True, shrinking=False, tol=1e-05, score=0.969, total=   4.8s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.1, score=0.983, total=   0.6s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.1, score=0.967, total=   0.6s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.1, score=0.954, total=   0.5s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.1, score=0.979, total=   0.6s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.1, score=0.969, total=   0.5s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.01, score=0.981, total=   0.6s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.01, score=0.967, total=   0.6s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.01, score=0.954, total=   0.5s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.01, score=0.979, total=   0.6s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.01, score=0.969, total=   0.5s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.001, score=0.981, total=   0.7s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.001, score=0.967, total=   0.6s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.001, score=0.954, total=   0.6s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.001, score=0.979, total=   0.6s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.001, score=0.969, total=   0.6s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.0001, score=0.981, total=   0.7s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.0001, score=0.967, total=   0.7s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.0001, score=0.954, total=   0.7s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.0001, score=0.979, total=   0.7s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=True, tol=0.0001, score=0.969, total=   0.6s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=True, tol=1e-05, score=0.981, total=   0.7s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=True, tol=1e-05, score=0.967, total=   0.7s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=True, tol=1e-05, score=0.954, total=   0.8s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=True, tol=1e-05, score=0.979, total=   0.7s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=True, tol=1e-05, score=0.969, total=   0.6s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.1, score=0.983, total=   0.6s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.1, score=0.967, total=   0.6s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.1, score=0.954, total=   0.6s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.1, score=0.979, total=   0.7s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.1, score=0.969, total=   0.6s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.01, score=0.981, total=   0.7s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.01, score=0.967, total=   0.8s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.01, score=0.954, total=   0.7s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.01, score=0.979, total=   0.8s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.01, score=0.969, total=   0.6s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.001, score=0.981, total=   0.8s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.001, score=0.967, total=   0.8s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.001, score=0.954, total=   0.9s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.001, score=0.979, total=   1.0s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.001, score=0.969, total=   0.7s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.0001, score=0.981, total=   0.8s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.0001, score=0.967, total=   0.9s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.0001, score=0.954, total=   1.2s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.0001, score=0.979, total=   1.2s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=False, tol=0.0001, score=0.969, total=   0.7s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=False, tol=1e-05, score=0.981, total=   0.9s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=False, tol=1e-05, score=0.967, total=   1.1s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=False, tol=1e-05, score=0.954, total=   1.5s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=False, tol=1e-05, score=0.979, total=   1.3s\n",
            "[CV] gamma=scale, kernel=linear, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=linear, probability=False, shrinking=False, tol=1e-05, score=0.969, total=   0.8s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.1, score=0.848, total=   6.1s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.1, score=0.856, total=   5.9s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.1, score=0.850, total=   5.5s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.1, score=0.852, total=   6.1s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.1, score=0.856, total=   6.2s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.01, score=0.848, total=   6.7s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.01, score=0.856, total=   6.6s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.01, score=0.850, total=   6.3s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.01, score=0.854, total=   6.7s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.01, score=0.854, total=   6.5s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.001, score=0.848, total=   7.0s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.001, score=0.856, total=   7.0s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.001, score=0.850, total=   6.5s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.001, score=0.854, total=   7.0s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.001, score=0.854, total=   7.3s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.0001, score=0.848, total=   7.1s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.0001, score=0.856, total=   7.0s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.0001, score=0.850, total=   6.6s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.0001, score=0.854, total=   7.0s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=True, tol=0.0001, score=0.854, total=   7.3s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=True, tol=1e-05, score=0.848, total=   7.0s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=True, tol=1e-05, score=0.850, total=   6.7s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=True, tol=1e-05, score=0.854, total=   7.0s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=True, tol=1e-05, score=0.854, total=   7.4s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.1, score=0.848, total=   6.1s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.1, score=0.856, total=   5.9s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.1, score=0.850, total=   5.5s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.1, score=0.852, total=   6.1s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.1, score=0.856, total=   6.2s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.01, score=0.848, total=   6.7s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.01, score=0.856, total=   6.5s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.01, score=0.850, total=   6.2s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.01, score=0.854, total=   6.6s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.01, score=0.854, total=   6.4s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.001, score=0.848, total=   6.9s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.001, score=0.856, total=   6.8s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.001, score=0.850, total=   6.5s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.001, score=0.854, total=   6.9s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.001, score=0.854, total=   7.2s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.0001, score=0.848, total=   7.0s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.0001, score=0.856, total=   7.0s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.0001, score=0.850, total=   6.6s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.0001, score=0.854, total=   7.0s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=False, tol=0.0001, score=0.854, total=   7.4s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=False, tol=1e-05, score=0.848, total=   7.1s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=False, tol=1e-05, score=0.856, total=   7.0s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=False, tol=1e-05, score=0.850, total=   6.7s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=False, tol=1e-05, score=0.854, total=   7.1s\n",
            "[CV] gamma=scale, kernel=poly, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=poly, probability=True, shrinking=False, tol=1e-05, score=0.854, total=   7.4s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.1, score=0.848, total=   1.1s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.1, score=0.856, total=   1.1s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.1, score=0.850, total=   1.1s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.1, score=0.852, total=   1.1s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.1, score=0.856, total=   1.1s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.01, score=0.848, total=   1.5s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.01, score=0.856, total=   1.3s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.01, score=0.850, total=   1.3s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.01, score=0.854, total=   1.4s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.01, score=0.854, total=   1.2s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.001, score=0.848, total=   1.5s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.001, score=0.856, total=   1.5s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.001, score=0.850, total=   1.4s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.001, score=0.854, total=   1.5s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.001, score=0.854, total=   1.6s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.0001, score=0.848, total=   1.5s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.0001, score=0.856, total=   1.5s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.0001, score=0.850, total=   1.4s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.0001, score=0.854, total=   1.6s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=True, tol=0.0001, score=0.854, total=   1.6s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=True, tol=1e-05, score=0.848, total=   1.6s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=True, tol=1e-05, score=0.856, total=   1.6s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=True, tol=1e-05, score=0.850, total=   1.4s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=True, tol=1e-05, score=0.854, total=   1.6s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=True, tol=1e-05, score=0.854, total=   1.7s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.1, score=0.848, total=   1.2s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.1, score=0.856, total=   1.2s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.1, score=0.850, total=   1.1s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.1, score=0.852, total=   1.1s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.1, score=0.856, total=   1.1s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.01, score=0.848, total=   1.5s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.01, score=0.856, total=   1.3s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.01, score=0.850, total=   1.3s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.01, score=0.854, total=   1.4s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.01, score=0.854, total=   1.2s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.001, score=0.848, total=   1.6s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.001, score=0.856, total=   1.5s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.001, score=0.850, total=   1.4s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.001, score=0.854, total=   1.6s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.001, score=0.854, total=   1.6s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.0001, score=0.848, total=   1.6s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.0001, score=0.856, total=   1.6s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.0001, score=0.850, total=   1.4s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.0001, score=0.854, total=   1.6s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=False, tol=0.0001, score=0.854, total=   1.6s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=False, tol=1e-05, score=0.848, total=   1.6s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=False, tol=1e-05, score=0.856, total=   1.6s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=False, tol=1e-05, score=0.850, total=   1.4s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=False, tol=1e-05, score=0.854, total=   1.6s\n",
            "[CV] gamma=scale, kernel=poly, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=poly, probability=False, shrinking=False, tol=1e-05, score=0.854, total=   1.7s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.1, score=0.848, total=   6.1s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.1, score=0.852, total=   6.3s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.1, score=0.860, total=   6.1s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.1, score=0.854, total=   6.1s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.1, score=0.854, total=   6.3s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.01, score=0.848, total=   6.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.01, score=0.852, total=   6.6s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.01, score=0.860, total=   6.4s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.01, score=0.854, total=   6.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.01, score=0.854, total=   6.7s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.001, score=0.848, total=   6.6s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.001, score=0.852, total=   6.6s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.001, score=0.860, total=   6.4s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.001, score=0.854, total=   6.6s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.001, score=0.854, total=   6.8s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.0001, score=0.848, total=   6.7s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.0001, score=0.852, total=   6.7s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.0001, score=0.860, total=   6.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.0001, score=0.854, total=   6.6s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=0.0001, score=0.854, total=   6.8s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=1e-05, score=0.848, total=   6.7s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=1e-05, score=0.852, total=   6.7s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=1e-05, score=0.860, total=   6.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=1e-05, score=0.854, total=   6.6s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=True, tol=1e-05, score=0.854, total=   6.8s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.1, score=0.848, total=   6.1s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.1, score=0.852, total=   6.2s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.1, score=0.860, total=   6.2s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.1, score=0.854, total=   6.1s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.1, score=0.854, total=   6.3s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.01, score=0.848, total=   6.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.01, score=0.852, total=   6.6s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.01, score=0.860, total=   6.4s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.01, score=0.854, total=   6.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.01, score=0.854, total=   6.7s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.001, score=0.848, total=   6.7s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.001, score=0.852, total=   6.8s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.001, score=0.860, total=   6.6s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.001, score=0.854, total=   6.8s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.001, score=0.854, total=   6.9s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.0001, score=0.848, total=   6.7s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.0001, score=0.852, total=   6.7s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.0001, score=0.860, total=   6.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.0001, score=0.854, total=   6.7s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=0.0001, score=0.854, total=   6.9s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=1e-05, score=0.848, total=   6.7s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=1e-05, score=0.852, total=   6.7s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=1e-05, score=0.860, total=   6.6s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=1e-05, score=0.854, total=   6.7s\n",
            "[CV] gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=True, shrinking=False, tol=1e-05, score=0.854, total=   6.8s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.1, score=0.848, total=   1.3s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.1, score=0.852, total=   1.4s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.1, score=0.860, total=   1.4s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.1, score=0.854, total=   1.4s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.1, score=0.854, total=   1.4s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.01, score=0.848, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.01, score=0.852, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.01, score=0.860, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.01, score=0.854, total=   1.4s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.01, score=0.854, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.001, score=0.848, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.001, score=0.852, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.001, score=0.860, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.001, score=0.854, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.001, score=0.854, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.0001, score=0.848, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.0001, score=0.852, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.0001, score=0.860, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.0001, score=0.854, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=0.0001, score=0.854, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=1e-05, score=0.848, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=1e-05, score=0.852, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=1e-05, score=0.860, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=1e-05, score=0.854, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=True, tol=1e-05, score=0.854, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.1, score=0.848, total=   1.3s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.1, score=0.852, total=   1.4s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.1, score=0.860, total=   1.4s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.1, score=0.854, total=   1.4s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.1, score=0.854, total=   1.4s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.01, score=0.848, total=   1.4s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.01, score=0.852, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.01, score=0.860, total=   1.4s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.01, score=0.854, total=   1.4s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.01, score=0.854, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.001, score=0.848, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.001, score=0.852, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.001, score=0.860, total=   1.4s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.001, score=0.854, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.001, score=0.854, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.0001, score=0.848, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.0001, score=0.852, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.0001, score=0.860, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.0001, score=0.854, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=0.0001, score=0.854, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=1e-05, score=0.848, total=   1.4s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=1e-05, score=0.852, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=1e-05, score=0.860, total=   1.4s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=1e-05, score=0.854, total=   1.5s\n",
            "[CV] gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=rbf, probability=False, shrinking=False, tol=1e-05, score=0.854, total=   1.5s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.1, score=0.850, total=   4.8s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.1, score=0.850, total=   4.9s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.1, score=0.858, total=   5.1s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.1, score=0.854, total=   6.2s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.1, score=0.846, total=   4.8s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.01, score=0.850, total=   4.8s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.01, score=0.850, total=   4.9s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.01, score=0.858, total=   5.2s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.01, score=0.854, total=   6.3s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.01, score=0.846, total=   4.9s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.001, score=0.850, total=   4.9s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.001, score=0.850, total=   4.9s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.001, score=0.858, total=   5.2s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.001, score=0.854, total=   6.3s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.001, score=0.846, total=   4.9s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.0001, score=0.850, total=   4.8s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.0001, score=0.850, total=   4.9s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.0001, score=0.858, total=   5.2s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.0001, score=0.854, total=   6.4s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=0.0001, score=0.846, total=   4.9s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=1e-05, score=0.850, total=   4.9s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=1e-05, score=0.850, total=   4.9s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=1e-05, score=0.858, total=   5.2s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=1e-05, score=0.854, total=   6.3s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=True, tol=1e-05, score=0.846, total=   4.9s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.1, score=0.850, total=   4.8s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.1, score=0.850, total=   4.9s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.1, score=0.858, total=   5.1s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.1, score=0.854, total=   6.3s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.1, score=0.846, total=   4.9s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.01, score=0.850, total=   4.9s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.01, score=0.850, total=   4.9s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.01, score=0.858, total=   5.2s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.01, score=0.846, total=   4.9s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.001, score=0.850, total=   4.9s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.001, score=0.850, total=   4.9s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.001, score=0.858, total=   5.2s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.001, score=0.854, total=   6.4s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.001, score=0.846, total=   4.9s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.0001, score=0.850, total=   4.9s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.0001, score=0.850, total=   4.9s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.0001, score=0.858, total=   5.2s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.0001, score=0.854, total=   6.3s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=0.0001, score=0.846, total=   4.9s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=1e-05, score=0.850, total=   4.8s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=1e-05, score=0.850, total=   4.9s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=1e-05, score=0.858, total=   5.2s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=1e-05, score=0.854, total=   6.3s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=True, shrinking=False, tol=1e-05, score=0.846, total=   4.9s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.1, score=0.850, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.1, score=0.850, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.1, score=0.858, total=   1.5s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.1, score=0.854, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.1, score=0.846, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.01, score=0.850, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.01, score=0.850, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.01, score=0.858, total=   1.5s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.01, score=0.854, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.01, score=0.846, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.001, score=0.850, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.001, score=0.850, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.001, score=0.858, total=   1.5s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.001, score=0.854, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.001, score=0.846, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.0001, score=0.850, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.0001, score=0.850, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.0001, score=0.858, total=   1.5s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.0001, score=0.854, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=0.0001, score=0.846, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=1e-05, score=0.850, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=1e-05, score=0.850, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=1e-05, score=0.858, total=   1.5s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=1e-05, score=0.854, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=True, tol=1e-05, score=0.846, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.1, score=0.850, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.1, score=0.850, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.1, score=0.858, total=   1.5s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.1, score=0.854, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.1, score=0.846, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.01, score=0.850, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.01, score=0.850, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.01, score=0.858, total=   1.5s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.01, score=0.854, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.01, score=0.846, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.001, score=0.850, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.001, score=0.850, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.001, score=0.858, total=   1.5s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.001, score=0.854, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.001, score=0.846, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.0001, score=0.850, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.0001, score=0.850, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.0001, score=0.858, total=   1.5s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.0001, score=0.854, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=0.0001, score=0.846, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=1e-05, score=0.850, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=1e-05, score=0.850, total=   1.7s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=1e-05, score=0.858, total=   1.5s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=1e-05, score=0.854, total=   1.6s\n",
            "[CV] gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=scale, kernel=sigmoid, probability=False, shrinking=False, tol=1e-05, score=0.846, total=   1.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.1, score=0.983, total=   2.8s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.1, score=0.967, total=   2.5s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.1, score=0.954, total=   2.5s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.1, score=0.979, total=   2.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.1, score=0.969, total=   2.5s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.01, score=0.981, total=   2.8s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.01, score=0.967, total=   2.7s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.01, score=0.954, total=   2.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.01, score=0.979, total=   2.8s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.01, score=0.969, total=   2.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.001, score=0.981, total=   2.9s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.001, score=0.967, total=   2.8s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.001, score=0.954, total=   2.9s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.001, score=0.979, total=   3.0s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.001, score=0.969, total=   2.7s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.0001, score=0.981, total=   3.0s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.0001, score=0.967, total=   3.0s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.0001, score=0.954, total=   3.2s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.0001, score=0.979, total=   3.3s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=True, tol=0.0001, score=0.969, total=   2.8s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=True, tol=1e-05, score=0.981, total=   3.2s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=True, tol=1e-05, score=0.967, total=   3.2s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=True, tol=1e-05, score=0.954, total=   3.5s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=True, tol=1e-05, score=0.979, total=   3.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=True, tol=1e-05, score=0.969, total=   3.0s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.1, score=0.983, total=   3.1s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.1, score=0.967, total=   3.2s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.1, score=0.954, total=   3.5s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.1, score=0.979, total=   3.5s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.1, score=0.969, total=   2.8s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.01, score=0.981, total=   3.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.01, score=0.967, total=   3.9s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.01, score=0.954, total=   4.4s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.01, score=0.979, total=   4.4s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.01, score=0.969, total=   3.3s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.001, score=0.981, total=   4.1s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.001, score=0.967, total=   4.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.001, score=0.954, total=   5.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.001, score=0.979, total=   5.3s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.001, score=0.969, total=   3.8s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.0001, score=0.981, total=   4.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.0001, score=0.967, total=   5.3s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.0001, score=0.954, total=   6.9s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.0001, score=0.979, total=   6.2s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=False, tol=0.0001, score=0.969, total=   4.2s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=False, tol=1e-05, score=0.981, total=   5.1s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=False, tol=1e-05, score=0.967, total=   6.2s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=False, tol=1e-05, score=0.954, total=   8.2s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=False, tol=1e-05, score=0.979, total=   7.2s\n",
            "[CV] gamma=auto, kernel=linear, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=linear, probability=True, shrinking=False, tol=1e-05, score=0.969, total=   4.8s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.1, score=0.983, total=   0.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.1, score=0.967, total=   0.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.1, score=0.954, total=   0.5s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.1, score=0.979, total=   0.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.1, score=0.969, total=   0.5s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.01, score=0.981, total=   0.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.01, score=0.967, total=   0.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.01, score=0.954, total=   0.5s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.01, score=0.979, total=   0.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.01, score=0.969, total=   0.5s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.001, score=0.981, total=   0.7s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.001, score=0.967, total=   0.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.001, score=0.954, total=   0.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.001, score=0.979, total=   0.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.001, score=0.969, total=   0.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.0001, score=0.981, total=   0.7s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.0001, score=0.967, total=   0.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.0001, score=0.954, total=   0.7s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.0001, score=0.979, total=   0.7s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=True, tol=0.0001, score=0.969, total=   0.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=True, tol=1e-05, score=0.981, total=   0.7s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=True, tol=1e-05, score=0.967, total=   0.7s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=True, tol=1e-05, score=0.954, total=   0.8s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=True, tol=1e-05, score=0.979, total=   0.7s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=True, tol=1e-05, score=0.969, total=   0.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.1, score=0.983, total=   0.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.1, score=0.967, total=   0.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.1, score=0.954, total=   0.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.1, score=0.979, total=   0.7s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.1, score=0.969, total=   0.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.01, score=0.981, total=   0.7s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.01, score=0.967, total=   0.7s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.01, score=0.954, total=   0.7s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.01, score=0.979, total=   0.8s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.01, score=0.969, total=   0.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.001, score=0.981, total=   0.8s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.001, score=0.967, total=   0.8s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.001, score=0.954, total=   0.9s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.001, score=0.979, total=   1.0s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.001, score=0.969, total=   0.6s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.0001, score=0.981, total=   0.8s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.0001, score=0.967, total=   0.9s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.0001, score=0.954, total=   1.2s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.0001, score=0.979, total=   1.2s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=False, tol=0.0001, score=0.969, total=   0.7s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=False, tol=1e-05, score=0.981, total=   0.9s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=False, tol=1e-05, score=0.967, total=   1.1s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=False, tol=1e-05, score=0.954, total=   1.4s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=False, tol=1e-05, score=0.979, total=   1.3s\n",
            "[CV] gamma=auto, kernel=linear, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=linear, probability=False, shrinking=False, tol=1e-05, score=0.969, total=   0.7s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.1, score=0.931, total=   4.2s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.1, score=0.906, total=   4.5s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.1, score=0.898, total=   4.4s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.1, score=0.929, total=   4.6s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.1, score=0.913, total=   4.2s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.01, score=0.931, total=   4.3s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.01, score=0.906, total=   4.6s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.01, score=0.898, total=   4.6s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.01, score=0.929, total=   4.8s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.01, score=0.913, total=   4.3s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.001, score=0.931, total=   4.3s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.001, score=0.906, total=   4.8s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.001, score=0.898, total=   4.6s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.001, score=0.929, total=   4.9s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.001, score=0.913, total=   4.4s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.0001, score=0.931, total=   4.4s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.0001, score=0.906, total=   4.9s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.0001, score=0.898, total=   4.7s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.0001, score=0.929, total=   5.1s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=True, tol=0.0001, score=0.913, total=   4.4s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=True, tol=1e-05, score=0.931, total=   4.4s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=True, tol=1e-05, score=0.906, total=   5.1s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=True, tol=1e-05, score=0.898, total=   4.9s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=True, tol=1e-05, score=0.929, total=   5.3s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=True, tol=1e-05, score=0.913, total=   4.5s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.1, score=0.931, total=   4.6s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.1, score=0.906, total=   5.5s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.1, score=0.898, total=   5.3s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.1, score=0.929, total=   6.0s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.1, score=0.913, total=   4.4s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.01, score=0.931, total=   4.9s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.01, score=0.906, total=   6.4s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.01, score=0.898, total=   6.0s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.01, score=0.929, total=   7.0s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.01, score=0.913, total=   4.8s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.001, score=0.931, total=   5.2s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.001, score=0.906, total=   7.3s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.001, score=0.898, total=   6.9s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.001, score=0.929, total=   8.4s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.001, score=0.913, total=   5.0s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.0001, score=0.931, total=   5.4s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.0001, score=0.906, total=   8.3s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.0001, score=0.898, total=   7.5s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.0001, score=0.929, total=   9.6s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=False, tol=0.0001, score=0.913, total=   5.3s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=False, tol=1e-05, score=0.931, total=   5.7s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=False, tol=1e-05, score=0.906, total=   9.2s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=False, tol=1e-05, score=0.898, total=   8.2s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=False, tol=1e-05, score=0.929, total=  10.9s\n",
            "[CV] gamma=auto, kernel=poly, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=poly, probability=True, shrinking=False, tol=1e-05, score=0.913, total=   5.5s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.1, score=0.931, total=   1.0s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.1, score=0.906, total=   1.2s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.1, score=0.898, total=   1.1s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.1, score=0.929, total=   1.2s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.1, score=0.913, total=   1.0s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.01, score=0.931, total=   1.0s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.01, score=0.906, total=   1.2s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.01, score=0.898, total=   1.1s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.01, score=0.929, total=   1.2s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.01, score=0.913, total=   1.1s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.001, score=0.931, total=   1.0s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.001, score=0.906, total=   1.3s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.001, score=0.898, total=   1.2s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.001, score=0.929, total=   1.3s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.001, score=0.913, total=   1.1s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.0001, score=0.931, total=   1.0s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.0001, score=0.906, total=   1.3s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.0001, score=0.898, total=   1.2s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.0001, score=0.929, total=   1.4s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=True, tol=0.0001, score=0.913, total=   1.1s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=True, tol=1e-05, score=0.931, total=   1.0s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=True, tol=1e-05, score=0.906, total=   1.4s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=True, tol=1e-05, score=0.898, total=   1.2s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=True, tol=1e-05, score=0.929, total=   1.4s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=True, tol=1e-05, score=0.913, total=   1.1s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.1, score=0.931, total=   1.0s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.1, score=0.906, total=   1.7s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.1, score=0.898, total=   1.6s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.1, score=0.929, total=   1.9s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.1, score=0.913, total=   1.1s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.01, score=0.931, total=   1.1s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.01, score=0.906, total=   2.0s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.01, score=0.898, total=   1.9s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.01, score=0.929, total=   2.3s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.01, score=0.913, total=   1.2s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.001, score=0.931, total=   1.2s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.001, score=0.906, total=   2.4s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.001, score=0.898, total=   2.2s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.001, score=0.929, total=   2.8s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.001, score=0.913, total=   1.3s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.0001, score=0.931, total=   1.2s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.0001, score=0.906, total=   2.7s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.0001, score=0.898, total=   2.5s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.0001, score=0.929, total=   3.1s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=False, tol=0.0001, score=0.913, total=   1.3s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=False, tol=1e-05, score=0.931, total=   1.3s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=False, tol=1e-05, score=0.906, total=   3.0s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=False, tol=1e-05, score=0.898, total=   2.8s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=False, tol=1e-05, score=0.929, total=   3.6s\n",
            "[CV] gamma=auto, kernel=poly, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=poly, probability=False, shrinking=False, tol=1e-05, score=0.913, total=   1.4s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.1, score=0.948, total=   6.9s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.1, score=0.942, total=   6.9s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.1, score=0.958, total=   6.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.1, score=0.952, total=   7.0s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.1, score=0.938, total=   7.2s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.01, score=0.948, total=   7.5s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.01, score=0.942, total=   7.4s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.01, score=0.958, total=   7.3s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.01, score=0.952, total=   7.5s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.01, score=0.938, total=   7.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.001, score=0.948, total=   7.6s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.001, score=0.942, total=   7.5s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.001, score=0.958, total=   7.3s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.001, score=0.952, total=   7.6s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.001, score=0.938, total=   7.8s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.0001, score=0.948, total=   7.6s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.0001, score=0.942, total=   7.5s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.0001, score=0.958, total=   7.5s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.0001, score=0.952, total=   7.6s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=0.0001, score=0.938, total=   8.0s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=1e-05, score=0.948, total=   7.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=1e-05, score=0.942, total=   7.6s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=1e-05, score=0.958, total=   7.4s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=1e-05, score=0.952, total=   7.6s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=True, tol=1e-05, score=0.938, total=   7.9s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.1, score=0.948, total=   6.9s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.1, score=0.942, total=   6.8s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.1, score=0.958, total=   6.8s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.1, score=0.952, total=   6.9s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.1, score=0.938, total=   7.1s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.01, score=0.948, total=   7.5s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.01, score=0.942, total=   7.4s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.01, score=0.958, total=   7.3s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.01, score=0.952, total=   7.5s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.01, score=0.938, total=   7.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.001, score=0.948, total=   7.5s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.001, score=0.942, total=   7.4s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.001, score=0.958, total=   7.3s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.001, score=0.952, total=   7.5s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.001, score=0.938, total=   7.8s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.0001, score=0.948, total=   7.6s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.0001, score=0.942, total=   7.4s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.0001, score=0.958, total=   7.3s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.0001, score=0.952, total=   7.6s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=0.0001, score=0.938, total=   7.8s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=1e-05, score=0.948, total=   7.6s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=1e-05, score=0.942, total=   7.5s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=1e-05, score=0.958, total=   7.3s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=1e-05, score=0.952, total=   7.6s\n",
            "[CV] gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=True, shrinking=False, tol=1e-05, score=0.938, total=   7.8s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.1, score=0.948, total=   1.6s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.1, score=0.942, total=   1.5s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.1, score=0.958, total=   1.5s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.1, score=0.952, total=   1.6s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.1, score=0.938, total=   1.6s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.01, score=0.948, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.01, score=0.942, total=   1.6s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.01, score=0.958, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.01, score=0.952, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.01, score=0.938, total=   1.8s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.001, score=0.948, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.001, score=0.942, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.001, score=0.958, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.001, score=0.952, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.001, score=0.938, total=   1.8s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.0001, score=0.948, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.0001, score=0.942, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.0001, score=0.958, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.0001, score=0.952, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=0.0001, score=0.938, total=   1.8s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=1e-05, score=0.948, total=   1.8s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=1e-05, score=0.942, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=1e-05, score=0.958, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=1e-05, score=0.952, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=True, tol=1e-05, score=0.938, total=   1.8s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.1, score=0.948, total=   1.6s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.1, score=0.942, total=   1.5s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.1, score=0.958, total=   1.5s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.1, score=0.952, total=   1.6s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.1, score=0.938, total=   1.6s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.01, score=0.948, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.01, score=0.942, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.01, score=0.958, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.01, score=0.952, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.01, score=0.938, total=   1.8s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.001, score=0.948, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.001, score=0.942, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.001, score=0.958, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.001, score=0.952, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.001, score=0.938, total=   1.8s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.0001, score=0.948, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.0001, score=0.942, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.0001, score=0.958, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.0001, score=0.952, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=0.0001, score=0.938, total=   1.8s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=1e-05, score=0.948, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=1e-05, score=0.942, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=1e-05, score=0.958, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=1e-05, score=0.952, total=   1.7s\n",
            "[CV] gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=rbf, probability=False, shrinking=False, tol=1e-05, score=0.938, total=   1.8s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.1, score=0.740, total=   4.6s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.1, score=0.756, total=   4.7s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.1, score=0.719, total=   4.6s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.1, score=0.740, total=   5.5s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.1, score=0.802, total=   5.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.01, score=0.740, total=   4.6s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.01, score=0.756, total=   4.7s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.01, score=0.719, total=   4.7s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.01, score=0.740, total=   5.5s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.01, score=0.802, total=   5.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.001, score=0.740, total=   4.6s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.001, score=0.756, total=   4.7s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.001, score=0.719, total=   4.7s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.001, score=0.740, total=   5.5s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.001, score=0.802, total=   5.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.0001, score=0.740, total=   4.6s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.0001, score=0.756, total=   4.7s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.0001, score=0.719, total=   4.7s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.0001, score=0.740, total=   5.5s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=0.0001, score=0.802, total=   5.4s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=1e-05, score=0.740, total=   4.6s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=1e-05, score=0.756, total=   4.7s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=1e-05, score=0.719, total=   4.7s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=1e-05, score=0.740, total=   5.5s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=True, tol=1e-05, score=0.802, total=   5.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.1, score=0.740, total=   4.6s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.1, score=0.756, total=   4.7s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.1, score=0.719, total=   4.6s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.1, score=0.740, total=   5.5s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.1, score=0.802, total=   5.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.01, score=0.740, total=   4.6s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.01, score=0.756, total=   4.7s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.01, score=0.719, total=   4.7s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.01, score=0.740, total=   5.5s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.01, score=0.802, total=   5.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.001, score=0.740, total=   4.6s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.001, score=0.756, total=   4.7s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.001, score=0.719, total=   4.7s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.001, score=0.740, total=   5.5s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.001, score=0.802, total=   5.4s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.0001, score=0.740, total=   4.6s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.0001, score=0.756, total=   4.7s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.0001, score=0.719, total=   4.7s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.0001, score=0.740, total=   5.5s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=0.0001, score=0.802, total=   5.4s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=1e-05, score=0.740, total=   4.6s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=1e-05, score=0.756, total=   4.7s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=1e-05, score=0.719, total=   4.7s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=1e-05, score=0.740, total=   5.5s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=True, shrinking=False, tol=1e-05, score=0.802, total=   5.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.1, score=0.740, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.1, score=0.756, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.1, score=0.719, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.1, score=0.740, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.1, score=0.802, total=   0.9s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.01, score=0.740, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.01, score=0.756, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.01, score=0.719, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.01, score=0.740, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.01, score=0.802, total=   0.9s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.001, score=0.740, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.001, score=0.756, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.001, score=0.719, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.001, score=0.740, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.001, score=0.802, total=   1.0s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.0001, score=0.740, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.0001, score=0.756, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.0001, score=0.719, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.0001, score=0.740, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=0.0001, score=0.802, total=   1.0s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=1e-05, score=0.740, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=1e-05, score=0.756, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=1e-05, score=0.719, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=1e-05, score=0.740, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=True, tol=1e-05, score=0.802, total=   1.0s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.1, score=0.740, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.1, score=0.756, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.1, score=0.719, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.1, score=0.740, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.1 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.1, score=0.802, total=   1.0s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.01, score=0.740, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.01, score=0.756, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.01, score=0.719, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.01, score=0.740, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.01 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.01, score=0.802, total=   0.9s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.001, score=0.740, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.001, score=0.756, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.001, score=0.719, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.001, score=0.740, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.001, score=0.802, total=   1.0s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.0001, score=0.740, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.0001, score=0.756, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.0001, score=0.719, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.0001, score=0.740, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.0001 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=0.0001, score=0.802, total=   1.0s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=1e-05, score=0.740, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=1e-05, score=0.756, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=1e-05, score=0.719, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=1e-05, score=0.740, total=   1.3s\n",
            "[CV] gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=1e-05 \n",
            "[CV]  gamma=auto, kernel=sigmoid, probability=False, shrinking=False, tol=1e-05, score=0.802, total=   1.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 800 out of 800 | elapsed: 45.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=42, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'gamma': ['scale', 'auto'],\n",
              "                          'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
              "                          'probability': [True, False],\n",
              "                          'shrinking': [True, False],\n",
              "                          'tol': [0.1, 0.01, 0.001, 0.0001, 1e-05]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztEF8yp8pFa_",
        "outputId": "9e121e2d-64bd-4c3f-8a8d-b03c7a0fbdc8"
      },
      "source": [
        "grid_search_svc.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'gamma': 'scale',\n",
              " 'kernel': 'linear',\n",
              " 'probability': True,\n",
              " 'shrinking': True,\n",
              " 'tol': 0.1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfgNIADjpWO2",
        "outputId": "c00dede9-4526-4f7a-b34f-c6db91ebbd05"
      },
      "source": [
        "grid_search_svc.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9703846153846154"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPGbPBv3p26P",
        "outputId": "f8bc9647-72d1-40af-f89f-68f3282b2420"
      },
      "source": [
        "y_pred_svc = grid_search_svc.predict(X_test_transformed.toarray())\n",
        "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred_svc)))\n",
        "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred_svc)))\n",
        "print(\"f1 score: {:.2f}%\".format(100 * f1_score(y_test, y_pred_svc)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 88.89%\n",
            "Recall: 92.31%\n",
            "f1 score: 90.57%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "Xbzi_IWTrLXP",
        "outputId": "148191a7-e982-4c5c-bae7-1f5bb6c58be6"
      },
      "source": [
        "plot_confusion_matrix(grid_search_svc, X_test_transformed, y_test, cmap=plt.cm.Blues)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f5f9b3c3110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlOxNPhEcZQg"
      },
      "source": [
        "###7. Ensemble Methods<br>\n",
        "####1. Boosting\n",
        "Here we use the weakest model (Gaussian Naive Bayes) since stronger models will overfit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoBbkQcgcdJF",
        "outputId": "56565e4f-31e4-42e8-e96a-71a900332f4e"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "adb_param_grid = [{\n",
        "    'n_estimators': [50, 100, 150, 200, 250, 300],\n",
        "    'learning_rate': [0.0001, 0.05, 0.5, 1., 1.5, 2.],\n",
        "    'algorithm': ['SAMME', 'SAMME.R']\n",
        "}]\n",
        "\n",
        "gnb_v2 = GaussianNB()\n",
        "adaboost = AdaBoostClassifier(gnb_v2)\n",
        "grid_search_adb = GridSearchCV(adaboost, adb_param_grid, cv=5, verbose=3)\n",
        "grid_search_adb.fit(X_train_transformed.toarray(), y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=50 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=50, score=0.744, total=   3.7s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=50 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=50, score=0.779, total=   3.7s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=50 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    7.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=50, score=0.867, total=   3.7s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=50 ..........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=50, score=0.787, total=   3.7s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=50 ..........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=50, score=0.825, total=   3.7s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=100 .........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=100, score=0.744, total=   7.4s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=100 .........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=100, score=0.779, total=   7.3s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=100 .........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=100, score=0.867, total=   7.3s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=100 .........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=100, score=0.787, total=   7.3s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=100 .........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=100, score=0.825, total=   7.3s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=150 .........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=150, score=0.746, total=  11.0s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=150 .........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=150, score=0.779, total=  11.1s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=150 .........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=150, score=0.867, total=  11.2s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=150 .........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=150, score=0.787, total=  11.3s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=150 .........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=150, score=0.825, total=  11.4s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=200 .........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=200, score=0.746, total=  15.0s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=200 .........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=200, score=0.779, total=  14.9s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=200 .........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=200, score=0.867, total=  15.0s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=200 .........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=200, score=0.787, total=  14.9s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=200 .........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=200, score=0.825, total=  14.9s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=250 .........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=250, score=0.746, total=  18.3s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=250 .........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=250, score=0.779, total=  18.8s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=250 .........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=250, score=0.867, total=  19.0s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=250 .........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=250, score=0.787, total=  19.0s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=250 .........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=250, score=0.825, total=  18.7s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=300 .........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=300, score=0.746, total=  22.2s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=300 .........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=300, score=0.779, total=  22.7s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=300 .........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=300, score=0.867, total=  22.6s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=300 .........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=300, score=0.788, total=  22.6s\n",
            "[CV] algorithm=SAMME, learning_rate=0.0001, n_estimators=300 .........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.0001, n_estimators=300, score=0.825, total=  22.6s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=50 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=50, score=0.862, total=   3.8s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=50 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=50, score=0.779, total=   3.8s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=50 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=50, score=0.913, total=   3.8s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=50 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=50, score=0.896, total=   3.8s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=50 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=50, score=0.823, total=   3.8s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=100 ...........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=100, score=0.937, total=   7.7s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=100 ...........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=100, score=0.779, total=   7.7s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=100 ...........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=100, score=0.938, total=   7.7s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=100 ...........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=100, score=0.952, total=   7.7s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=100 ...........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=100, score=0.904, total=   7.8s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=150 ...........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=150, score=0.938, total=   9.4s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=150 ...........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=150, score=0.779, total=  11.6s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=150 ...........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=150, score=0.938, total=   8.4s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=150 ...........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=150, score=0.952, total=   8.3s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=150 ...........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=150, score=0.919, total=  10.2s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=200 ...........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=200, score=0.938, total=   9.2s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=200 ...........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=200, score=0.779, total=  15.2s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=200 ...........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=200, score=0.938, total=   8.3s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=200 ...........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=200, score=0.952, total=   8.2s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=200 ...........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=200, score=0.919, total=  10.3s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=250 ...........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=250, score=0.938, total=   9.2s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=250 ...........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=250, score=0.877, total=  19.0s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=250 ...........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=250, score=0.938, total=   8.2s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=250 ...........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=250, score=0.952, total=   8.1s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=250 ...........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=250, score=0.919, total=  10.1s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=300 ...........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=300, score=0.938, total=   9.2s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=300 ...........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=300, score=0.915, total=  22.5s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=300 ...........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=300, score=0.938, total=   8.0s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=300 ...........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=300, score=0.952, total=   8.1s\n",
            "[CV] algorithm=SAMME, learning_rate=0.05, n_estimators=300 ...........\n",
            "[CV]  algorithm=SAMME, learning_rate=0.05, n_estimators=300, score=0.919, total=  10.2s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=50 .............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=50, score=0.917, total=   1.1s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=50 .............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=50, score=0.915, total=   2.3s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=50 .............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=50, score=0.929, total=   3.8s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=50 .............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=50, score=0.952, total=   0.9s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=50 .............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=50, score=0.910, total=   1.0s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=100, score=0.917, total=   1.1s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=100, score=0.915, total=   2.3s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=100, score=0.929, total=   4.3s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=100, score=0.952, total=   0.9s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=100, score=0.910, total=   1.0s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=150, score=0.917, total=   1.1s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=150, score=0.915, total=   2.3s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=150, score=0.929, total=   4.3s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=150, score=0.952, total=   0.9s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=150, score=0.910, total=   1.0s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=200, score=0.917, total=   1.1s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=200, score=0.915, total=   2.3s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=200, score=0.929, total=   4.2s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=200, score=0.952, total=   0.9s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=200, score=0.910, total=   1.0s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=250, score=0.917, total=   1.1s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=250, score=0.915, total=   2.3s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=250, score=0.929, total=   4.2s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=250, score=0.952, total=   0.9s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=250, score=0.910, total=   0.9s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=300 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=300, score=0.917, total=   1.1s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=300 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=300, score=0.915, total=   2.3s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=300 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=300, score=0.929, total=   4.2s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=300 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=300, score=0.952, total=   0.9s\n",
            "[CV] algorithm=SAMME, learning_rate=0.5, n_estimators=300 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=0.5, n_estimators=300, score=0.910, total=   1.0s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=50 .............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=50, score=0.921, total=   1.0s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=50 .............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=50, score=0.946, total=   1.0s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=50 .............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=50, score=0.935, total=   1.3s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=50 .............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=50, score=0.937, total=   0.7s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=50 .............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=50, score=0.867, total=   0.5s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=100, score=0.921, total=   0.9s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=100, score=0.946, total=   1.0s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=100, score=0.935, total=   1.3s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=100, score=0.937, total=   0.7s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=100, score=0.867, total=   0.5s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=150, score=0.921, total=   1.0s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=150, score=0.946, total=   1.0s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=150, score=0.935, total=   1.3s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=150, score=0.937, total=   0.7s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=150, score=0.867, total=   0.5s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=200, score=0.921, total=   0.9s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=200, score=0.946, total=   1.0s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=200, score=0.935, total=   1.3s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=200, score=0.937, total=   0.7s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=200, score=0.867, total=   0.5s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=250, score=0.921, total=   1.0s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=250, score=0.946, total=   1.0s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=250, score=0.935, total=   1.3s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=250, score=0.937, total=   0.7s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=250, score=0.867, total=   0.5s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=300 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=300, score=0.921, total=   0.9s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=300 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=300, score=0.946, total=   1.0s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=300 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=300, score=0.935, total=   1.3s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=300 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=300, score=0.937, total=   0.7s\n",
            "[CV] algorithm=SAMME, learning_rate=1.0, n_estimators=300 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.0, n_estimators=300, score=0.867, total=   0.5s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=50 .............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=50, score=0.960, total=   2.7s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=50 .............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=50, score=0.946, total=   2.7s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=50 .............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=50, score=0.946, total=   2.0s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=50 .............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=50, score=0.965, total=   2.4s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=50 .............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=50, score=0.958, total=   3.3s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=100, score=0.960, total=   2.7s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=100, score=0.946, total=   2.6s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=100, score=0.946, total=   2.0s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=100, score=0.965, total=   2.4s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=100, score=0.958, total=   3.2s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=150, score=0.960, total=   2.7s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=150, score=0.946, total=   2.7s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=150, score=0.946, total=   2.0s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=150, score=0.965, total=   2.4s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=150, score=0.958, total=   3.2s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=200, score=0.960, total=   2.6s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=200, score=0.946, total=   2.6s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=200, score=0.946, total=   2.0s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=200, score=0.965, total=   2.3s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=200, score=0.958, total=   3.1s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=250, score=0.960, total=   2.6s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=250, score=0.946, total=   2.5s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=250, score=0.946, total=   1.9s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=250, score=0.965, total=   2.3s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=250, score=0.958, total=   3.1s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=300 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=300, score=0.960, total=   2.5s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=300 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=300, score=0.946, total=   2.6s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=300 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=300, score=0.946, total=   1.9s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=300 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=300, score=0.965, total=   2.3s\n",
            "[CV] algorithm=SAMME, learning_rate=1.5, n_estimators=300 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=1.5, n_estimators=300, score=0.958, total=   3.1s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=50 .............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=50, score=0.938, total=   3.6s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=50 .............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=50, score=0.933, total=   3.5s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=50 .............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=50, score=0.910, total=   3.5s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=50 .............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=50, score=0.938, total=   3.5s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=50 .............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=50, score=0.927, total=   3.5s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=100, score=0.938, total=   7.1s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=100, score=0.933, total=   7.1s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=100, score=0.910, total=   7.1s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=100, score=0.938, total=   7.2s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=100 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=100, score=0.927, total=   7.2s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=150, score=0.938, total=  10.8s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=150, score=0.933, total=  10.7s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=150, score=0.910, total=  10.6s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=150, score=0.938, total=  10.7s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=150 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=150, score=0.927, total=  10.6s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=200, score=0.938, total=  14.1s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=200, score=0.933, total=  14.0s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=200, score=0.910, total=  14.2s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=200, score=0.938, total=  14.2s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=200 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=200, score=0.927, total=  14.3s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=250, score=0.938, total=  17.9s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=250, score=0.933, total=  17.7s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=250, score=0.910, total=  17.8s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=250, score=0.938, total=  17.8s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=250 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=250, score=0.927, total=  17.8s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=300 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=300, score=0.938, total=  21.4s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=300 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=300, score=0.933, total=  21.4s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=300 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=300, score=0.910, total=  21.4s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=300 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=300, score=0.938, total=  21.5s\n",
            "[CV] algorithm=SAMME, learning_rate=2.0, n_estimators=300 ............\n",
            "[CV]  algorithm=SAMME, learning_rate=2.0, n_estimators=300, score=0.927, total=  21.5s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=50 ........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=50, score=0.748, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=50 ........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=50, score=0.779, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=50 ........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=50, score=0.867, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=50 ........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=50, score=0.790, total=   3.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=50 ........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=50, score=0.825, total=   3.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=100 .......\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=100, score=0.750, total=   7.3s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=100 .......\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=100, score=0.779, total=   7.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=100 .......\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=100, score=0.871, total=   7.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=100 .......\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=100, score=0.794, total=   7.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=100 .......\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=100, score=0.825, total=   7.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=150 .......\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=150, score=0.752, total=  10.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=150 .......\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=150, score=0.779, total=  10.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=150 .......\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=150, score=0.869, total=  10.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=150 .......\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=150, score=0.794, total=  10.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=150 .......\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=150, score=0.825, total=  10.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=200 .......\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=200, score=0.754, total=  14.4s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=200 .......\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=200, score=0.779, total=  14.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=200 .......\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=200, score=0.869, total=  14.3s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=200 .......\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=200, score=0.808, total=  14.3s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=200 .......\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=200, score=0.825, total=  14.3s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=250 .......\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=250, score=0.762, total=  17.9s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=250 .......\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=250, score=0.779, total=  17.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=250 .......\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=250, score=0.869, total=  17.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=250 .......\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=250, score=0.825, total=  17.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=250 .......\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=250, score=0.825, total=  17.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=300 .......\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=300, score=0.773, total=  21.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=300 .......\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=300, score=0.779, total=  21.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=300 .......\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=300, score=0.869, total=  21.4s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=300 .......\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=300, score=0.871, total=  21.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.0001, n_estimators=300 .......\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.0001, n_estimators=300, score=0.825, total=  21.3s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=50 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=50, score=0.942, total=   3.5s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=50 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=50, score=0.925, total=   3.5s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=50 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=50, score=0.935, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=50 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=50, score=0.960, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=50 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=50, score=0.908, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=100 .........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=100, score=0.942, total=   7.1s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=100 .........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=100, score=0.925, total=   7.1s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=100 .........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=100, score=0.935, total=   7.1s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=100 .........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=100, score=0.960, total=   7.1s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=100 .........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=100, score=0.908, total=   7.1s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=150 .........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=150, score=0.942, total=  10.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=150 .........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=150, score=0.925, total=  10.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=150 .........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=150, score=0.935, total=  10.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=150 .........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=150, score=0.960, total=  10.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=150 .........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=150, score=0.908, total=  10.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=200 .........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=200, score=0.942, total=  14.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=200 .........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=200, score=0.925, total=  14.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=200 .........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=200, score=0.935, total=  14.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=200 .........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=200, score=0.960, total=  14.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=200 .........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=200, score=0.908, total=  14.3s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=250 .........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=250, score=0.942, total=  17.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=250 .........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=250, score=0.925, total=  17.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=250 .........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=250, score=0.935, total=  17.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=250 .........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=250, score=0.960, total=  17.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=250 .........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=250, score=0.908, total=  17.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=300 .........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=300, score=0.942, total=  21.3s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=300 .........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=300, score=0.925, total=  21.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=300 .........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=300, score=0.935, total=  21.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=300 .........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=300, score=0.960, total=  21.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.05, n_estimators=300 .........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.05, n_estimators=300, score=0.908, total=  21.3s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=50 ...........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=50, score=0.935, total=   3.5s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=50 ...........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=50, score=0.927, total=   3.5s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=50 ...........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=50, score=0.919, total=   3.5s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=50 ...........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=50, score=0.948, total=   3.5s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=50 ...........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=50, score=0.875, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=100, score=0.935, total=   7.0s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=100, score=0.927, total=   7.1s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=100, score=0.919, total=   7.0s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=100, score=0.948, total=   7.1s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=100, score=0.875, total=   7.1s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=150, score=0.935, total=  10.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=150, score=0.927, total=  10.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=150, score=0.919, total=  10.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=150, score=0.948, total=  10.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=150, score=0.875, total=  10.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=200, score=0.935, total=  14.1s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=200, score=0.927, total=  14.1s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=200, score=0.919, total=  14.1s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=200, score=0.948, total=  14.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=200, score=0.875, total=  14.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=250, score=0.935, total=  17.9s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=250, score=0.927, total=  17.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=250, score=0.919, total=  17.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=250, score=0.948, total=  17.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=250, score=0.875, total=  17.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=300 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=300, score=0.935, total=  21.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=300 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=300, score=0.927, total=  21.4s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=300 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=300, score=0.919, total=  21.4s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=300 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=300, score=0.948, total=  21.3s\n",
            "[CV] algorithm=SAMME.R, learning_rate=0.5, n_estimators=300 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=0.5, n_estimators=300, score=0.875, total=  21.4s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=50 ...........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=50, score=0.958, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=50 ...........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=50, score=0.912, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=50 ...........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=50, score=0.908, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=50 ...........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=50, score=0.946, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=50 ...........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=50, score=0.869, total=   3.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=100, score=0.958, total=   7.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=100, score=0.912, total=   7.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=100, score=0.898, total=   7.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=100, score=0.946, total=   7.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=100, score=0.910, total=   7.3s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=150, score=0.958, total=  10.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=150, score=0.912, total=  10.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=150, score=0.898, total=  10.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=150, score=0.946, total=  10.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=150, score=0.873, total=  10.9s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=200, score=0.958, total=  14.4s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=200, score=0.912, total=  14.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=200, score=0.898, total=  14.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=200, score=0.946, total=  14.3s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=200, score=0.890, total=  14.5s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=250, score=0.958, total=  17.9s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=250, score=0.912, total=  17.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=250, score=0.898, total=  17.9s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=250, score=0.946, total=  17.9s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=250 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=250, score=nan, total=  14.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=300 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=300, score=0.958, total=  21.5s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=300 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=300, score=0.912, total=  21.4s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=300 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=300, score=0.898, total=  21.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=300 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=300, score=0.946, total=  21.9s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.0, n_estimators=300 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME.R, learning_rate=1.0, n_estimators=300, score=nan, total=  14.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=50 ...........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=50, score=0.846, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=50 ...........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=50, score=0.863, total=   3.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=50 ...........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=50, score=0.848, total=   3.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=50 ...........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=50, score=0.912, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=50 ...........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=50, score=0.848, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=100, score=0.937, total=   7.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=100, score=0.937, total=   7.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=100 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=100, score=nan, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=100, score=0.912, total=   7.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=100 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=100, score=nan, total=   5.3s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=150, score=0.954, total=  11.0s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=150, score=0.954, total=  10.9s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=150 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=150, score=nan, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=150, score=0.912, total=  10.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=150 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=150, score=nan, total=   5.4s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=200, score=0.942, total=  14.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=200, score=0.960, total=  14.4s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=200 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=200, score=nan, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=200, score=0.912, total=  14.4s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=200 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=200, score=nan, total=   5.3s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=250, score=0.965, total=  18.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=250, score=0.960, total=  18.0s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=250 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=250, score=nan, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=250, score=0.912, total=  17.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=250 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=250, score=nan, total=   5.3s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=300 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=300, score=nan, total=  18.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=300 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=300, score=0.960, total=  21.5s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=300 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=300, score=nan, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=300 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=300, score=0.912, total=  21.3s\n",
            "[CV] algorithm=SAMME.R, learning_rate=1.5, n_estimators=300 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME.R, learning_rate=1.5, n_estimators=300, score=nan, total=   5.3s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=50 ...........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=50, score=0.413, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=50 ...........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=50, score=0.912, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=50 ...........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=50, score=nan, total=   2.5s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=50 ...........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=50, score=0.842, total=   3.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=50 ...........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=50, score=0.856, total=   3.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=100, score=0.413, total=   7.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=100, score=0.910, total=   7.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=100 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=100, score=nan, total=   2.5s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=100, score=0.671, total=   7.1s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=100 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=100, score=0.906, total=   7.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=150, score=0.413, total=  10.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=150, score=0.910, total=  10.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=150 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=150, score=nan, total=   2.5s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=150, score=0.671, total=  10.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=150 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=150, score=0.904, total=  10.8s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=200, score=0.413, total=  14.3s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=200, score=0.910, total=  14.1s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=200 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=200, score=nan, total=   2.5s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=200, score=0.671, total=  14.3s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=200 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=200, score=0.946, total=  14.4s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=250, score=0.413, total=  18.1s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=250, score=0.910, total=  18.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=250 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=250, score=nan, total=   2.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=250 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=250, score=0.671, total=  18.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=250 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=250, score=nan, total=  14.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=300 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=300, score=0.413, total=  21.6s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=300 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=300, score=0.910, total=  21.2s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=300 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=300, score=nan, total=   2.5s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=300 ..........\n",
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=300, score=0.671, total=  21.7s\n",
            "[CV] algorithm=SAMME.R, learning_rate=2.0, n_estimators=300 ..........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ZeroDivisionError: Weights sum to zero, can't be normalized\n",
            "\n",
            "  FitFailedWarning)\n",
            "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed: 54.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  algorithm=SAMME.R, learning_rate=2.0, n_estimators=300, score=nan, total=  14.6s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
              "                                          base_estimator=GaussianNB(priors=None,\n",
              "                                                                    var_smoothing=1e-09),\n",
              "                                          learning_rate=1.0, n_estimators=50,\n",
              "                                          random_state=None),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'algorithm': ['SAMME', 'SAMME.R'],\n",
              "                          'learning_rate': [0.0001, 0.05, 0.5, 1.0, 1.5, 2.0],\n",
              "                          'n_estimators': [50, 100, 150, 200, 250, 300]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W5RAuYVBeJo",
        "outputId": "5fee55dd-5bf6-493e-cbf2-593d5fa3421e"
      },
      "source": [
        "grid_search_adb.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'algorithm': 'SAMME', 'learning_rate': 1.5, 'n_estimators': 50}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6rXvfMYBiuo",
        "outputId": "371daf7e-de43-4cf6-d894-b0ff70630d75"
      },
      "source": [
        "grid_search_adb.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9550000000000001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qM8pnt1pBmR_",
        "outputId": "0f0f53c3-bb51-4369-e136-9e01015f9c9c"
      },
      "source": [
        "y_pred_adb = grid_search_adb.predict(X_test_transformed.toarray())\n",
        "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred_adb)))\n",
        "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred_adb)))\n",
        "print(\"f1 score: {:.2f}%\".format(100 * f1_score(y_test, y_pred_adb)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 87.16%\n",
            "Recall: 91.35%\n",
            "f1 score: 89.20%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "aNdGw3QuntMM",
        "outputId": "f42b3d4e-612d-428a-ead6-837f07dba622"
      },
      "source": [
        "plot_confusion_matrix(grid_search_adb, X_test_transformed.toarray(), y_test, cmap=plt.cm.Blues)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f5f8cb24950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAEGCAYAAADxD4m3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAaIUlEQVR4nO3debgU5Z328e99DrIp+xYVUFTcQtxCxC1G8TWCOoKOGrfIGEdiosZxxiRqnLhkJjEmbzBuyWsUBbeocSNqUAdxjDuoSFxixBUQRRZRBGPQ3/tH18EWzlLFOU13FfcnV19UPVVd9Wu4vPPU9pQiAjOzIqqrdgFmZpXigDOzwnLAmVlhOeDMrLAccGZWWO2qXUA5tesUat+l2mVYBjtsM7DaJVgGb77xOgsWLFBrtlHfdZOIFctTrRvL3703Ika0Zn+tUVsB174LHbY6vNplWAYPP3ZJtUuwDPbY9Sut3kasWJ76v9OPZlzWu9U7bIWaCjgzywOB8nF2ywFnZtkIqKuvdhWpOODMLDu16jTeWuOAM7OMfIhqZkXmHpyZFZJwD87MikruwZlZgfkqqpkVU34uMuSjSjOrHaJ0iJrm09KmpNcl/UXSDEnTk7aeku6X9HLyZ4+kXZIuljRL0kxJO7W0fQecmWWnunSfdPaOiB0iYmgyfwYwJSIGA1OSeYCRwODkMxb4TUsbdsCZWUZq64Bb1ShgQjI9ARhd1j4xSh4HukvasLkNOeDMLBsB9fXpPtBb0vSyz9hVthbAfZKeKlvWLyLmJdNvA/2S6Y2B2WXfnZO0NckXGcwsu/S3iSwoO/RszB4RMVdSX+B+SX8tXxgRIWmN34zlHpyZZdR2h6gRMTf5cz5wO7Az8E7DoWfy5/xk9bnAgLKv90/amuSAM7Ps2uAqqqT1JXVpmAa+DjwHTALGJKuNAe5MpicBxyZXU3cBlpQdyjbKh6hmll3b3AfXD7hdpSBsB9wQEZMlTQNulnQ88AbQMLrmPcD+wCxgGXBcSztwwJlZNinvcWtJRLwKbN9I+0Jgn0baAzgpyz4ccGaWnR/VMrNiys+jWg44M8vOo4mYWSF5PDgzKy4foppZkfkig5kVls/BmVkhyYeoZlZk7sGZWVHJAWdmRVQasdwBZ2ZFJKE6B5yZFZR7cGZWWA44MyssB5yZFZOSTw444MwsEyH34MysuOrq/CSDmRWUe3BmVkw+B2dmReYenJkVki8ymFmh+VEtMysm+RDVzArMAWdmheWAM7NC8kUGMyu2fOSbA87MMpIf1TKzAvMhqpkVVz7yzQHXmGfvPI+ly/7OJ59+yooVnzJ8zIWfWz5yzy/xoxMP5NMIVqz4lLN+9Qcef/bVVu2ze9fOjP/ptxi4YU/enLeI4868iiUfLOewEUM59dh9kcTSZR/xHxfcxHMvz23Vvuwzp/zkeu575Dl69+jCIzee9blll10/hR9ffAd/u/dn9Oq+QZUqrE156cFV9EBa0ghJL0maJemMSu6rrf3Tib9mz6MvWC3cAB6a9hJ7HPUz9jz6Ak75yXX8+uyjUm93950Gc9k5x6zWftqYfXlo2ksM/efzeWjaS5w25usAvPHWQg749kXsfuRP+cVVkxl31pFr/qNsNUceOIybL/ruau1z31nM1Cf+Sv8v9KhCVbVNUupPyu3VS3pG0l3J/CBJTyS5cZOk9kl7h2R+VrJ805a2XbGAk1QPXAaMBLYFjpS0baX2tzZ9uPzjldOdO3Ug4rNlpxyzD1MmfJ+HbziTM8bun3qbI7+2HTfe9QQAN971BPvvtR0AT858jSUfLAdg2l9eY6O+3dvgF1iD3Xbcgh5dO6/W/qNxt3HuyaNy01NZ29oy4IBTgRfL5n8OjIuILYDFwPFJ+/HA4qR9XLJesyrZg9sZmBURr0bEx8DvgVEV3F+biQhuu/Rkpk78AWMO3r3RdQ7YazueuOVsbhp3Iqf85HoA9h62NZsN7Ms+Y37BV4++gB22HshuO26eap99e3bhnYXvA/DOwvfp27PLaut8c9Ru/M+jL6zhr7K07vnfmWzYpxtDtuxf7VJqluqU6tPidqT+wAHAlcm8gOHAH5JVJgCjk+lRyTzJ8n3UQopW8hzcxsDssvk5wLBVV5I0FhgLwHq1cZ5j5AnjmPfuEnr32IDbLz2Zl19/m0efeeVz69z94EzufnAmu+24OWedeAAHn3Qpe++yDcOHbc1D15eOxtfv1IHNBvTl0Wde4f6rT6dD+3as36kDPbp2XrnOuZfcyQOPv7haDeW9QoA9vjyYYw7alZEnjKvMjzYAln30MeMm3MetF59U7VJqWobeWW9J08vmr4iIK8rmLwJ+ADT8P3ov4L2IWJHMz6GUJVCWKRGxQtKSZP0FTe286hcZkh97BUBd577Rwuprxbx3lwCwYPFS7npwJjt9cdPVAq7Bo8+8wqYb96Znt/WRYNw193HN7Y+stt6+x/0SKJ2DO+qfhnHSedd9bvn8RR/Qr1dX3ln4Pv16deXdxR+sXPbFLTbi4rOP4rBTf8PiJR+21c+0Rrw+ZwFvvrWQPY+5AIC35r/H3sdeyP1Xn06/Xl2rXF2NyPaw/YKIGNroZqQDgfkR8ZSkvdqqvHKVPESdCwwom++ftNW0zh3bs0HnDiunh++yNS++8tbn1hnUv/fK6e226k/79dqxaMmHPPDYixx90K6s36k9ABv26UbvHul6pZMf+gtHHljq4B554DD+9L8zAejfrwcTLzyBE8+ZyCtvzm/177PmbbvFRrw0+WfMuOM8ZtxxHhv17c7UiT9wuJURIKX7tGB34CBJr1M6hTUc+DXQXVJD56s8N1ZmSrK8G7CwuR1Usgc3DRgsaVBS2BFA+suNVdKnVxeuu/AEAOrb1XPr5OlMeexFjjtkDwCuvu1hDhq+A984YBgrVnzC8o/+wfFnjQdg6hN/ZctBX+C+8acDsHTZ3/n2jyewYPHSFvc7bsL9XP2zb3HMQbsy++1FHHdmaZvf/9eR9Oy2Pr/84TcAGr1txdbcCWdfzSNPz2Lhe0sZcuB/csbY/TnmoF2rXVaNa5tnUSPiTOBMgKQHd3pEHC3pFuBQSqE3Brgz+cqkZP6xZPkDEauezFml0haWt4qk/SkdY9cD4yPiv5tbv65z3+iw1eEVq8fa3sInLql2CZbBHrt+haefmt6qdOr4hS1jkzHp/t3/duGIp5o6RC1XFnAHStqMUrj1BJ4BjomIv0vqCFwL7AgsAo6IiGZvQK3oObiIuAe4p5L7MLO1LN3hZyYR8SDwYDL9KqW7MFZd5yPgsCzbrfpFBjPLFwF1HrLczIoqL/c/O+DMLLO8POHhgDOzbCpwDq5SHHBmlomQB7w0s+JyD87MCsvn4MysmHwOzsyKqvQsaj4SzgFnZpnlJN8ccGaWnZ9kMLNiyjYeXFU54Mwsk4bx4PLAAWdmGbXNeHBrgwPOzDLLSb454MwsI/kig5kVlO+DM7NCc8CZWWHlJN8ccGaWnXtwZlZMftjezIqqNOBlPhLOAWdmmdXlpAvngDOzzHKSbw44M8tGftjezIosJ6fgmg44SZcA0dTyiPheRSoys5pXhIsM09daFWaWG6J0JTUPmgy4iJhQPi+pc0Qsq3xJZlbrctKBo8W3t0raVdILwF+T+e0lXV7xysysNqk0HlyaT7WleT31RcB+wEKAiHgW2LOSRZlZbZPSfaot1VXUiJi9Shp/UplyzKzWiWLd6Dtb0m5ASFoPOBV4sbJlmVkty8tV1DSHqCcCJwEbA28BOyTzZrYOSnt42lInT1JHSU9KelbS85LOS9oHSXpC0ixJN0lqn7R3SOZnJcs3banWFgMuIhZExNER0S8i+kTEMRGxMM1fhJkVU52U6tOCvwPDI2J7Sh2nEZJ2AX4OjIuILYDFwPHJ+scDi5P2ccl6zdfZ0gqSNpP0R0nvSpov6U5Jm7X0PTMrLqX8NCdKliaz6yWfAIYDf0jaJwCjk+lRyTzJ8n3UwqXaNIeoNwA3AxsCGwG3ADem+J6ZFVSG20R6S5pe9hm7ynbqJc0A5gP3A68A70XEimSVOZROj5H8ORsgWb4E6NVcnWkuMnSOiGvL5q+T9P0U3zOzAipdRU29+oKIGNrUwoj4BNhBUnfgdmDrVhdYprlnUXsmk3+SdAbwe0rdx28A97RlEWaWI2r7AS8j4j1JU4Fdge6S2iW9tP7A3GS1ucAAYI6kdkA3kvtzm9JcD+4pSoHW8Eu+XV4PcGbmX2FmhdAWTylI6gP8Iwm3TsC+lC4cTAUOpdSpGgPcmXxlUjL/WLL8gYhockAQaP5Z1EGt/gVmVjgZD1GbsyEwQVI9pesBN0fEXcmjob+X9F/AM8BVyfpXAddKmgUsAo5oaQepnmSQNATYFujY0BYRE7P8EjMrjrbowUXETGDHRtpfBXZupP0j4LAs+2gx4CSdA+xFKeDuAUYCDwMOOLN1VD6eY0h3m8ihwD7A2xFxHLA9pZN7ZrYOkqC+Tqk+1ZbmEHV5RHwqaYWkrpTuVxlQ4brMrIbVwlBIaaQJuOnJPSq/o3RldSmlqxhmto7KSb61HHAR8d1k8reSJgNdk5ODZrYOEqmeM60Jzd3ou1NzyyLi6cqUZGY1rUYGs0yjuR7c/21mWcMDsW1qx20G8sgTl7b1Zq2CXpv/YbVLsAw+XvFpm2wn9+fgImLvtVmImeWDgPq8B5yZWVNq4A6QVBxwZpaZA87MCqk0HHk+Ei7NiL6SdIykHyfzAyWt9pyYma076pTuU21pHtW6nNIYTUcm8x8Al1WsIjOreUV6L+qwiNhJ0jMAEbG44S03ZrbuEdCuFtIrhTQB949kvKaAlYPUtc3NNGaWSznJt1QBdzGlsdL7SvpvSqOLnF3RqsysZindKwFrQppnUa+X9BSlIZMEjI4Iv9nebB2Wk3xLNeDlQGAZ8Mfytoh4s5KFmVntqoUrpGmkOUS9m89ePtMRGAS8BHyxgnWZWY0S1MRglmmkOUT9Uvl8MsrId5tY3cyKrkbucUsj85MMEfG0pGGVKMbM8kE5eStDmnNw/142WwfsBLxVsYrMrKa14WsDKy5ND65L2fQKSufkbq1MOWaWB4UIuOQG3y4RcfpaqsfMciAvD9s3N2R5u4hYIWn3tVmQmdW20msDq11FOs314J6kdL5thqRJwC3AyvGpI+K2CtdmZjWqME8yULr3bSGldzA03A8XgAPObB1UlIsMfZMrqM/xWbA1iIpWZWY1LScduGYDrh7YABq94cUBZ7bOEnUFuA9uXkScv9YqMbNcEMXoweXkJ5jZWiVol5OTcM0F3D5rrQozy4089eCavJslIhatzULMLD/qkkEvW/o0R9IASVMlvSDpeUmnJu09Jd0v6eXkzx5JuyRdLGmWpJnJwB/N19kmv9bM1ilt9NKZFcB/RMS2wC7ASZK2Bc4ApkTEYGBKMg8wEhicfMYCv2lpBw44M8tElIIjzac5ETEvIp5Opj8AXgQ2BkYBE5LVJgCjk+lRwMQoeRzoLmnD5vbhFz+bWTbK9CRDb0nTy+aviIgrVtuktCmwI/AE0C8i5iWL3gb6JdMbA7PLvjYnaZtHExxwZpZJ6UmG1AG3ICKGNrs9aQNKIxT9W0S8X/4gf0SEpDW+79aHqGaWmVJ+WtyOtB6lcLu+7Pn2dxoOPZM/5yftc4EBZV/vn7Q1yQFnZpm1xUUGlbpqVwEvRsSvyhZNAsYk02OAO8vaj02upu4CLCk7lG2UD1HNLCO11XhwuwPfBP4iaUbSdhZwAXCzpOOBN4DDk2X3APsDsyi96e+4lnbggDOzTBquorZWRDxM00eyqz1oEBEBnJRlHw44M8usSOPBmZl9RgUYstzMrDFtdYi6NjjgzCwz9+DMrLDyEW8OODPLSEC9e3BmVlQ5yTcHnJllJZSTg1QHnJll5h6cmRVS6TaRfCScA87Mskk3Wm9NcMCZWWZ+VMvMCqk04GW1q0jHAWdmmfkqqpkVVk6OUB1wlfTbG6cy4Y5HIYJjR+/Od47au9olWSNuuPNhbr/3SSKCg/fbmaNHf5XfXn8/t9/7JD26rg/AyWNGsMdXtq5ypbVjne/BSRoPHAjMj4ghldpPrXph1ltMuONRpkz4Pu3b1XPo9y5nv68OYbMBfapdmpWZ9frb3H7vk0z81cmst149J//neL668zYAHD1qD479569VucLak6dzcJUc9eQaYEQFt1/T/vb62wwdsimdO7anXbt6dt9pC/44dUbLX7S16rXZ8xmy5QA6dWxPu/p6vvylQTzw6HPVLqu2pXyrfS1caa1YwEXEQ8CiSm2/1m2z+UY8NmMWi95byrKPPub+R59n7juLq12WrWLzTfrxzPOv8977H7L8o495ePpLvPPuEgBuuusxDj9pHOdedAvvf7CsypXWlrZ6q1alVf0cnKSxwFiAAQMHVrmatrPVoC9w6rH7csgpl9G5U3uGbNmf+rq8DBO47thsYD/+5dCv8d2zr6JTx/ZstdlG1NWLw/bfhROO2AcJLr/2Pn511d2c+2+HVbvcmpDxvahVVfWAS95yfQXAl788dI1f8FqLvjlqN745ajcAzr9sEhv17V7liqwxo/fbmdH77QzAJRMm069XN3r16LJy+SEjdubU866pUnW1KR/xlp+Rh3Pp3UUfADD77UXcNfVZDhvR7Au+rUoWvbcUgHnzFzP10ecYudcOvLvo/ZXLH3j0eTbfpF+1yqtNOTlGrXoPrsiO/eGVLF7yIe3a1fOLHxxOty6dq12SNeL0n17LkveX0a5dPT/8zmi6bNCJn//yTv726jwQbNS3Bz865ZBql1lT1vlDVEk3AnsBvSXNAc6JiKsqtb9a9KffnVbtEiyF8Rd+Z7W2/zr9iCpUkh/5iLcKBlxEHFmpbZtZleUk4XyIamaZlE6v5SPhHHBmlo3HgzOzIstJvjngzCwr+cXPZlZcOck3B5yZZVMj9/Cm4oAzs+xyknAOODPLLC+3ifhZVDPLTEr3aXk7Gi9pvqTnytp6Srpf0svJnz2Sdkm6WNIsSTMl7dTS9h1wZpZNynBLeSHiGlYfGPcMYEpEDAamJPMAI4HByWcs8JuWNu6AM7PMlPJ/LWliYNxRwIRkegIwuqx9YpQ8DnSXtGFz2/c5ODPLRGS6TaS3pOll81ckY0A2p19EzEum3wYaxqraGJhdtt6cpG0eTXDAmVlmGS4xLIiINR4IMSJC0hoPhOtDVDPLrrIDXr7TcOiZ/Dk/aZ8LDChbr3/S1iQHnJllVuG3ak0CxiTTY4A7y9qPTa6m7gIsKTuUbZQPUc0ss7a6C66xgXGBC4CbJR0PvAEcnqx+D7A/MAtYBhzX0vYdcGaWXRslXDMD4+7TyLoBnJRl+w44M8vEA16aWXF5wEszK7Kc5JsDzsyy8oCXZlZgOck3B5yZZeMBL82s2HKScA44M8vMt4mYWWH5HJyZFZOgzgFnZsWVj4RzwJlZJhkHvKwqB5yZZZaTfHPAmVl27sGZWWH5US0zK6x8xJsDzswyyvDO06pzwJlZZn6SwcyKKx/55oAzs+xykm8OODPLqlWvBFyrHHBmlkmenmTwi5/NrLDcgzOzzPLSg3PAmVlmvk3EzIrJN/qaWVHl6SKDA87MMvMhqpkVlntwZlZYOck3B5yZrYGcJJwDzswyEeTmUS1FRLVrWEnSu8Ab1a6jAnoDC6pdhGVS1H+zTSKiT2s2IGkypb+fNBZExIjW7K81airgikrS9IgYWu06LD3/mxWDn0U1s8JywJlZYTng1o4rql2AZeZ/swLwOTgzKyz34MyssBxwZlZYDrgKkjRC0kuSZkk6o9r1WMskjZc0X9Jz1a7FWs8BVyGS6oHLgJHAtsCRkratblWWwjVA1W5MtbblgKucnYFZEfFqRHwM/B4YVeWarAUR8RCwqNp1WNtwwFXOxsDssvk5SZuZrSUOODMrLAdc5cwFBpTN90/azGwtccBVzjRgsKRBktoDRwCTqlyT2TrFAVchEbECOBm4F3gRuDkinq9uVdYSSTcCjwFbSZoj6fhq12Rrzo9qmVlhuQdnZoXlgDOzwnLAmVlhOeDMrLAccGZWWA64HJH0iaQZkp6TdIukzq3Y1jWSDk2mr2xuIABJe0nabQ328bqk1d6+1FT7KusszbivcyWdnrVGKzYHXL4sj4gdImII8DFwYvlCSWv0ntuI+NeIeKGZVfYCMgecWbU54PLrz8AWSe/qz5ImAS9Iqpf0C0nTJM2U9G0AlVyajE/3P0Dfhg1JelDS0GR6hKSnJT0raYqkTSkF6WlJ7/GrkvpIujXZxzRJuyff7SXpPknPS7qSFO8/l3SHpKeS74xdZdm4pH2KpD5J2+aSJiff+bOkrdviL9OKyW+2z6GkpzYSmJw07QQMiYjXkpBYEhFfkdQBeETSfcCOwFaUxqbrB7wAjF9lu32A3wF7JtvqGRGLJP0WWBoRv0zWuwEYFxEPSxpI6WmNbYBzgIcj4nxJBwBpngL4VrKPTsA0SbdGxEJgfWB6RJwm6cfJtk+m9DKYEyPiZUnDgMuB4Wvw12jrAAdcvnSSNCOZ/jNwFaVDxycj4rWk/evAdg3n14BuwGBgT+DGiPgEeEvSA41sfxfgoYZtRURT46L9H2BbaWUHraukDZJ9HJJ8925Ji1P8pu9JOjiZHpDUuhD4FLgpab8OuC3Zx27ALWX77pBiH7aOcsDly/KI2KG8IfkP/cPyJuCUiLh3lfX2b8M66oBdIuKjRmpJTdJelMJy14hYJulBoGMTq0ey3/dW/Tswa4rPwRXPvcB3JK0HIGlLSesDDwHfSM7RbQjs3ch3Hwf2lDQo+W7PpP0DoEvZevcBpzTMSGoInIeAo5K2kUCPFmrtBixOwm1rSj3IBnVAQy/0KEqHvu8Dr0k6LNmHJG3fwj5sHeaAK54rKZ1fezp5ccr/o9RTvx14OVk2kdKIGZ8TEe8CYykdDj7LZ4eIfwQObrjIAHwPGJpcxHiBz67mnkcpIJ+ndKj6Zgu1TgbaSXoRuIBSwDb4ENg5+Q3DgfOT9qOB45P6nsfDwFszPJqImRWWe3BmVlgOODMrLAecmRWWA87MCssBZ2aF5YAzs8JywJlZYf1/nwljmdLcPfYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80ALA5a3gg1c"
      },
      "source": [
        "####2. Majority Voting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5asfBk-gX0p",
        "outputId": "49bbed50-9aa6-4d7d-e5e5-c6e1877827f4"
      },
      "source": [
        "# We use our best models: Logistic Regression, Random Forests(rf), SVC, Complement Naive Bayes(cnb)\n",
        "# There's a small error here with the Logistic Regressor.\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "vclf_param_grid = [{\n",
        "    'voting': ['hard', 'soft'],\n",
        "}]\n",
        "\n",
        "cnb_voter = ComplementNB(**grid_search_cnb.best_params_)\n",
        "log_voter = LogisticRegression(**grid_search_log.best_params_)\n",
        "rf_voter = RandomForestClassifier(**grid_search_rf.best_params_)\n",
        "svc_voter = SVC(**grid_search_svc.best_params_)\n",
        "vot_clf = VotingClassifier(estimators=[('rf', rf_voter), ('svc', svc_voter), ('cnb', cnb_voter), ('logi', log_voter)])\n",
        "grid_search_vot = GridSearchCV(vot_clf, vclf_param_grid, cv=5, verbose=3)\n",
        "grid_search_vot.fit(X_train_transformed.toarray(), y_train)  # toarray because of the naive bayes algorithm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
            "[CV] voting=hard .....................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ......................... voting=hard, score=0.985, total=   7.8s\n",
            "[CV] voting=hard .....................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.9s remaining:    0.0s\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ......................... voting=hard, score=0.969, total=   8.0s\n",
            "[CV] voting=hard .....................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   15.8s remaining:    0.0s\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ......................... voting=hard, score=0.983, total=   7.8s\n",
            "[CV] voting=hard .....................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ......................... voting=hard, score=0.981, total=   8.1s\n",
            "[CV] voting=hard .....................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ......................... voting=hard, score=0.971, total=   7.9s\n",
            "[CV] voting=soft .....................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ......................... voting=soft, score=0.988, total=   7.9s\n",
            "[CV] voting=soft .....................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ......................... voting=soft, score=0.979, total=   8.0s\n",
            "[CV] voting=soft .....................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ......................... voting=soft, score=0.981, total=   7.6s\n",
            "[CV] voting=soft .....................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ......................... voting=soft, score=0.979, total=   8.2s\n",
            "[CV] voting=soft .....................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ......................... voting=soft, score=0.969, total=   7.7s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.3min finished\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=VotingClassifier(estimators=[('rf',\n",
              "                                                     RandomForestClassifier(bootstrap=True,\n",
              "                                                                            ccp_alpha=0.0,\n",
              "                                                                            class_weight=None,\n",
              "                                                                            criterion='gini',\n",
              "                                                                            max_depth=None,\n",
              "                                                                            max_features='auto',\n",
              "                                                                            max_leaf_nodes=None,\n",
              "                                                                            max_samples=None,\n",
              "                                                                            min_impurity_decrease=0.0,\n",
              "                                                                            min_impurity_split=None,\n",
              "                                                                            min_samples_leaf=1,\n",
              "                                                                            min_samples_split=2,\n",
              "                                                                            min_weight_fraction_lea...\n",
              "                                                                        l1_ratio=None,\n",
              "                                                                        max_iter=100,\n",
              "                                                                        multi_class='auto',\n",
              "                                                                        n_jobs=None,\n",
              "                                                                        penalty='l2',\n",
              "                                                                        random_state=None,\n",
              "                                                                        solver='lbfgs',\n",
              "                                                                        tol=0.0001,\n",
              "                                                                        verbose=0,\n",
              "                                                                        warm_start=False))],\n",
              "                                        flatten_transform=True, n_jobs=None,\n",
              "                                        voting='hard', weights=None),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'voting': ['hard', 'soft']}], pre_dispatch='2*n_jobs',\n",
              "             refit=True, return_train_score=False, scoring=None, verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQKVkxqkjGEL",
        "outputId": "ca9c8de0-0fd2-4380-b8bd-c00174746036"
      },
      "source": [
        "grid_search_vot.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('rf',\n",
              "                              RandomForestClassifier(bootstrap=True,\n",
              "                                                     ccp_alpha=0.0,\n",
              "                                                     class_weight=None,\n",
              "                                                     criterion='gini',\n",
              "                                                     max_depth=None,\n",
              "                                                     max_features='auto',\n",
              "                                                     max_leaf_nodes=None,\n",
              "                                                     max_samples=None,\n",
              "                                                     min_impurity_decrease=0.0,\n",
              "                                                     min_impurity_split=None,\n",
              "                                                     min_samples_leaf=1,\n",
              "                                                     min_samples_split=2,\n",
              "                                                     min_weight_fraction_leaf=0.0,\n",
              "                                                     n_estimators=153,\n",
              "                                                     n_jobs=None,\n",
              "                                                     oob_score...\n",
              "                                           class_prior=None, fit_prior=True,\n",
              "                                           norm=False)),\n",
              "                             ('logi',\n",
              "                              LogisticRegression(C=0.615848211066026,\n",
              "                                                 class_weight=None, dual=False,\n",
              "                                                 fit_intercept=False,\n",
              "                                                 intercept_scaling=1,\n",
              "                                                 l1_ratio=None, max_iter=100,\n",
              "                                                 multi_class='auto',\n",
              "                                                 n_jobs=None, penalty='l2',\n",
              "                                                 random_state=None,\n",
              "                                                 solver='lbfgs', tol=0.0001,\n",
              "                                                 verbose=0,\n",
              "                                                 warm_start=False))],\n",
              "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
              "                 weights=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xikiNr6kjTdA",
        "outputId": "c0c4a673-38b0-4aa8-f1f7-6430e59d42e0"
      },
      "source": [
        "grid_search_vot.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'voting': 'soft'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ONDqUawjW8k",
        "outputId": "d148ae80-239d-402e-8950-90607fc6a09f"
      },
      "source": [
        "grid_search_vot.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9792307692307693"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ApkqrxejaRO",
        "outputId": "a823a0c3-b458-4ba7-f12d-b5633d409a7f"
      },
      "source": [
        "y_pred_vot = grid_search_vot.predict(X_test_transformed.toarray())\n",
        "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred_vot)))\n",
        "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred_vot)))\n",
        "print(\"f1 score: {:.2f}%\".format(100 * f1_score(y_test, y_pred_vot)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 98.02%\n",
            "Recall: 95.19%\n",
            "f1 score: 96.59%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "-jJvlHWOnSRF",
        "outputId": "53723068-cf54-4045-e3c7-d9edeec03a72"
      },
      "source": [
        "plot_confusion_matrix(grid_search_vot, X_test_transformed.toarray(), y_test, cmap=plt.cm.Blues)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f5f8c96ae50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnVwvY_nqDUb"
      },
      "source": [
        "####3. Bootstrap Aggregation/Bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USFb5he3qNVJ",
        "outputId": "edc87931-a9ed-499c-cbd9-6840d8d4bc2c"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "bag_param_grid = [{\n",
        "    'base_estimator': [cnb_voter, log_voter, rf_voter, svc_voter],\n",
        "    'bootstrap': [True, False],\n",
        "    'bootstrap_features': [True, False],\n",
        "}]\n",
        "\n",
        "bag_clf = BaggingClassifier(random_state=42)\n",
        "grid_search_bag = GridSearchCV(bag_clf, bag_param_grid, cv=5, verbose=3)\n",
        "grid_search_bag.fit(X_train_transformed, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
            "[CV] base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=True, bootstrap_features=True \n",
            "[CV]  base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=True, bootstrap_features=True, score=0.971, total=   0.1s\n",
            "[CV] base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=True, bootstrap_features=True \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=True, bootstrap_features=True, score=0.962, total=   0.1s\n",
            "[CV] base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=True, bootstrap_features=True \n",
            "[CV]  base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=True, bootstrap_features=True, score=0.962, total=   0.1s\n",
            "[CV] base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=True, bootstrap_features=True \n",
            "[CV]  base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=True, bootstrap_features=True, score=0.965, total=   0.1s\n",
            "[CV] base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=True, bootstrap_features=True \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=True, bootstrap_features=True, score=0.963, total=   0.1s\n",
            "[CV] base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=True, bootstrap_features=False \n",
            "[CV]  base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=True, bootstrap_features=False, score=0.965, total=   0.1s\n",
            "[CV] base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=True, bootstrap_features=False \n",
            "[CV]  base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=True, bootstrap_features=False, score=0.967, total=   0.1s\n",
            "[CV] base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=True, bootstrap_features=False \n",
            "[CV]  base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=True, bootstrap_features=False, score=0.954, total=   0.1s\n",
            "[CV] base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=True, bootstrap_features=False \n",
            "[CV]  base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=True, bootstrap_features=False, score=0.969, total=   0.1s\n",
            "[CV] base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=True, bootstrap_features=False \n",
            "[CV]  base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=True, bootstrap_features=False, score=0.962, total=   0.1s\n",
            "[CV] base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=False, bootstrap_features=True \n",
            "[CV]  base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=False, bootstrap_features=True, score=0.973, total=   0.1s\n",
            "[CV] base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=False, bootstrap_features=True \n",
            "[CV]  base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=False, bootstrap_features=True, score=0.962, total=   0.1s\n",
            "[CV] base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=False, bootstrap_features=True \n",
            "[CV]  base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=False, bootstrap_features=True, score=0.960, total=   0.1s\n",
            "[CV] base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=False, bootstrap_features=True \n",
            "[CV]  base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=False, bootstrap_features=True, score=0.965, total=   0.1s\n",
            "[CV] base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=False, bootstrap_features=True \n",
            "[CV]  base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=False, bootstrap_features=True, score=0.963, total=   0.1s\n",
            "[CV] base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=False, bootstrap_features=False \n",
            "[CV]  base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=False, bootstrap_features=False, score=0.971, total=   0.1s\n",
            "[CV] base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=False, bootstrap_features=False \n",
            "[CV]  base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=False, bootstrap_features=False, score=0.969, total=   0.1s\n",
            "[CV] base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=False, bootstrap_features=False \n",
            "[CV]  base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=False, bootstrap_features=False, score=0.956, total=   0.1s\n",
            "[CV] base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=False, bootstrap_features=False \n",
            "[CV]  base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=False, bootstrap_features=False, score=0.963, total=   0.1s\n",
            "[CV] base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=False, bootstrap_features=False \n",
            "[CV]  base_estimator=ComplementNB(alpha=0.8254066339240771, class_prior=None, fit_prior=True,\n",
            "             norm=False), bootstrap=False, bootstrap_features=False, score=0.960, total=   0.1s\n",
            "[CV] base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=True, bootstrap_features=True \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=True, bootstrap_features=True, score=0.985, total=   1.9s\n",
            "[CV] base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=True, bootstrap_features=True \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=True, bootstrap_features=True, score=0.971, total=   1.7s\n",
            "[CV] base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=True, bootstrap_features=True \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=True, bootstrap_features=True, score=0.973, total=   1.9s\n",
            "[CV] base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=True, bootstrap_features=True \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=True, bootstrap_features=True, score=0.977, total=   1.8s\n",
            "[CV] base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=True, bootstrap_features=True \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=True, bootstrap_features=True, score=0.973, total=   1.9s\n",
            "[CV] base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=True, bootstrap_features=False \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=True, bootstrap_features=False, score=0.987, total=   1.9s\n",
            "[CV] base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=True, bootstrap_features=False \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=True, bootstrap_features=False, score=0.971, total=   1.7s\n",
            "[CV] base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=True, bootstrap_features=False \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=True, bootstrap_features=False, score=0.977, total=   1.9s\n",
            "[CV] base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=True, bootstrap_features=False \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=True, bootstrap_features=False, score=0.981, total=   1.8s\n",
            "[CV] base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=True, bootstrap_features=False \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=True, bootstrap_features=False, score=0.973, total=   1.9s\n",
            "[CV] base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=False, bootstrap_features=True \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=False, bootstrap_features=True, score=0.987, total=   1.9s\n",
            "[CV] base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=False, bootstrap_features=True \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=False, bootstrap_features=True, score=0.969, total=   1.8s\n",
            "[CV] base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=False, bootstrap_features=True \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=False, bootstrap_features=True, score=0.975, total=   1.9s\n",
            "[CV] base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=False, bootstrap_features=True \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=False, bootstrap_features=True, score=0.979, total=   1.8s\n",
            "[CV] base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=False, bootstrap_features=True \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=False, bootstrap_features=True, score=0.971, total=   1.9s\n",
            "[CV] base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=False, bootstrap_features=False \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=False, bootstrap_features=False, score=0.983, total=   1.8s\n",
            "[CV] base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=False, bootstrap_features=False \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=False, bootstrap_features=False, score=0.973, total=   1.7s\n",
            "[CV] base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=False, bootstrap_features=False \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=False, bootstrap_features=False, score=0.975, total=   2.0s\n",
            "[CV] base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=False, bootstrap_features=False \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=False, bootstrap_features=False, score=0.983, total=   1.7s\n",
            "[CV] base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=False, bootstrap_features=False \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  base_estimator=LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
            "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), bootstrap=False, bootstrap_features=False, score=0.967, total=   1.9s\n",
            "[CV] base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=True, bootstrap_features=True \n",
            "[CV]  base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=True, bootstrap_features=True, score=0.977, total=  10.5s\n",
            "[CV] base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=True, bootstrap_features=True \n",
            "[CV]  base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=True, bootstrap_features=True, score=0.954, total=  10.3s\n",
            "[CV] base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=True, bootstrap_features=True \n",
            "[CV]  base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=True, bootstrap_features=True, score=0.969, total=  10.2s\n",
            "[CV] base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=True, bootstrap_features=True \n",
            "[CV]  base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=True, bootstrap_features=True, score=0.973, total=  10.2s\n",
            "[CV] base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=True, bootstrap_features=True \n",
            "[CV]  base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=True, bootstrap_features=True, score=0.973, total=  10.1s\n",
            "[CV] base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=True, bootstrap_features=False \n",
            "[CV]  base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=True, bootstrap_features=False, score=0.975, total=  10.0s\n",
            "[CV] base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=True, bootstrap_features=False \n",
            "[CV]  base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=True, bootstrap_features=False, score=0.962, total=   9.9s\n",
            "[CV] base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=True, bootstrap_features=False \n",
            "[CV]  base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=True, bootstrap_features=False, score=0.975, total=   9.8s\n",
            "[CV] base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=True, bootstrap_features=False \n",
            "[CV]  base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=True, bootstrap_features=False, score=0.971, total=   9.8s\n",
            "[CV] base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=True, bootstrap_features=False \n",
            "[CV]  base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=True, bootstrap_features=False, score=0.973, total=   9.8s\n",
            "[CV] base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=False, bootstrap_features=True \n",
            "[CV]  base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=False, bootstrap_features=True, score=0.975, total=  14.4s\n",
            "[CV] base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=False, bootstrap_features=True \n",
            "[CV]  base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=False, bootstrap_features=True, score=0.960, total=  14.2s\n",
            "[CV] base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=False, bootstrap_features=True \n",
            "[CV]  base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=False, bootstrap_features=True, score=0.977, total=  13.8s\n",
            "[CV] base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=False, bootstrap_features=True \n",
            "[CV]  base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=False, bootstrap_features=True, score=0.975, total=  14.0s\n",
            "[CV] base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=False, bootstrap_features=True \n",
            "[CV]  base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=False, bootstrap_features=True, score=0.969, total=  14.2s\n",
            "[CV] base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=False, bootstrap_features=False \n",
            "[CV]  base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=False, bootstrap_features=False, score=0.977, total=  13.9s\n",
            "[CV] base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=False, bootstrap_features=False \n",
            "[CV]  base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=False, bootstrap_features=False, score=0.965, total=  13.6s\n",
            "[CV] base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=False, bootstrap_features=False \n",
            "[CV]  base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=False, bootstrap_features=False, score=0.975, total=  13.3s\n",
            "[CV] base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=False, bootstrap_features=False \n",
            "[CV]  base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=False, bootstrap_features=False, score=0.973, total=  13.5s\n",
            "[CV] base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=False, bootstrap_features=False \n",
            "[CV]  base_estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=153,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), bootstrap=False, bootstrap_features=False, score=0.973, total=  13.6s\n",
            "[CV] base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=True, bootstrap_features=True \n",
            "[CV]  base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=True, bootstrap_features=True, score=0.946, total=  14.7s\n",
            "[CV] base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=True, bootstrap_features=True \n",
            "[CV]  base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=True, bootstrap_features=True, score=0.958, total=  14.1s\n",
            "[CV] base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=True, bootstrap_features=True \n",
            "[CV]  base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=True, bootstrap_features=True, score=0.950, total=  13.5s\n",
            "[CV] base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=True, bootstrap_features=True \n",
            "[CV]  base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=True, bootstrap_features=True, score=0.935, total=  15.1s\n",
            "[CV] base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=True, bootstrap_features=True \n",
            "[CV]  base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=True, bootstrap_features=True, score=0.940, total=  14.9s\n",
            "[CV] base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=True, bootstrap_features=False \n",
            "[CV]  base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=True, bootstrap_features=False, score=0.944, total=  13.4s\n",
            "[CV] base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=True, bootstrap_features=False \n",
            "[CV]  base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=True, bootstrap_features=False, score=0.963, total=  12.7s\n",
            "[CV] base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=True, bootstrap_features=False \n",
            "[CV]  base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=True, bootstrap_features=False, score=0.935, total=  12.3s\n",
            "[CV] base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=True, bootstrap_features=False \n",
            "[CV]  base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=True, bootstrap_features=False, score=0.938, total=  13.7s\n",
            "[CV] base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=True, bootstrap_features=False \n",
            "[CV]  base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=True, bootstrap_features=False, score=0.946, total=  12.7s\n",
            "[CV] base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=False, bootstrap_features=True \n",
            "[CV]  base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=False, bootstrap_features=True, score=0.963, total=  31.2s\n",
            "[CV] base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=False, bootstrap_features=True \n",
            "[CV]  base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=False, bootstrap_features=True, score=0.962, total=  30.2s\n",
            "[CV] base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=False, bootstrap_features=True \n",
            "[CV]  base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=False, bootstrap_features=True, score=0.954, total=  28.5s\n",
            "[CV] base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=False, bootstrap_features=True \n",
            "[CV]  base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=False, bootstrap_features=True, score=0.938, total=  31.6s\n",
            "[CV] base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=False, bootstrap_features=True \n",
            "[CV]  base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=False, bootstrap_features=True, score=0.962, total=  30.6s\n",
            "[CV] base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=False, bootstrap_features=False \n",
            "[CV]  base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=False, bootstrap_features=False, score=0.962, total=  26.8s\n",
            "[CV] base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=False, bootstrap_features=False \n",
            "[CV]  base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=False, bootstrap_features=False, score=0.962, total=  26.1s\n",
            "[CV] base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=False, bootstrap_features=False \n",
            "[CV]  base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=False, bootstrap_features=False, score=0.956, total=  24.8s\n",
            "[CV] base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=False, bootstrap_features=False \n",
            "[CV]  base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=False, bootstrap_features=False, score=0.933, total=  27.1s\n",
            "[CV] base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=False, bootstrap_features=False \n",
            "[CV]  base_estimator=SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.1,\n",
            "    verbose=False), bootstrap=False, bootstrap_features=False, score=0.965, total=  25.2s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed: 11.6min finished\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=BaggingClassifier(base_estimator=None, bootstrap=True,\n",
              "                                         bootstrap_features=False,\n",
              "                                         max_features=1.0, max_samples=1.0,\n",
              "                                         n_estimators=10, n_jobs=None,\n",
              "                                         oob_score=False, random_state=42,\n",
              "                                         verbose=0, warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'base_estimator': [ComplementNB(alpha=0.8254066339240771,\n",
              "                                                          class_pri...\n",
              "                                             SVC(C=1.0, break_ties=False,\n",
              "                                                 cache_size=200,\n",
              "                                                 class_weight=None, coef0=0.0,\n",
              "                                                 decision_function_shape='ovr',\n",
              "                                                 degree=3, gamma='scale',\n",
              "                                                 kernel='linear', max_iter=-1,\n",
              "                                                 probability=True,\n",
              "                                                 random_state=None,\n",
              "                                                 shrinking=True, tol=0.1,\n",
              "                                                 verbose=False)],\n",
              "                          'bootstrap': [True, False],\n",
              "                          'bootstrap_features': [True, False]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwSJJl18sOam",
        "outputId": "fea28048-a660-4724-fd87-7e95b1862fcc"
      },
      "source": [
        "grid_search_bag.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BaggingClassifier(base_estimator=LogisticRegression(C=0.615848211066026,\n",
              "                                                    class_weight=None,\n",
              "                                                    dual=False,\n",
              "                                                    fit_intercept=False,\n",
              "                                                    intercept_scaling=1,\n",
              "                                                    l1_ratio=None, max_iter=100,\n",
              "                                                    multi_class='auto',\n",
              "                                                    n_jobs=None, penalty='l2',\n",
              "                                                    random_state=None,\n",
              "                                                    solver='lbfgs', tol=0.0001,\n",
              "                                                    verbose=0,\n",
              "                                                    warm_start=False),\n",
              "                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
              "                  max_samples=1.0, n_estimators=10, n_jobs=None,\n",
              "                  oob_score=False, random_state=42, verbose=0,\n",
              "                  warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mya2ksTuj3A",
        "outputId": "f482dbfe-cb5f-4e21-90f5-222f09719ae9"
      },
      "source": [
        "grid_search_bag.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'base_estimator': LogisticRegression(C=0.615848211066026, class_weight=None, dual=False,\n",
              "                    fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
              "                    max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                    random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                    warm_start=False),\n",
              " 'bootstrap': True,\n",
              " 'bootstrap_features': False}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0YIJu7suoWS",
        "outputId": "9a120d07-8c74-4c9c-90e9-1f3b6a714adf"
      },
      "source": [
        "grid_search_bag.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9776923076923077"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoCWTOf5usDx",
        "outputId": "09eea535-8537-4ade-cf63-ee8ea4efc94d"
      },
      "source": [
        "y_pred_bag = grid_search_bag.predict(X_test_transformed.toarray())\n",
        "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred_bag)))\n",
        "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred_bag)))\n",
        "print(\"f1 score: {:.2f}%\".format(100 * f1_score(y_test, y_pred_bag)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 97.03%\n",
            "Recall: 94.23%\n",
            "f1 score: 95.61%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "jBPTnePrm31d",
        "outputId": "b54d2a40-51a6-4a30-f77c-a6c8cec17dad"
      },
      "source": [
        "plot_confusion_matrix(grid_search_bag, X_test_transformed.toarray(), y_test, cmap=plt.cm.Blues)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f5f8ca43590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}